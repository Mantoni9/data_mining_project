{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef098fd-ee40-4773-97a8-8c1b70ff6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import cos, sin, arcsin, sqrt\n",
    "from math import radians\n",
    "from datetime import date\n",
    "import holidays\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d10650-768f-4a33-8a23-c541d3cf7d9a",
   "metadata": {},
   "source": [
    "## Train, test and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e234c50-a401-4ca2-a907-9709ef5a213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/task_2/pre_task2_2014_2018.csv\", index_col=0)\n",
    "date_train = df_train['start_date']\n",
    "df_train = df_train.drop([\"start_date\"], axis=1)\n",
    "\n",
    "df_valid = pd.read_csv(\"data/task_2/pre_task2_2019.csv\", index_col=0)\n",
    "date_valid = df_valid['start_date']\n",
    "df_valid = df_valid.drop([\"start_date\"], axis=1)\n",
    "\n",
    "df_test = pd.read_csv(\"data/task_2/pre_task2_2022.csv\", index_col=0)\n",
    "date_test = df_test['start_date']\n",
    "df_test = df_test.drop([\"start_date\"], axis=1)\n",
    "\n",
    "def df_split(train, valid, test):\n",
    "    X_train = train.copy()\n",
    "    y_train = X_train['count']\n",
    "    X_train = X_train.drop([\"count\", 'duration_sec'], axis=1)\n",
    "    \n",
    "    X_valid = valid.copy()\n",
    "    y_valid = X_valid['count']\n",
    "    X_valid = X_valid.drop([\"count\", 'duration_sec'], axis=1)\n",
    "    \n",
    "    X_test = test.copy()\n",
    "    y_test = X_test['count']\n",
    "    X_test = X_test.drop([\"count\", 'duration_sec'], axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(df_train, df_valid, df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46535f9e-28c8-48ee-a7bb-75797f41acf2",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "In the following block we have made functions for 4 different models:\n",
    "- RandomForrestRegressor\n",
    "- GradientBoostingRegressor\n",
    "- TensorFlow\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf0ac1d-7dfb-4a33-a220-b4f329504885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12440/12440 [==============================] - 5s 418us/step - loss: 3860.4878 - val_loss: 4424.5840\n",
      "Epoch 2/20\n",
      "12440/12440 [==============================] - 5s 413us/step - loss: 3813.3074 - val_loss: 4394.8242\n",
      "Epoch 3/20\n",
      "12440/12440 [==============================] - 5s 417us/step - loss: 3771.2366 - val_loss: 4366.7407\n",
      "Epoch 4/20\n",
      "12440/12440 [==============================] - 5s 419us/step - loss: 3720.9177 - val_loss: 4263.5435\n",
      "Epoch 5/20\n",
      "12440/12440 [==============================] - 5s 416us/step - loss: 3626.9675 - val_loss: 4126.1440\n",
      "Epoch 6/20\n",
      "12440/12440 [==============================] - 5s 415us/step - loss: 3536.5811 - val_loss: 4067.0356\n",
      "Epoch 7/20\n",
      "12440/12440 [==============================] - 5s 411us/step - loss: 3488.1931 - val_loss: 3992.3518\n",
      "Epoch 8/20\n",
      "12440/12440 [==============================] - 5s 413us/step - loss: 3448.6890 - val_loss: 4000.2124\n",
      "Epoch 9/20\n",
      "12440/12440 [==============================] - 5s 426us/step - loss: 3405.3291 - val_loss: 3945.2188\n",
      "Epoch 10/20\n",
      "12440/12440 [==============================] - 5s 419us/step - loss: 3347.6431 - val_loss: 3826.0623\n",
      "Epoch 11/20\n",
      "12440/12440 [==============================] - 5s 415us/step - loss: 3291.7539 - val_loss: 3759.3403\n",
      "Epoch 12/20\n",
      "12440/12440 [==============================] - 5s 410us/step - loss: 3235.9382 - val_loss: 3667.0549\n",
      "Epoch 13/20\n",
      "12440/12440 [==============================] - 5s 416us/step - loss: 3166.1426 - val_loss: 3605.9412\n",
      "Epoch 14/20\n",
      "12440/12440 [==============================] - 5s 410us/step - loss: 3103.6934 - val_loss: 3557.3684\n",
      "Epoch 15/20\n",
      "12440/12440 [==============================] - 5s 417us/step - loss: 3062.2136 - val_loss: 3521.8633\n",
      "Epoch 16/20\n",
      "12440/12440 [==============================] - 5s 412us/step - loss: 3027.6526 - val_loss: 3511.9263\n",
      "Epoch 17/20\n",
      "12440/12440 [==============================] - 5s 409us/step - loss: 2997.0813 - val_loss: 3530.4426\n",
      "Epoch 18/20\n",
      "12440/12440 [==============================] - 5s 407us/step - loss: 2971.4675 - val_loss: 3430.3267\n",
      "Epoch 19/20\n",
      "12440/12440 [==============================] - 5s 405us/step - loss: 2955.5205 - val_loss: 3450.8184\n",
      "Epoch 20/20\n",
      "12440/12440 [==============================] - 5s 407us/step - loss: 2936.4775 - val_loss: 3529.2700\n",
      "6857/6857 [==============================] - 2s 225us/step\n",
      "Learning rate set to 0.117635\n",
      "0:\tlearn: 61.8587892\ttotal: 83.3ms\tremaining: 1m 23s\n",
      "1:\tlearn: 61.3293885\ttotal: 103ms\tremaining: 51.4s\n",
      "2:\tlearn: 60.7857552\ttotal: 125ms\tremaining: 41.5s\n",
      "3:\tlearn: 60.3360363\ttotal: 143ms\tremaining: 35.7s\n",
      "4:\tlearn: 59.6225599\ttotal: 165ms\tremaining: 32.9s\n",
      "5:\tlearn: 59.2355040\ttotal: 185ms\tremaining: 30.6s\n",
      "6:\tlearn: 58.8085780\ttotal: 208ms\tremaining: 29.5s\n",
      "7:\tlearn: 58.5402449\ttotal: 226ms\tremaining: 28s\n",
      "8:\tlearn: 57.9769075\ttotal: 247ms\tremaining: 27.2s\n",
      "9:\tlearn: 57.7708455\ttotal: 268ms\tremaining: 26.6s\n",
      "10:\tlearn: 57.2036997\ttotal: 291ms\tremaining: 26.1s\n",
      "11:\tlearn: 56.9222314\ttotal: 312ms\tremaining: 25.7s\n",
      "12:\tlearn: 56.6750598\ttotal: 334ms\tremaining: 25.4s\n",
      "13:\tlearn: 56.4772764\ttotal: 353ms\tremaining: 24.8s\n",
      "14:\tlearn: 56.2666211\ttotal: 374ms\tremaining: 24.5s\n",
      "15:\tlearn: 56.1178040\ttotal: 396ms\tremaining: 24.3s\n",
      "16:\tlearn: 55.6660943\ttotal: 416ms\tremaining: 24.1s\n",
      "17:\tlearn: 55.5159738\ttotal: 437ms\tremaining: 23.8s\n",
      "18:\tlearn: 55.3540052\ttotal: 459ms\tremaining: 23.7s\n",
      "19:\tlearn: 54.9252622\ttotal: 480ms\tremaining: 23.5s\n",
      "20:\tlearn: 54.6673288\ttotal: 499ms\tremaining: 23.3s\n",
      "21:\tlearn: 54.5341599\ttotal: 520ms\tremaining: 23.1s\n",
      "22:\tlearn: 54.1353049\ttotal: 543ms\tremaining: 23.1s\n",
      "23:\tlearn: 53.9999438\ttotal: 563ms\tremaining: 22.9s\n",
      "24:\tlearn: 53.8315049\ttotal: 584ms\tremaining: 22.8s\n",
      "25:\tlearn: 53.6502537\ttotal: 602ms\tremaining: 22.6s\n",
      "26:\tlearn: 53.4937591\ttotal: 620ms\tremaining: 22.4s\n",
      "27:\tlearn: 53.2191935\ttotal: 641ms\tremaining: 22.3s\n",
      "28:\tlearn: 53.1185227\ttotal: 663ms\tremaining: 22.2s\n",
      "29:\tlearn: 52.7968555\ttotal: 684ms\tremaining: 22.1s\n",
      "30:\tlearn: 52.6327523\ttotal: 704ms\tremaining: 22s\n",
      "31:\tlearn: 52.3238820\ttotal: 728ms\tremaining: 22s\n",
      "32:\tlearn: 52.1617586\ttotal: 747ms\tremaining: 21.9s\n",
      "33:\tlearn: 52.0602975\ttotal: 764ms\tremaining: 21.7s\n",
      "34:\tlearn: 51.6328416\ttotal: 787ms\tremaining: 21.7s\n",
      "35:\tlearn: 51.3692408\ttotal: 810ms\tremaining: 21.7s\n",
      "36:\tlearn: 51.3239967\ttotal: 828ms\tremaining: 21.6s\n",
      "37:\tlearn: 51.2074988\ttotal: 851ms\tremaining: 21.5s\n",
      "38:\tlearn: 51.1074380\ttotal: 873ms\tremaining: 21.5s\n",
      "39:\tlearn: 50.9943717\ttotal: 892ms\tremaining: 21.4s\n",
      "40:\tlearn: 50.8296282\ttotal: 917ms\tremaining: 21.4s\n",
      "41:\tlearn: 50.7182213\ttotal: 934ms\tremaining: 21.3s\n",
      "42:\tlearn: 50.4859418\ttotal: 958ms\tremaining: 21.3s\n",
      "43:\tlearn: 50.2729300\ttotal: 981ms\tremaining: 21.3s\n",
      "44:\tlearn: 50.1402094\ttotal: 999ms\tremaining: 21.2s\n",
      "45:\tlearn: 50.0716342\ttotal: 1.02s\tremaining: 21.2s\n",
      "46:\tlearn: 49.9246287\ttotal: 1.04s\tremaining: 21.1s\n",
      "47:\tlearn: 49.8700726\ttotal: 1.06s\tremaining: 21.1s\n",
      "48:\tlearn: 49.7923870\ttotal: 1.08s\tremaining: 21s\n",
      "49:\tlearn: 49.6677429\ttotal: 1.1s\tremaining: 20.9s\n",
      "50:\tlearn: 49.5782220\ttotal: 1.12s\tremaining: 20.9s\n",
      "51:\tlearn: 49.4345640\ttotal: 1.15s\tremaining: 20.9s\n",
      "52:\tlearn: 49.2729677\ttotal: 1.17s\tremaining: 20.8s\n",
      "53:\tlearn: 49.2345230\ttotal: 1.18s\tremaining: 20.7s\n",
      "54:\tlearn: 49.1055874\ttotal: 1.2s\tremaining: 20.7s\n",
      "55:\tlearn: 48.7878878\ttotal: 1.23s\tremaining: 20.7s\n",
      "56:\tlearn: 48.7087124\ttotal: 1.25s\tremaining: 20.6s\n",
      "57:\tlearn: 48.4391550\ttotal: 1.27s\tremaining: 20.6s\n",
      "58:\tlearn: 48.3045248\ttotal: 1.29s\tremaining: 20.6s\n",
      "59:\tlearn: 48.1247339\ttotal: 1.31s\tremaining: 20.6s\n",
      "60:\tlearn: 47.8218137\ttotal: 1.33s\tremaining: 20.5s\n",
      "61:\tlearn: 47.7589058\ttotal: 1.35s\tremaining: 20.5s\n",
      "62:\tlearn: 47.5125148\ttotal: 1.37s\tremaining: 20.4s\n",
      "63:\tlearn: 47.3722702\ttotal: 1.4s\tremaining: 20.5s\n",
      "64:\tlearn: 47.3265786\ttotal: 1.46s\tremaining: 21s\n",
      "65:\tlearn: 47.1834360\ttotal: 1.48s\tremaining: 20.9s\n",
      "66:\tlearn: 47.1335542\ttotal: 1.5s\tremaining: 20.9s\n",
      "67:\tlearn: 47.0547285\ttotal: 1.54s\tremaining: 21.1s\n",
      "68:\tlearn: 47.0081756\ttotal: 1.64s\tremaining: 22.1s\n",
      "69:\tlearn: 46.9014207\ttotal: 1.66s\tremaining: 22.1s\n",
      "70:\tlearn: 46.7817272\ttotal: 1.68s\tremaining: 22s\n",
      "71:\tlearn: 46.7195989\ttotal: 1.7s\tremaining: 21.9s\n",
      "72:\tlearn: 46.6946149\ttotal: 1.72s\tremaining: 21.9s\n",
      "73:\tlearn: 46.5628782\ttotal: 1.74s\tremaining: 21.8s\n",
      "74:\tlearn: 46.3570245\ttotal: 1.76s\tremaining: 21.7s\n",
      "75:\tlearn: 46.1198393\ttotal: 1.78s\tremaining: 21.7s\n",
      "76:\tlearn: 46.0022100\ttotal: 1.8s\tremaining: 21.6s\n",
      "77:\tlearn: 45.8612759\ttotal: 1.82s\tremaining: 21.5s\n",
      "78:\tlearn: 45.8033590\ttotal: 1.84s\tremaining: 21.5s\n",
      "79:\tlearn: 45.7088107\ttotal: 1.86s\tremaining: 21.4s\n",
      "80:\tlearn: 45.6145555\ttotal: 1.88s\tremaining: 21.4s\n",
      "81:\tlearn: 45.5451258\ttotal: 1.91s\tremaining: 21.3s\n",
      "82:\tlearn: 45.5077421\ttotal: 1.92s\tremaining: 21.3s\n",
      "83:\tlearn: 45.4753130\ttotal: 1.94s\tremaining: 21.2s\n",
      "84:\tlearn: 45.3081242\ttotal: 1.97s\tremaining: 21.2s\n",
      "85:\tlearn: 45.2369612\ttotal: 1.99s\tremaining: 21.1s\n",
      "86:\tlearn: 45.1257126\ttotal: 2s\tremaining: 21s\n",
      "87:\tlearn: 45.0777913\ttotal: 2.02s\tremaining: 21s\n",
      "88:\tlearn: 45.0494574\ttotal: 2.04s\tremaining: 20.9s\n",
      "89:\tlearn: 44.9175079\ttotal: 2.06s\tremaining: 20.8s\n",
      "90:\tlearn: 44.8919056\ttotal: 2.08s\tremaining: 20.8s\n",
      "91:\tlearn: 44.8382576\ttotal: 2.1s\tremaining: 20.7s\n",
      "92:\tlearn: 44.7681827\ttotal: 2.12s\tremaining: 20.7s\n",
      "93:\tlearn: 44.7354519\ttotal: 2.14s\tremaining: 20.6s\n",
      "94:\tlearn: 44.5389769\ttotal: 2.16s\tremaining: 20.6s\n",
      "95:\tlearn: 44.4634871\ttotal: 2.18s\tremaining: 20.5s\n",
      "96:\tlearn: 44.4311093\ttotal: 2.2s\tremaining: 20.4s\n",
      "97:\tlearn: 44.3388268\ttotal: 2.21s\tremaining: 20.4s\n",
      "98:\tlearn: 44.0762314\ttotal: 2.24s\tremaining: 20.4s\n",
      "99:\tlearn: 43.9361334\ttotal: 2.26s\tremaining: 20.3s\n",
      "100:\tlearn: 43.7509781\ttotal: 2.28s\tremaining: 20.3s\n",
      "101:\tlearn: 43.6856311\ttotal: 2.3s\tremaining: 20.3s\n",
      "102:\tlearn: 43.6379702\ttotal: 2.32s\tremaining: 20.2s\n",
      "103:\tlearn: 43.5150716\ttotal: 2.34s\tremaining: 20.2s\n",
      "104:\tlearn: 43.4424362\ttotal: 2.37s\tremaining: 20.2s\n",
      "105:\tlearn: 43.4250836\ttotal: 2.38s\tremaining: 20.1s\n",
      "106:\tlearn: 43.3811966\ttotal: 2.4s\tremaining: 20s\n",
      "107:\tlearn: 43.3187193\ttotal: 2.42s\tremaining: 20s\n",
      "108:\tlearn: 43.1744699\ttotal: 2.44s\tremaining: 20s\n",
      "109:\tlearn: 43.1353787\ttotal: 2.46s\tremaining: 19.9s\n",
      "110:\tlearn: 42.9478534\ttotal: 2.48s\tremaining: 19.9s\n",
      "111:\tlearn: 42.8765191\ttotal: 2.5s\tremaining: 19.8s\n",
      "112:\tlearn: 42.7409393\ttotal: 2.53s\tremaining: 19.8s\n",
      "113:\tlearn: 42.7075016\ttotal: 2.54s\tremaining: 19.8s\n",
      "114:\tlearn: 42.6779277\ttotal: 2.56s\tremaining: 19.7s\n",
      "115:\tlearn: 42.6240161\ttotal: 2.58s\tremaining: 19.7s\n",
      "116:\tlearn: 42.5990096\ttotal: 2.6s\tremaining: 19.6s\n",
      "117:\tlearn: 42.4391524\ttotal: 2.63s\tremaining: 19.6s\n",
      "118:\tlearn: 42.4138806\ttotal: 2.65s\tremaining: 19.6s\n",
      "119:\tlearn: 42.3947002\ttotal: 2.67s\tremaining: 19.6s\n",
      "120:\tlearn: 42.3114065\ttotal: 2.69s\tremaining: 19.5s\n",
      "121:\tlearn: 42.2893832\ttotal: 2.71s\tremaining: 19.5s\n",
      "122:\tlearn: 42.2477734\ttotal: 2.73s\tremaining: 19.5s\n",
      "123:\tlearn: 42.1521295\ttotal: 2.76s\tremaining: 19.5s\n",
      "124:\tlearn: 41.9388237\ttotal: 2.78s\tremaining: 19.5s\n",
      "125:\tlearn: 41.6933724\ttotal: 2.8s\tremaining: 19.4s\n",
      "126:\tlearn: 41.6817177\ttotal: 2.82s\tremaining: 19.4s\n",
      "127:\tlearn: 41.6591743\ttotal: 2.84s\tremaining: 19.4s\n",
      "128:\tlearn: 41.6023584\ttotal: 2.86s\tremaining: 19.3s\n",
      "129:\tlearn: 41.4688865\ttotal: 2.89s\tremaining: 19.3s\n",
      "130:\tlearn: 41.3925583\ttotal: 2.91s\tremaining: 19.3s\n",
      "131:\tlearn: 41.3333760\ttotal: 2.93s\tremaining: 19.3s\n",
      "132:\tlearn: 41.2790270\ttotal: 2.95s\tremaining: 19.2s\n",
      "133:\tlearn: 41.2394815\ttotal: 2.97s\tremaining: 19.2s\n",
      "134:\tlearn: 41.2238637\ttotal: 2.99s\tremaining: 19.2s\n",
      "135:\tlearn: 41.1130190\ttotal: 3.01s\tremaining: 19.1s\n",
      "136:\tlearn: 41.0595963\ttotal: 3.04s\tremaining: 19.1s\n",
      "137:\tlearn: 41.0042217\ttotal: 3.06s\tremaining: 19.1s\n",
      "138:\tlearn: 40.9705797\ttotal: 3.08s\tremaining: 19.1s\n",
      "139:\tlearn: 40.8930013\ttotal: 3.1s\tremaining: 19s\n",
      "140:\tlearn: 40.7838246\ttotal: 3.12s\tremaining: 19s\n",
      "141:\tlearn: 40.5242383\ttotal: 3.15s\tremaining: 19s\n",
      "142:\tlearn: 40.5108232\ttotal: 3.16s\tremaining: 19s\n",
      "143:\tlearn: 40.4641588\ttotal: 3.19s\tremaining: 18.9s\n",
      "144:\tlearn: 40.4072454\ttotal: 3.2s\tremaining: 18.9s\n",
      "145:\tlearn: 40.3440986\ttotal: 3.22s\tremaining: 18.8s\n",
      "146:\tlearn: 40.3135716\ttotal: 3.24s\tremaining: 18.8s\n",
      "147:\tlearn: 40.2141153\ttotal: 3.26s\tremaining: 18.8s\n",
      "148:\tlearn: 39.9936208\ttotal: 3.28s\tremaining: 18.8s\n",
      "149:\tlearn: 39.9718267\ttotal: 3.3s\tremaining: 18.7s\n",
      "150:\tlearn: 39.9419626\ttotal: 3.32s\tremaining: 18.7s\n",
      "151:\tlearn: 39.9092273\ttotal: 3.34s\tremaining: 18.7s\n",
      "152:\tlearn: 39.8717871\ttotal: 3.37s\tremaining: 18.6s\n",
      "153:\tlearn: 39.8580120\ttotal: 3.39s\tremaining: 18.6s\n",
      "154:\tlearn: 39.8050729\ttotal: 3.41s\tremaining: 18.6s\n",
      "155:\tlearn: 39.7546900\ttotal: 3.43s\tremaining: 18.5s\n",
      "156:\tlearn: 39.7406884\ttotal: 3.45s\tremaining: 18.5s\n",
      "157:\tlearn: 39.6139796\ttotal: 3.47s\tremaining: 18.5s\n",
      "158:\tlearn: 39.5792802\ttotal: 3.49s\tremaining: 18.5s\n",
      "159:\tlearn: 39.5618195\ttotal: 3.51s\tremaining: 18.4s\n",
      "160:\tlearn: 39.4714466\ttotal: 3.53s\tremaining: 18.4s\n",
      "161:\tlearn: 39.3995021\ttotal: 3.55s\tremaining: 18.4s\n",
      "162:\tlearn: 39.2210811\ttotal: 3.57s\tremaining: 18.3s\n",
      "163:\tlearn: 39.1726753\ttotal: 3.59s\tremaining: 18.3s\n",
      "164:\tlearn: 39.1081139\ttotal: 3.62s\tremaining: 18.3s\n",
      "165:\tlearn: 39.0246801\ttotal: 3.64s\tremaining: 18.3s\n",
      "166:\tlearn: 38.9681460\ttotal: 3.66s\tremaining: 18.2s\n",
      "167:\tlearn: 38.8245539\ttotal: 3.68s\tremaining: 18.2s\n",
      "168:\tlearn: 38.7924944\ttotal: 3.7s\tremaining: 18.2s\n",
      "169:\tlearn: 38.6488327\ttotal: 3.72s\tremaining: 18.2s\n",
      "170:\tlearn: 38.5583462\ttotal: 3.75s\tremaining: 18.2s\n",
      "171:\tlearn: 38.4878208\ttotal: 3.77s\tremaining: 18.1s\n",
      "172:\tlearn: 38.4473701\ttotal: 3.79s\tremaining: 18.1s\n",
      "173:\tlearn: 38.4353538\ttotal: 3.81s\tremaining: 18.1s\n",
      "174:\tlearn: 38.4210347\ttotal: 3.83s\tremaining: 18s\n",
      "175:\tlearn: 38.3359059\ttotal: 3.85s\tremaining: 18s\n",
      "176:\tlearn: 38.2624418\ttotal: 3.87s\tremaining: 18s\n",
      "177:\tlearn: 38.2401177\ttotal: 3.88s\tremaining: 17.9s\n",
      "178:\tlearn: 38.1680970\ttotal: 3.9s\tremaining: 17.9s\n",
      "179:\tlearn: 38.1611609\ttotal: 3.92s\tremaining: 17.9s\n",
      "180:\tlearn: 38.1423617\ttotal: 3.94s\tremaining: 17.8s\n",
      "181:\tlearn: 38.1227224\ttotal: 3.96s\tremaining: 17.8s\n",
      "182:\tlearn: 38.0998701\ttotal: 3.98s\tremaining: 17.8s\n",
      "183:\tlearn: 38.0273126\ttotal: 4s\tremaining: 17.7s\n",
      "184:\tlearn: 37.9509705\ttotal: 4.02s\tremaining: 17.7s\n",
      "185:\tlearn: 37.8721153\ttotal: 4.04s\tremaining: 17.7s\n",
      "186:\tlearn: 37.7906457\ttotal: 4.06s\tremaining: 17.7s\n",
      "187:\tlearn: 37.6245088\ttotal: 4.09s\tremaining: 17.7s\n",
      "188:\tlearn: 37.6066504\ttotal: 4.11s\tremaining: 17.6s\n",
      "189:\tlearn: 37.5506617\ttotal: 4.13s\tremaining: 17.6s\n",
      "190:\tlearn: 37.5035810\ttotal: 4.15s\tremaining: 17.6s\n",
      "191:\tlearn: 37.4507217\ttotal: 4.17s\tremaining: 17.5s\n",
      "192:\tlearn: 37.4157661\ttotal: 4.19s\tremaining: 17.5s\n",
      "193:\tlearn: 37.4042618\ttotal: 4.21s\tremaining: 17.5s\n",
      "194:\tlearn: 37.3660763\ttotal: 4.23s\tremaining: 17.4s\n",
      "195:\tlearn: 37.3496535\ttotal: 4.24s\tremaining: 17.4s\n",
      "196:\tlearn: 37.2722186\ttotal: 4.26s\tremaining: 17.4s\n",
      "197:\tlearn: 37.2126188\ttotal: 4.29s\tremaining: 17.4s\n",
      "198:\tlearn: 37.1967836\ttotal: 4.3s\tremaining: 17.3s\n",
      "199:\tlearn: 37.1819110\ttotal: 4.32s\tremaining: 17.3s\n",
      "200:\tlearn: 37.1769145\ttotal: 4.34s\tremaining: 17.3s\n",
      "201:\tlearn: 37.1451170\ttotal: 4.36s\tremaining: 17.2s\n",
      "202:\tlearn: 37.0960125\ttotal: 4.38s\tremaining: 17.2s\n",
      "203:\tlearn: 37.0618212\ttotal: 4.4s\tremaining: 17.2s\n",
      "204:\tlearn: 37.0289229\ttotal: 4.42s\tremaining: 17.2s\n",
      "205:\tlearn: 36.9836854\ttotal: 4.44s\tremaining: 17.1s\n",
      "206:\tlearn: 36.9724598\ttotal: 4.46s\tremaining: 17.1s\n",
      "207:\tlearn: 36.9639912\ttotal: 4.48s\tremaining: 17.1s\n",
      "208:\tlearn: 36.9321601\ttotal: 4.5s\tremaining: 17s\n",
      "209:\tlearn: 36.8691385\ttotal: 4.52s\tremaining: 17s\n",
      "210:\tlearn: 36.8478614\ttotal: 4.54s\tremaining: 17s\n",
      "211:\tlearn: 36.8220291\ttotal: 4.56s\tremaining: 16.9s\n",
      "212:\tlearn: 36.7916962\ttotal: 4.58s\tremaining: 16.9s\n",
      "213:\tlearn: 36.7037851\ttotal: 4.6s\tremaining: 16.9s\n",
      "214:\tlearn: 36.6572617\ttotal: 4.62s\tremaining: 16.9s\n",
      "215:\tlearn: 36.6480360\ttotal: 4.64s\tremaining: 16.9s\n",
      "216:\tlearn: 36.6451297\ttotal: 4.66s\tremaining: 16.8s\n",
      "217:\tlearn: 36.5925840\ttotal: 4.68s\tremaining: 16.8s\n",
      "218:\tlearn: 36.5861203\ttotal: 4.7s\tremaining: 16.7s\n",
      "219:\tlearn: 36.5626189\ttotal: 4.72s\tremaining: 16.7s\n",
      "220:\tlearn: 36.5482148\ttotal: 4.74s\tremaining: 16.7s\n",
      "221:\tlearn: 36.4868042\ttotal: 4.76s\tremaining: 16.7s\n",
      "222:\tlearn: 36.4596180\ttotal: 4.78s\tremaining: 16.6s\n",
      "223:\tlearn: 36.4184021\ttotal: 4.79s\tremaining: 16.6s\n",
      "224:\tlearn: 36.3927291\ttotal: 4.82s\tremaining: 16.6s\n",
      "225:\tlearn: 36.3807337\ttotal: 4.83s\tremaining: 16.6s\n",
      "226:\tlearn: 36.3516713\ttotal: 4.86s\tremaining: 16.5s\n",
      "227:\tlearn: 36.2729432\ttotal: 4.89s\tremaining: 16.6s\n",
      "228:\tlearn: 36.2103073\ttotal: 4.93s\tremaining: 16.6s\n",
      "229:\tlearn: 36.1339033\ttotal: 4.95s\tremaining: 16.6s\n",
      "230:\tlearn: 36.0901310\ttotal: 4.97s\tremaining: 16.5s\n",
      "231:\tlearn: 35.9712200\ttotal: 4.99s\tremaining: 16.5s\n",
      "232:\tlearn: 35.9081917\ttotal: 5.01s\tremaining: 16.5s\n",
      "233:\tlearn: 35.8558987\ttotal: 5.04s\tremaining: 16.5s\n",
      "234:\tlearn: 35.8406397\ttotal: 5.05s\tremaining: 16.4s\n",
      "235:\tlearn: 35.7766183\ttotal: 5.08s\tremaining: 16.4s\n",
      "236:\tlearn: 35.7335439\ttotal: 5.09s\tremaining: 16.4s\n",
      "237:\tlearn: 35.6949774\ttotal: 5.11s\tremaining: 16.4s\n",
      "238:\tlearn: 35.6327631\ttotal: 5.13s\tremaining: 16.3s\n",
      "239:\tlearn: 35.6242362\ttotal: 5.15s\tremaining: 16.3s\n",
      "240:\tlearn: 35.6178202\ttotal: 5.17s\tremaining: 16.3s\n",
      "241:\tlearn: 35.5112746\ttotal: 5.19s\tremaining: 16.3s\n",
      "242:\tlearn: 35.5013847\ttotal: 5.21s\tremaining: 16.2s\n",
      "243:\tlearn: 35.4746778\ttotal: 5.23s\tremaining: 16.2s\n",
      "244:\tlearn: 35.4672585\ttotal: 5.25s\tremaining: 16.2s\n",
      "245:\tlearn: 35.4588514\ttotal: 5.27s\tremaining: 16.2s\n",
      "246:\tlearn: 35.4292460\ttotal: 5.29s\tremaining: 16.1s\n",
      "247:\tlearn: 35.4152775\ttotal: 5.31s\tremaining: 16.1s\n",
      "248:\tlearn: 35.3691632\ttotal: 5.33s\tremaining: 16.1s\n",
      "249:\tlearn: 35.3321514\ttotal: 5.35s\tremaining: 16.1s\n",
      "250:\tlearn: 35.3261731\ttotal: 5.37s\tremaining: 16s\n",
      "251:\tlearn: 35.2786457\ttotal: 5.39s\tremaining: 16s\n",
      "252:\tlearn: 35.2158147\ttotal: 5.41s\tremaining: 16s\n",
      "253:\tlearn: 35.1952530\ttotal: 5.43s\tremaining: 16s\n",
      "254:\tlearn: 35.1255750\ttotal: 5.45s\tremaining: 15.9s\n",
      "255:\tlearn: 35.1046496\ttotal: 5.47s\tremaining: 15.9s\n",
      "256:\tlearn: 35.0914041\ttotal: 5.49s\tremaining: 15.9s\n",
      "257:\tlearn: 35.0782169\ttotal: 5.51s\tremaining: 15.9s\n",
      "258:\tlearn: 35.0499726\ttotal: 5.54s\tremaining: 15.8s\n",
      "259:\tlearn: 35.0459917\ttotal: 5.55s\tremaining: 15.8s\n",
      "260:\tlearn: 35.0386614\ttotal: 5.58s\tremaining: 15.8s\n",
      "261:\tlearn: 34.9884624\ttotal: 5.6s\tremaining: 15.8s\n",
      "262:\tlearn: 34.9830470\ttotal: 5.62s\tremaining: 15.7s\n",
      "263:\tlearn: 34.9323682\ttotal: 5.64s\tremaining: 15.7s\n",
      "264:\tlearn: 34.9056318\ttotal: 5.66s\tremaining: 15.7s\n",
      "265:\tlearn: 34.8410167\ttotal: 5.68s\tremaining: 15.7s\n",
      "266:\tlearn: 34.8211909\ttotal: 5.7s\tremaining: 15.6s\n",
      "267:\tlearn: 34.8103664\ttotal: 5.72s\tremaining: 15.6s\n",
      "268:\tlearn: 34.7479078\ttotal: 5.74s\tremaining: 15.6s\n",
      "269:\tlearn: 34.6618508\ttotal: 5.76s\tremaining: 15.6s\n",
      "270:\tlearn: 34.6282234\ttotal: 5.78s\tremaining: 15.6s\n",
      "271:\tlearn: 34.5742542\ttotal: 5.81s\tremaining: 15.5s\n",
      "272:\tlearn: 34.5334599\ttotal: 5.83s\tremaining: 15.5s\n",
      "273:\tlearn: 34.5227037\ttotal: 5.85s\tremaining: 15.5s\n",
      "274:\tlearn: 34.5148713\ttotal: 5.87s\tremaining: 15.5s\n",
      "275:\tlearn: 34.4936113\ttotal: 5.89s\tremaining: 15.4s\n",
      "276:\tlearn: 34.4405303\ttotal: 5.91s\tremaining: 15.4s\n",
      "277:\tlearn: 34.4107048\ttotal: 5.92s\tremaining: 15.4s\n",
      "278:\tlearn: 34.3738743\ttotal: 5.95s\tremaining: 15.4s\n",
      "279:\tlearn: 34.3413441\ttotal: 5.97s\tremaining: 15.4s\n",
      "280:\tlearn: 34.3149661\ttotal: 5.99s\tremaining: 15.3s\n",
      "281:\tlearn: 34.2828505\ttotal: 6.01s\tremaining: 15.3s\n",
      "282:\tlearn: 34.2760758\ttotal: 6.03s\tremaining: 15.3s\n",
      "283:\tlearn: 34.2705773\ttotal: 6.05s\tremaining: 15.2s\n",
      "284:\tlearn: 34.2519767\ttotal: 6.07s\tremaining: 15.2s\n",
      "285:\tlearn: 34.2167618\ttotal: 6.09s\tremaining: 15.2s\n",
      "286:\tlearn: 34.1783470\ttotal: 6.11s\tremaining: 15.2s\n",
      "287:\tlearn: 34.1258915\ttotal: 6.13s\tremaining: 15.2s\n",
      "288:\tlearn: 34.0760913\ttotal: 6.15s\tremaining: 15.1s\n",
      "289:\tlearn: 34.0576752\ttotal: 6.17s\tremaining: 15.1s\n",
      "290:\tlearn: 34.0530959\ttotal: 6.19s\tremaining: 15.1s\n",
      "291:\tlearn: 34.0455848\ttotal: 6.21s\tremaining: 15.1s\n",
      "292:\tlearn: 34.0104458\ttotal: 6.23s\tremaining: 15s\n",
      "293:\tlearn: 33.9656591\ttotal: 6.25s\tremaining: 15s\n",
      "294:\tlearn: 33.9343183\ttotal: 6.27s\tremaining: 15s\n",
      "295:\tlearn: 33.9190444\ttotal: 6.29s\tremaining: 15s\n",
      "296:\tlearn: 33.8758703\ttotal: 6.31s\tremaining: 14.9s\n",
      "297:\tlearn: 33.8739544\ttotal: 6.33s\tremaining: 14.9s\n",
      "298:\tlearn: 33.8713623\ttotal: 6.34s\tremaining: 14.9s\n",
      "299:\tlearn: 33.8594406\ttotal: 6.36s\tremaining: 14.8s\n",
      "300:\tlearn: 33.8531635\ttotal: 6.38s\tremaining: 14.8s\n",
      "301:\tlearn: 33.8502102\ttotal: 6.4s\tremaining: 14.8s\n",
      "302:\tlearn: 33.8251574\ttotal: 6.42s\tremaining: 14.8s\n",
      "303:\tlearn: 33.8142411\ttotal: 6.44s\tremaining: 14.7s\n",
      "304:\tlearn: 33.8124506\ttotal: 6.45s\tremaining: 14.7s\n",
      "305:\tlearn: 33.7963988\ttotal: 6.47s\tremaining: 14.7s\n",
      "306:\tlearn: 33.7886881\ttotal: 6.49s\tremaining: 14.7s\n",
      "307:\tlearn: 33.7564224\ttotal: 6.52s\tremaining: 14.6s\n",
      "308:\tlearn: 33.7345073\ttotal: 6.54s\tremaining: 14.6s\n",
      "309:\tlearn: 33.7166310\ttotal: 6.56s\tremaining: 14.6s\n",
      "310:\tlearn: 33.7142400\ttotal: 6.58s\tremaining: 14.6s\n",
      "311:\tlearn: 33.6861141\ttotal: 6.6s\tremaining: 14.5s\n",
      "312:\tlearn: 33.6440022\ttotal: 6.62s\tremaining: 14.5s\n",
      "313:\tlearn: 33.6131768\ttotal: 6.63s\tremaining: 14.5s\n",
      "314:\tlearn: 33.6096671\ttotal: 6.66s\tremaining: 14.5s\n",
      "315:\tlearn: 33.6003587\ttotal: 6.67s\tremaining: 14.4s\n",
      "316:\tlearn: 33.5885749\ttotal: 6.69s\tremaining: 14.4s\n",
      "317:\tlearn: 33.5562668\ttotal: 6.71s\tremaining: 14.4s\n",
      "318:\tlearn: 33.5273214\ttotal: 6.73s\tremaining: 14.4s\n",
      "319:\tlearn: 33.5037045\ttotal: 6.75s\tremaining: 14.4s\n",
      "320:\tlearn: 33.5027541\ttotal: 6.77s\tremaining: 14.3s\n",
      "321:\tlearn: 33.4493493\ttotal: 6.79s\tremaining: 14.3s\n",
      "322:\tlearn: 33.4304610\ttotal: 6.81s\tremaining: 14.3s\n",
      "323:\tlearn: 33.3906222\ttotal: 6.83s\tremaining: 14.3s\n",
      "324:\tlearn: 33.3880403\ttotal: 6.85s\tremaining: 14.2s\n",
      "325:\tlearn: 33.3749730\ttotal: 6.87s\tremaining: 14.2s\n",
      "326:\tlearn: 33.3346894\ttotal: 6.89s\tremaining: 14.2s\n",
      "327:\tlearn: 33.3054819\ttotal: 6.91s\tremaining: 14.2s\n",
      "328:\tlearn: 33.2359458\ttotal: 6.94s\tremaining: 14.2s\n",
      "329:\tlearn: 33.2349385\ttotal: 6.95s\tremaining: 14.1s\n",
      "330:\tlearn: 33.2025978\ttotal: 6.97s\tremaining: 14.1s\n",
      "331:\tlearn: 33.1981211\ttotal: 6.99s\tremaining: 14.1s\n",
      "332:\tlearn: 33.1510807\ttotal: 7.01s\tremaining: 14s\n",
      "333:\tlearn: 33.1290845\ttotal: 7.03s\tremaining: 14s\n",
      "334:\tlearn: 33.0983864\ttotal: 7.05s\tremaining: 14s\n",
      "335:\tlearn: 33.0890530\ttotal: 7.07s\tremaining: 14s\n",
      "336:\tlearn: 33.0462215\ttotal: 7.08s\tremaining: 13.9s\n",
      "337:\tlearn: 33.0318730\ttotal: 7.11s\tremaining: 13.9s\n",
      "338:\tlearn: 33.0131288\ttotal: 7.13s\tremaining: 13.9s\n",
      "339:\tlearn: 33.0033886\ttotal: 7.15s\tremaining: 13.9s\n",
      "340:\tlearn: 32.9960479\ttotal: 7.17s\tremaining: 13.8s\n",
      "341:\tlearn: 32.9865873\ttotal: 7.18s\tremaining: 13.8s\n",
      "342:\tlearn: 32.9768807\ttotal: 7.2s\tremaining: 13.8s\n",
      "343:\tlearn: 32.9333647\ttotal: 7.22s\tremaining: 13.8s\n",
      "344:\tlearn: 32.8921357\ttotal: 7.24s\tremaining: 13.8s\n",
      "345:\tlearn: 32.8706505\ttotal: 7.26s\tremaining: 13.7s\n",
      "346:\tlearn: 32.8652180\ttotal: 7.28s\tremaining: 13.7s\n",
      "347:\tlearn: 32.8548139\ttotal: 7.3s\tremaining: 13.7s\n",
      "348:\tlearn: 32.8381689\ttotal: 7.32s\tremaining: 13.7s\n",
      "349:\tlearn: 32.8173967\ttotal: 7.34s\tremaining: 13.6s\n",
      "350:\tlearn: 32.7137430\ttotal: 7.37s\tremaining: 13.6s\n",
      "351:\tlearn: 32.7059097\ttotal: 7.39s\tremaining: 13.6s\n",
      "352:\tlearn: 32.6764217\ttotal: 7.41s\tremaining: 13.6s\n",
      "353:\tlearn: 32.6409903\ttotal: 7.43s\tremaining: 13.6s\n",
      "354:\tlearn: 32.5926972\ttotal: 7.45s\tremaining: 13.5s\n",
      "355:\tlearn: 32.5541183\ttotal: 7.47s\tremaining: 13.5s\n",
      "356:\tlearn: 32.5132711\ttotal: 7.49s\tremaining: 13.5s\n",
      "357:\tlearn: 32.4210392\ttotal: 7.51s\tremaining: 13.5s\n",
      "358:\tlearn: 32.3904096\ttotal: 7.53s\tremaining: 13.5s\n",
      "359:\tlearn: 32.3599388\ttotal: 7.55s\tremaining: 13.4s\n",
      "360:\tlearn: 32.3429465\ttotal: 7.58s\tremaining: 13.4s\n",
      "361:\tlearn: 32.3246678\ttotal: 7.59s\tremaining: 13.4s\n",
      "362:\tlearn: 32.3165782\ttotal: 7.62s\tremaining: 13.4s\n",
      "363:\tlearn: 32.2726229\ttotal: 7.64s\tremaining: 13.3s\n",
      "364:\tlearn: 32.2539892\ttotal: 7.66s\tremaining: 13.3s\n",
      "365:\tlearn: 32.2207551\ttotal: 7.68s\tremaining: 13.3s\n",
      "366:\tlearn: 32.2167637\ttotal: 7.7s\tremaining: 13.3s\n",
      "367:\tlearn: 32.1720196\ttotal: 7.72s\tremaining: 13.3s\n",
      "368:\tlearn: 32.1636843\ttotal: 7.74s\tremaining: 13.2s\n",
      "369:\tlearn: 32.1394614\ttotal: 7.76s\tremaining: 13.2s\n",
      "370:\tlearn: 32.1250552\ttotal: 7.78s\tremaining: 13.2s\n",
      "371:\tlearn: 32.1123327\ttotal: 7.8s\tremaining: 13.2s\n",
      "372:\tlearn: 32.0751528\ttotal: 7.82s\tremaining: 13.1s\n",
      "373:\tlearn: 32.0659176\ttotal: 7.84s\tremaining: 13.1s\n",
      "374:\tlearn: 32.0585159\ttotal: 7.86s\tremaining: 13.1s\n",
      "375:\tlearn: 32.0471633\ttotal: 7.88s\tremaining: 13.1s\n",
      "376:\tlearn: 32.0417392\ttotal: 7.9s\tremaining: 13.1s\n",
      "377:\tlearn: 32.0023536\ttotal: 7.92s\tremaining: 13s\n",
      "378:\tlearn: 31.9675714\ttotal: 7.94s\tremaining: 13s\n",
      "379:\tlearn: 31.9428943\ttotal: 7.96s\tremaining: 13s\n",
      "380:\tlearn: 31.9248793\ttotal: 7.98s\tremaining: 13s\n",
      "381:\tlearn: 31.9029888\ttotal: 8s\tremaining: 12.9s\n",
      "382:\tlearn: 31.9003532\ttotal: 8.02s\tremaining: 12.9s\n",
      "383:\tlearn: 31.8849428\ttotal: 8.03s\tremaining: 12.9s\n",
      "384:\tlearn: 31.8725141\ttotal: 8.05s\tremaining: 12.9s\n",
      "385:\tlearn: 31.8678430\ttotal: 8.07s\tremaining: 12.8s\n",
      "386:\tlearn: 31.8514462\ttotal: 8.09s\tremaining: 12.8s\n",
      "387:\tlearn: 31.8173517\ttotal: 8.11s\tremaining: 12.8s\n",
      "388:\tlearn: 31.8119215\ttotal: 8.13s\tremaining: 12.8s\n",
      "389:\tlearn: 31.7922290\ttotal: 8.15s\tremaining: 12.8s\n",
      "390:\tlearn: 31.7840312\ttotal: 8.17s\tremaining: 12.7s\n",
      "391:\tlearn: 31.7651127\ttotal: 8.19s\tremaining: 12.7s\n",
      "392:\tlearn: 31.7638471\ttotal: 8.21s\tremaining: 12.7s\n",
      "393:\tlearn: 31.7317842\ttotal: 8.23s\tremaining: 12.7s\n",
      "394:\tlearn: 31.7114092\ttotal: 8.25s\tremaining: 12.6s\n",
      "395:\tlearn: 31.6742588\ttotal: 8.27s\tremaining: 12.6s\n",
      "396:\tlearn: 31.6653656\ttotal: 8.29s\tremaining: 12.6s\n",
      "397:\tlearn: 31.6584048\ttotal: 8.31s\tremaining: 12.6s\n",
      "398:\tlearn: 31.6429626\ttotal: 8.33s\tremaining: 12.5s\n",
      "399:\tlearn: 31.6357309\ttotal: 8.35s\tremaining: 12.5s\n",
      "400:\tlearn: 31.6053642\ttotal: 8.37s\tremaining: 12.5s\n",
      "401:\tlearn: 31.5979228\ttotal: 8.39s\tremaining: 12.5s\n",
      "402:\tlearn: 31.5876854\ttotal: 8.4s\tremaining: 12.4s\n",
      "403:\tlearn: 31.5829152\ttotal: 8.42s\tremaining: 12.4s\n",
      "404:\tlearn: 31.5149838\ttotal: 8.45s\tremaining: 12.4s\n",
      "405:\tlearn: 31.4897154\ttotal: 8.47s\tremaining: 12.4s\n",
      "406:\tlearn: 31.4853770\ttotal: 8.49s\tremaining: 12.4s\n",
      "407:\tlearn: 31.4790702\ttotal: 8.51s\tremaining: 12.3s\n",
      "408:\tlearn: 31.4638963\ttotal: 8.53s\tremaining: 12.3s\n",
      "409:\tlearn: 31.4610320\ttotal: 8.55s\tremaining: 12.3s\n",
      "410:\tlearn: 31.4208972\ttotal: 8.57s\tremaining: 12.3s\n",
      "411:\tlearn: 31.4061589\ttotal: 8.59s\tremaining: 12.3s\n",
      "412:\tlearn: 31.4035508\ttotal: 8.61s\tremaining: 12.2s\n",
      "413:\tlearn: 31.3488080\ttotal: 8.63s\tremaining: 12.2s\n",
      "414:\tlearn: 31.3319801\ttotal: 8.65s\tremaining: 12.2s\n",
      "415:\tlearn: 31.3284816\ttotal: 8.67s\tremaining: 12.2s\n",
      "416:\tlearn: 31.3223349\ttotal: 8.69s\tremaining: 12.1s\n",
      "417:\tlearn: 31.3051583\ttotal: 8.71s\tremaining: 12.1s\n",
      "418:\tlearn: 31.3016500\ttotal: 8.73s\tremaining: 12.1s\n",
      "419:\tlearn: 31.2945162\ttotal: 8.75s\tremaining: 12.1s\n",
      "420:\tlearn: 31.2765456\ttotal: 8.77s\tremaining: 12.1s\n",
      "421:\tlearn: 31.2626008\ttotal: 8.79s\tremaining: 12s\n",
      "422:\tlearn: 31.2548738\ttotal: 8.81s\tremaining: 12s\n",
      "423:\tlearn: 31.2401909\ttotal: 8.83s\tremaining: 12s\n",
      "424:\tlearn: 31.2374451\ttotal: 8.85s\tremaining: 12s\n",
      "425:\tlearn: 31.2083561\ttotal: 8.87s\tremaining: 12s\n",
      "426:\tlearn: 31.1827860\ttotal: 8.89s\tremaining: 11.9s\n",
      "427:\tlearn: 31.1822023\ttotal: 8.9s\tremaining: 11.9s\n",
      "428:\tlearn: 31.1555181\ttotal: 8.93s\tremaining: 11.9s\n",
      "429:\tlearn: 31.1372951\ttotal: 8.94s\tremaining: 11.9s\n",
      "430:\tlearn: 31.0420920\ttotal: 8.97s\tremaining: 11.8s\n",
      "431:\tlearn: 31.0399043\ttotal: 8.98s\tremaining: 11.8s\n",
      "432:\tlearn: 31.0383751\ttotal: 9s\tremaining: 11.8s\n",
      "433:\tlearn: 31.0351540\ttotal: 9.02s\tremaining: 11.8s\n",
      "434:\tlearn: 31.0297957\ttotal: 9.04s\tremaining: 11.7s\n",
      "435:\tlearn: 31.0277865\ttotal: 9.06s\tremaining: 11.7s\n",
      "436:\tlearn: 31.0124349\ttotal: 9.08s\tremaining: 11.7s\n",
      "437:\tlearn: 30.9849196\ttotal: 9.1s\tremaining: 11.7s\n",
      "438:\tlearn: 30.9747052\ttotal: 9.12s\tremaining: 11.7s\n",
      "439:\tlearn: 30.9716984\ttotal: 9.14s\tremaining: 11.6s\n",
      "440:\tlearn: 30.9695194\ttotal: 9.16s\tremaining: 11.6s\n",
      "441:\tlearn: 30.9507746\ttotal: 9.18s\tremaining: 11.6s\n",
      "442:\tlearn: 30.9424954\ttotal: 9.2s\tremaining: 11.6s\n",
      "443:\tlearn: 30.9393215\ttotal: 9.22s\tremaining: 11.5s\n",
      "444:\tlearn: 30.9338122\ttotal: 9.24s\tremaining: 11.5s\n",
      "445:\tlearn: 30.9280948\ttotal: 9.26s\tremaining: 11.5s\n",
      "446:\tlearn: 30.9104825\ttotal: 9.28s\tremaining: 11.5s\n",
      "447:\tlearn: 30.9088484\ttotal: 9.3s\tremaining: 11.5s\n",
      "448:\tlearn: 30.9056488\ttotal: 9.32s\tremaining: 11.4s\n",
      "449:\tlearn: 30.9034590\ttotal: 9.34s\tremaining: 11.4s\n",
      "450:\tlearn: 30.8904355\ttotal: 9.35s\tremaining: 11.4s\n",
      "451:\tlearn: 30.8890987\ttotal: 9.38s\tremaining: 11.4s\n",
      "452:\tlearn: 30.8853070\ttotal: 9.4s\tremaining: 11.4s\n",
      "453:\tlearn: 30.8811565\ttotal: 9.43s\tremaining: 11.3s\n",
      "454:\tlearn: 30.8575666\ttotal: 9.45s\tremaining: 11.3s\n",
      "455:\tlearn: 30.8543006\ttotal: 9.48s\tremaining: 11.3s\n",
      "456:\tlearn: 30.8286238\ttotal: 9.5s\tremaining: 11.3s\n",
      "457:\tlearn: 30.8143171\ttotal: 9.52s\tremaining: 11.3s\n",
      "458:\tlearn: 30.7579821\ttotal: 9.55s\tremaining: 11.3s\n",
      "459:\tlearn: 30.7566994\ttotal: 9.57s\tremaining: 11.2s\n",
      "460:\tlearn: 30.7526401\ttotal: 9.59s\tremaining: 11.2s\n",
      "461:\tlearn: 30.7394870\ttotal: 9.61s\tremaining: 11.2s\n",
      "462:\tlearn: 30.7383462\ttotal: 9.63s\tremaining: 11.2s\n",
      "463:\tlearn: 30.6661782\ttotal: 9.66s\tremaining: 11.2s\n",
      "464:\tlearn: 30.6641093\ttotal: 9.68s\tremaining: 11.1s\n",
      "465:\tlearn: 30.6406226\ttotal: 9.7s\tremaining: 11.1s\n",
      "466:\tlearn: 30.6321136\ttotal: 9.72s\tremaining: 11.1s\n",
      "467:\tlearn: 30.6054366\ttotal: 9.75s\tremaining: 11.1s\n",
      "468:\tlearn: 30.5651781\ttotal: 9.77s\tremaining: 11.1s\n",
      "469:\tlearn: 30.5386464\ttotal: 9.79s\tremaining: 11s\n",
      "470:\tlearn: 30.5206632\ttotal: 9.82s\tremaining: 11s\n",
      "471:\tlearn: 30.5192431\ttotal: 9.83s\tremaining: 11s\n",
      "472:\tlearn: 30.5175081\ttotal: 9.85s\tremaining: 11s\n",
      "473:\tlearn: 30.4901971\ttotal: 9.88s\tremaining: 11s\n",
      "474:\tlearn: 30.4798619\ttotal: 9.9s\tremaining: 10.9s\n",
      "475:\tlearn: 30.4733786\ttotal: 9.92s\tremaining: 10.9s\n",
      "476:\tlearn: 30.4669216\ttotal: 9.94s\tremaining: 10.9s\n",
      "477:\tlearn: 30.4654706\ttotal: 9.96s\tremaining: 10.9s\n",
      "478:\tlearn: 30.4623662\ttotal: 9.98s\tremaining: 10.9s\n",
      "479:\tlearn: 30.4619016\ttotal: 9.99s\tremaining: 10.8s\n",
      "480:\tlearn: 30.4600298\ttotal: 10s\tremaining: 10.8s\n",
      "481:\tlearn: 30.4489237\ttotal: 10s\tremaining: 10.8s\n",
      "482:\tlearn: 30.4477204\ttotal: 10s\tremaining: 10.8s\n",
      "483:\tlearn: 30.4463497\ttotal: 10.1s\tremaining: 10.7s\n",
      "484:\tlearn: 30.4438779\ttotal: 10.1s\tremaining: 10.7s\n",
      "485:\tlearn: 30.4351420\ttotal: 10.1s\tremaining: 10.7s\n",
      "486:\tlearn: 30.4341941\ttotal: 10.1s\tremaining: 10.7s\n",
      "487:\tlearn: 30.4288018\ttotal: 10.1s\tremaining: 10.6s\n",
      "488:\tlearn: 30.4141145\ttotal: 10.2s\tremaining: 10.6s\n",
      "489:\tlearn: 30.4080697\ttotal: 10.2s\tremaining: 10.6s\n",
      "490:\tlearn: 30.3973849\ttotal: 10.2s\tremaining: 10.6s\n",
      "491:\tlearn: 30.3809788\ttotal: 10.2s\tremaining: 10.6s\n",
      "492:\tlearn: 30.3224650\ttotal: 10.3s\tremaining: 10.6s\n",
      "493:\tlearn: 30.3192174\ttotal: 10.3s\tremaining: 10.5s\n",
      "494:\tlearn: 30.3154680\ttotal: 10.3s\tremaining: 10.5s\n",
      "495:\tlearn: 30.2685774\ttotal: 10.3s\tremaining: 10.5s\n",
      "496:\tlearn: 30.2528895\ttotal: 10.3s\tremaining: 10.5s\n",
      "497:\tlearn: 30.2513709\ttotal: 10.4s\tremaining: 10.4s\n",
      "498:\tlearn: 30.2498756\ttotal: 10.4s\tremaining: 10.4s\n",
      "499:\tlearn: 30.2311797\ttotal: 10.4s\tremaining: 10.4s\n",
      "500:\tlearn: 30.2169072\ttotal: 10.4s\tremaining: 10.4s\n",
      "501:\tlearn: 30.1894964\ttotal: 10.4s\tremaining: 10.4s\n",
      "502:\tlearn: 30.1829354\ttotal: 10.5s\tremaining: 10.3s\n",
      "503:\tlearn: 30.1810057\ttotal: 10.5s\tremaining: 10.3s\n",
      "504:\tlearn: 30.1798577\ttotal: 10.5s\tremaining: 10.3s\n",
      "505:\tlearn: 30.1611761\ttotal: 10.5s\tremaining: 10.3s\n",
      "506:\tlearn: 30.1482755\ttotal: 10.5s\tremaining: 10.3s\n",
      "507:\tlearn: 30.1313850\ttotal: 10.6s\tremaining: 10.2s\n",
      "508:\tlearn: 30.1275947\ttotal: 10.6s\tremaining: 10.2s\n",
      "509:\tlearn: 30.1237233\ttotal: 10.6s\tremaining: 10.2s\n",
      "510:\tlearn: 30.0938548\ttotal: 10.6s\tremaining: 10.2s\n",
      "511:\tlearn: 30.0924625\ttotal: 10.7s\tremaining: 10.2s\n",
      "512:\tlearn: 30.0912483\ttotal: 10.7s\tremaining: 10.1s\n",
      "513:\tlearn: 30.0816261\ttotal: 10.7s\tremaining: 10.1s\n",
      "514:\tlearn: 30.0804449\ttotal: 10.7s\tremaining: 10.1s\n",
      "515:\tlearn: 30.0746807\ttotal: 10.7s\tremaining: 10.1s\n",
      "516:\tlearn: 30.0616680\ttotal: 10.8s\tremaining: 10s\n",
      "517:\tlearn: 30.0562685\ttotal: 10.8s\tremaining: 10s\n",
      "518:\tlearn: 30.0475941\ttotal: 10.8s\tremaining: 10s\n",
      "519:\tlearn: 30.0231323\ttotal: 10.8s\tremaining: 9.98s\n",
      "520:\tlearn: 30.0136872\ttotal: 10.8s\tremaining: 9.96s\n",
      "521:\tlearn: 30.0008841\ttotal: 10.9s\tremaining: 9.94s\n",
      "522:\tlearn: 29.9691554\ttotal: 10.9s\tremaining: 9.92s\n",
      "523:\tlearn: 29.9687972\ttotal: 10.9s\tremaining: 9.89s\n",
      "524:\tlearn: 29.9311762\ttotal: 10.9s\tremaining: 9.89s\n",
      "525:\tlearn: 29.9074916\ttotal: 11s\tremaining: 9.89s\n",
      "526:\tlearn: 29.9054688\ttotal: 11s\tremaining: 9.87s\n",
      "527:\tlearn: 29.9036922\ttotal: 11s\tremaining: 9.85s\n",
      "528:\tlearn: 29.8973634\ttotal: 11s\tremaining: 9.82s\n",
      "529:\tlearn: 29.8899228\ttotal: 11.1s\tremaining: 9.8s\n",
      "530:\tlearn: 29.8844875\ttotal: 11.1s\tremaining: 9.78s\n",
      "531:\tlearn: 29.8686632\ttotal: 11.1s\tremaining: 9.76s\n",
      "532:\tlearn: 29.8451542\ttotal: 11.1s\tremaining: 9.74s\n",
      "533:\tlearn: 29.8169881\ttotal: 11.1s\tremaining: 9.71s\n",
      "534:\tlearn: 29.8074030\ttotal: 11.2s\tremaining: 9.7s\n",
      "535:\tlearn: 29.7945416\ttotal: 11.2s\tremaining: 9.68s\n",
      "536:\tlearn: 29.7927071\ttotal: 11.2s\tremaining: 9.66s\n",
      "537:\tlearn: 29.7867025\ttotal: 11.2s\tremaining: 9.64s\n",
      "538:\tlearn: 29.7615530\ttotal: 11.2s\tremaining: 9.62s\n",
      "539:\tlearn: 29.7520280\ttotal: 11.3s\tremaining: 9.59s\n",
      "540:\tlearn: 29.7500070\ttotal: 11.3s\tremaining: 9.58s\n",
      "541:\tlearn: 29.7247010\ttotal: 11.3s\tremaining: 9.55s\n",
      "542:\tlearn: 29.7231868\ttotal: 11.3s\tremaining: 9.53s\n",
      "543:\tlearn: 29.7207595\ttotal: 11.3s\tremaining: 9.51s\n",
      "544:\tlearn: 29.7191953\ttotal: 11.4s\tremaining: 9.49s\n",
      "545:\tlearn: 29.7177866\ttotal: 11.4s\tremaining: 9.47s\n",
      "546:\tlearn: 29.7142224\ttotal: 11.4s\tremaining: 9.45s\n",
      "547:\tlearn: 29.6947991\ttotal: 11.4s\tremaining: 9.43s\n",
      "548:\tlearn: 29.6945118\ttotal: 11.4s\tremaining: 9.4s\n",
      "549:\tlearn: 29.6922761\ttotal: 11.5s\tremaining: 9.38s\n",
      "550:\tlearn: 29.6766209\ttotal: 11.5s\tremaining: 9.36s\n",
      "551:\tlearn: 29.6057316\ttotal: 11.5s\tremaining: 9.34s\n",
      "552:\tlearn: 29.5947591\ttotal: 11.5s\tremaining: 9.32s\n",
      "553:\tlearn: 29.5909342\ttotal: 11.6s\tremaining: 9.3s\n",
      "554:\tlearn: 29.5785343\ttotal: 11.6s\tremaining: 9.28s\n",
      "555:\tlearn: 29.5587326\ttotal: 11.6s\tremaining: 9.26s\n",
      "556:\tlearn: 29.4818701\ttotal: 11.6s\tremaining: 9.24s\n",
      "557:\tlearn: 29.4799674\ttotal: 11.6s\tremaining: 9.22s\n",
      "558:\tlearn: 29.4790866\ttotal: 11.7s\tremaining: 9.2s\n",
      "559:\tlearn: 29.4666027\ttotal: 11.7s\tremaining: 9.18s\n",
      "560:\tlearn: 29.4644360\ttotal: 11.7s\tremaining: 9.16s\n",
      "561:\tlearn: 29.4618275\ttotal: 11.7s\tremaining: 9.14s\n",
      "562:\tlearn: 29.4612784\ttotal: 11.7s\tremaining: 9.11s\n",
      "563:\tlearn: 29.4323184\ttotal: 11.8s\tremaining: 9.09s\n",
      "564:\tlearn: 29.4268852\ttotal: 11.8s\tremaining: 9.07s\n",
      "565:\tlearn: 29.4249277\ttotal: 11.8s\tremaining: 9.05s\n",
      "566:\tlearn: 29.3756435\ttotal: 11.8s\tremaining: 9.03s\n",
      "567:\tlearn: 29.3744089\ttotal: 11.8s\tremaining: 9.01s\n",
      "568:\tlearn: 29.3582955\ttotal: 11.9s\tremaining: 8.99s\n",
      "569:\tlearn: 29.3557237\ttotal: 11.9s\tremaining: 8.97s\n",
      "570:\tlearn: 29.3449400\ttotal: 11.9s\tremaining: 8.95s\n",
      "571:\tlearn: 29.3311508\ttotal: 11.9s\tremaining: 8.93s\n",
      "572:\tlearn: 29.3276452\ttotal: 12s\tremaining: 8.91s\n",
      "573:\tlearn: 29.3252122\ttotal: 12s\tremaining: 8.89s\n",
      "574:\tlearn: 29.3236469\ttotal: 12s\tremaining: 8.87s\n",
      "575:\tlearn: 29.3191154\ttotal: 12s\tremaining: 8.85s\n",
      "576:\tlearn: 29.2923153\ttotal: 12s\tremaining: 8.83s\n",
      "577:\tlearn: 29.2889358\ttotal: 12.1s\tremaining: 8.81s\n",
      "578:\tlearn: 29.2768925\ttotal: 12.1s\tremaining: 8.79s\n",
      "579:\tlearn: 29.2555785\ttotal: 12.1s\tremaining: 8.77s\n",
      "580:\tlearn: 29.2505616\ttotal: 12.1s\tremaining: 8.75s\n",
      "581:\tlearn: 29.2152962\ttotal: 12.2s\tremaining: 8.73s\n",
      "582:\tlearn: 29.1842413\ttotal: 12.2s\tremaining: 8.71s\n",
      "583:\tlearn: 29.1545697\ttotal: 12.2s\tremaining: 8.69s\n",
      "584:\tlearn: 29.1236184\ttotal: 12.2s\tremaining: 8.67s\n",
      "585:\tlearn: 29.1122780\ttotal: 12.2s\tremaining: 8.65s\n",
      "586:\tlearn: 29.0984720\ttotal: 12.3s\tremaining: 8.63s\n",
      "587:\tlearn: 29.0970790\ttotal: 12.3s\tremaining: 8.61s\n",
      "588:\tlearn: 29.0741149\ttotal: 12.3s\tremaining: 8.59s\n",
      "589:\tlearn: 29.0663637\ttotal: 12.3s\tremaining: 8.57s\n",
      "590:\tlearn: 29.0651948\ttotal: 12.3s\tremaining: 8.54s\n",
      "591:\tlearn: 29.0575281\ttotal: 12.4s\tremaining: 8.52s\n",
      "592:\tlearn: 29.0414401\ttotal: 12.4s\tremaining: 8.5s\n",
      "593:\tlearn: 29.0400600\ttotal: 12.4s\tremaining: 8.48s\n",
      "594:\tlearn: 29.0388700\ttotal: 12.4s\tremaining: 8.45s\n",
      "595:\tlearn: 29.0379921\ttotal: 12.4s\tremaining: 8.43s\n",
      "596:\tlearn: 29.0192989\ttotal: 12.5s\tremaining: 8.41s\n",
      "597:\tlearn: 29.0172853\ttotal: 12.5s\tremaining: 8.39s\n",
      "598:\tlearn: 28.9730783\ttotal: 12.5s\tremaining: 8.37s\n",
      "599:\tlearn: 28.9568737\ttotal: 12.5s\tremaining: 8.35s\n",
      "600:\tlearn: 28.9561018\ttotal: 12.5s\tremaining: 8.33s\n",
      "601:\tlearn: 28.9547009\ttotal: 12.6s\tremaining: 8.31s\n",
      "602:\tlearn: 28.9515034\ttotal: 12.6s\tremaining: 8.28s\n",
      "603:\tlearn: 28.9426761\ttotal: 12.6s\tremaining: 8.26s\n",
      "604:\tlearn: 28.9413791\ttotal: 12.6s\tremaining: 8.24s\n",
      "605:\tlearn: 28.9402361\ttotal: 12.6s\tremaining: 8.22s\n",
      "606:\tlearn: 28.9389708\ttotal: 12.7s\tremaining: 8.2s\n",
      "607:\tlearn: 28.9271244\ttotal: 12.7s\tremaining: 8.18s\n",
      "608:\tlearn: 28.9222719\ttotal: 12.7s\tremaining: 8.16s\n",
      "609:\tlearn: 28.8739247\ttotal: 12.7s\tremaining: 8.14s\n",
      "610:\tlearn: 28.8588408\ttotal: 12.8s\tremaining: 8.12s\n",
      "611:\tlearn: 28.8566445\ttotal: 12.8s\tremaining: 8.1s\n",
      "612:\tlearn: 28.8409441\ttotal: 12.8s\tremaining: 8.08s\n",
      "613:\tlearn: 28.7666588\ttotal: 12.8s\tremaining: 8.06s\n",
      "614:\tlearn: 28.7544986\ttotal: 12.8s\tremaining: 8.04s\n",
      "615:\tlearn: 28.7299667\ttotal: 12.9s\tremaining: 8.02s\n",
      "616:\tlearn: 28.7184304\ttotal: 12.9s\tremaining: 8s\n",
      "617:\tlearn: 28.6761208\ttotal: 12.9s\tremaining: 7.98s\n",
      "618:\tlearn: 28.6688966\ttotal: 12.9s\tremaining: 7.96s\n",
      "619:\tlearn: 28.6423493\ttotal: 13s\tremaining: 7.94s\n",
      "620:\tlearn: 28.6287090\ttotal: 13s\tremaining: 7.92s\n",
      "621:\tlearn: 28.6189202\ttotal: 13s\tremaining: 7.9s\n",
      "622:\tlearn: 28.6041636\ttotal: 13s\tremaining: 7.88s\n",
      "623:\tlearn: 28.6019129\ttotal: 13s\tremaining: 7.86s\n",
      "624:\tlearn: 28.5924628\ttotal: 13.1s\tremaining: 7.83s\n",
      "625:\tlearn: 28.5906641\ttotal: 13.1s\tremaining: 7.81s\n",
      "626:\tlearn: 28.5837996\ttotal: 13.1s\tremaining: 7.79s\n",
      "627:\tlearn: 28.5828511\ttotal: 13.1s\tremaining: 7.77s\n",
      "628:\tlearn: 28.5819091\ttotal: 13.1s\tremaining: 7.75s\n",
      "629:\tlearn: 28.5632886\ttotal: 13.2s\tremaining: 7.72s\n",
      "630:\tlearn: 28.5609039\ttotal: 13.2s\tremaining: 7.7s\n",
      "631:\tlearn: 28.5524735\ttotal: 13.2s\tremaining: 7.68s\n",
      "632:\tlearn: 28.5376841\ttotal: 13.2s\tremaining: 7.66s\n",
      "633:\tlearn: 28.5341303\ttotal: 13.2s\tremaining: 7.64s\n",
      "634:\tlearn: 28.5270197\ttotal: 13.2s\tremaining: 7.61s\n",
      "635:\tlearn: 28.4893227\ttotal: 13.3s\tremaining: 7.59s\n",
      "636:\tlearn: 28.4809263\ttotal: 13.3s\tremaining: 7.58s\n",
      "637:\tlearn: 28.4685009\ttotal: 13.3s\tremaining: 7.55s\n",
      "638:\tlearn: 28.4467041\ttotal: 13.3s\tremaining: 7.54s\n",
      "639:\tlearn: 28.4307531\ttotal: 13.4s\tremaining: 7.52s\n",
      "640:\tlearn: 28.4296413\ttotal: 13.4s\tremaining: 7.5s\n",
      "641:\tlearn: 28.4115426\ttotal: 13.4s\tremaining: 7.48s\n",
      "642:\tlearn: 28.4113157\ttotal: 13.4s\tremaining: 7.45s\n",
      "643:\tlearn: 28.4106845\ttotal: 13.4s\tremaining: 7.43s\n",
      "644:\tlearn: 28.4021691\ttotal: 13.5s\tremaining: 7.41s\n",
      "645:\tlearn: 28.3956424\ttotal: 13.5s\tremaining: 7.39s\n",
      "646:\tlearn: 28.3946808\ttotal: 13.5s\tremaining: 7.36s\n",
      "647:\tlearn: 28.3790367\ttotal: 13.5s\tremaining: 7.34s\n",
      "648:\tlearn: 28.3623149\ttotal: 13.5s\tremaining: 7.33s\n",
      "649:\tlearn: 28.3447709\ttotal: 13.6s\tremaining: 7.3s\n",
      "650:\tlearn: 28.3352698\ttotal: 13.6s\tremaining: 7.29s\n",
      "651:\tlearn: 28.3272015\ttotal: 13.6s\tremaining: 7.26s\n",
      "652:\tlearn: 28.3221878\ttotal: 13.6s\tremaining: 7.24s\n",
      "653:\tlearn: 28.3144520\ttotal: 13.7s\tremaining: 7.22s\n",
      "654:\tlearn: 28.3078665\ttotal: 13.7s\tremaining: 7.2s\n",
      "655:\tlearn: 28.2936501\ttotal: 13.7s\tremaining: 7.18s\n",
      "656:\tlearn: 28.2785917\ttotal: 13.7s\tremaining: 7.16s\n",
      "657:\tlearn: 28.2767423\ttotal: 13.7s\tremaining: 7.14s\n",
      "658:\tlearn: 28.2631270\ttotal: 13.8s\tremaining: 7.12s\n",
      "659:\tlearn: 28.2104532\ttotal: 13.8s\tremaining: 7.11s\n",
      "660:\tlearn: 28.1985342\ttotal: 13.8s\tremaining: 7.08s\n",
      "661:\tlearn: 28.1912445\ttotal: 13.8s\tremaining: 7.06s\n",
      "662:\tlearn: 28.1892315\ttotal: 13.9s\tremaining: 7.04s\n",
      "663:\tlearn: 28.1879464\ttotal: 13.9s\tremaining: 7.02s\n",
      "664:\tlearn: 28.1868319\ttotal: 13.9s\tremaining: 7s\n",
      "665:\tlearn: 28.1817405\ttotal: 13.9s\tremaining: 6.97s\n",
      "666:\tlearn: 28.1799317\ttotal: 13.9s\tremaining: 6.96s\n",
      "667:\tlearn: 28.1659081\ttotal: 14s\tremaining: 6.93s\n",
      "668:\tlearn: 28.1639532\ttotal: 14s\tremaining: 6.92s\n",
      "669:\tlearn: 28.1478936\ttotal: 14s\tremaining: 6.89s\n",
      "670:\tlearn: 28.1373691\ttotal: 14s\tremaining: 6.88s\n",
      "671:\tlearn: 28.1278048\ttotal: 14s\tremaining: 6.85s\n",
      "672:\tlearn: 28.0917479\ttotal: 14.1s\tremaining: 6.84s\n",
      "673:\tlearn: 28.0910426\ttotal: 14.1s\tremaining: 6.81s\n",
      "674:\tlearn: 28.0790536\ttotal: 14.1s\tremaining: 6.79s\n",
      "675:\tlearn: 28.0646018\ttotal: 14.1s\tremaining: 6.77s\n",
      "676:\tlearn: 28.0597918\ttotal: 14.2s\tremaining: 6.75s\n",
      "677:\tlearn: 28.0578949\ttotal: 14.2s\tremaining: 6.73s\n",
      "678:\tlearn: 28.0501918\ttotal: 14.2s\tremaining: 6.71s\n",
      "679:\tlearn: 28.0412986\ttotal: 14.2s\tremaining: 6.69s\n",
      "680:\tlearn: 28.0330897\ttotal: 14.2s\tremaining: 6.67s\n",
      "681:\tlearn: 28.0304816\ttotal: 14.3s\tremaining: 6.65s\n",
      "682:\tlearn: 28.0086162\ttotal: 14.3s\tremaining: 6.63s\n",
      "683:\tlearn: 27.9979204\ttotal: 14.3s\tremaining: 6.61s\n",
      "684:\tlearn: 27.9745643\ttotal: 14.3s\tremaining: 6.58s\n",
      "685:\tlearn: 27.9506330\ttotal: 14.3s\tremaining: 6.57s\n",
      "686:\tlearn: 27.9491738\ttotal: 14.4s\tremaining: 6.54s\n",
      "687:\tlearn: 27.9468897\ttotal: 14.4s\tremaining: 6.53s\n",
      "688:\tlearn: 27.9462577\ttotal: 14.4s\tremaining: 6.5s\n",
      "689:\tlearn: 27.9398478\ttotal: 14.4s\tremaining: 6.48s\n",
      "690:\tlearn: 27.9341542\ttotal: 14.4s\tremaining: 6.46s\n",
      "691:\tlearn: 27.9326310\ttotal: 14.5s\tremaining: 6.44s\n",
      "692:\tlearn: 27.9314001\ttotal: 14.5s\tremaining: 6.42s\n",
      "693:\tlearn: 27.9157271\ttotal: 14.5s\tremaining: 6.4s\n",
      "694:\tlearn: 27.9141216\ttotal: 14.5s\tremaining: 6.37s\n",
      "695:\tlearn: 27.9013235\ttotal: 14.5s\tremaining: 6.35s\n",
      "696:\tlearn: 27.8994796\ttotal: 14.6s\tremaining: 6.33s\n",
      "697:\tlearn: 27.8924697\ttotal: 14.6s\tremaining: 6.31s\n",
      "698:\tlearn: 27.8700098\ttotal: 14.6s\tremaining: 6.29s\n",
      "699:\tlearn: 27.8574414\ttotal: 14.6s\tremaining: 6.27s\n",
      "700:\tlearn: 27.8527853\ttotal: 14.7s\tremaining: 6.25s\n",
      "701:\tlearn: 27.8495285\ttotal: 14.7s\tremaining: 6.23s\n",
      "702:\tlearn: 27.8435632\ttotal: 14.7s\tremaining: 6.21s\n",
      "703:\tlearn: 27.8423526\ttotal: 14.7s\tremaining: 6.18s\n",
      "704:\tlearn: 27.8389867\ttotal: 14.7s\tremaining: 6.16s\n",
      "705:\tlearn: 27.8229347\ttotal: 14.7s\tremaining: 6.14s\n",
      "706:\tlearn: 27.8171228\ttotal: 14.8s\tremaining: 6.12s\n",
      "707:\tlearn: 27.8134593\ttotal: 14.8s\tremaining: 6.1s\n",
      "708:\tlearn: 27.8125663\ttotal: 14.8s\tremaining: 6.08s\n",
      "709:\tlearn: 27.8114986\ttotal: 14.8s\tremaining: 6.05s\n",
      "710:\tlearn: 27.8102195\ttotal: 14.8s\tremaining: 6.03s\n",
      "711:\tlearn: 27.8050879\ttotal: 14.9s\tremaining: 6.01s\n",
      "712:\tlearn: 27.8032766\ttotal: 14.9s\tremaining: 5.99s\n",
      "713:\tlearn: 27.8016639\ttotal: 14.9s\tremaining: 5.97s\n",
      "714:\tlearn: 27.7994385\ttotal: 14.9s\tremaining: 5.95s\n",
      "715:\tlearn: 27.7869101\ttotal: 14.9s\tremaining: 5.93s\n",
      "716:\tlearn: 27.7153719\ttotal: 15s\tremaining: 5.91s\n",
      "717:\tlearn: 27.7147268\ttotal: 15s\tremaining: 5.88s\n",
      "718:\tlearn: 27.6862251\ttotal: 15s\tremaining: 5.87s\n",
      "719:\tlearn: 27.6844684\ttotal: 15s\tremaining: 5.84s\n",
      "720:\tlearn: 27.6830569\ttotal: 15.1s\tremaining: 5.83s\n",
      "721:\tlearn: 27.6755383\ttotal: 15.1s\tremaining: 5.8s\n",
      "722:\tlearn: 27.6709654\ttotal: 15.1s\tremaining: 5.79s\n",
      "723:\tlearn: 27.6618043\ttotal: 15.1s\tremaining: 5.76s\n",
      "724:\tlearn: 27.6606024\ttotal: 15.1s\tremaining: 5.74s\n",
      "725:\tlearn: 27.6592542\ttotal: 15.2s\tremaining: 5.72s\n",
      "726:\tlearn: 27.6541754\ttotal: 15.2s\tremaining: 5.7s\n",
      "727:\tlearn: 27.6362558\ttotal: 15.2s\tremaining: 5.68s\n",
      "728:\tlearn: 27.6262580\ttotal: 15.2s\tremaining: 5.66s\n",
      "729:\tlearn: 27.6231998\ttotal: 15.2s\tremaining: 5.64s\n",
      "730:\tlearn: 27.6221997\ttotal: 15.3s\tremaining: 5.62s\n",
      "731:\tlearn: 27.6018258\ttotal: 15.3s\tremaining: 5.6s\n",
      "732:\tlearn: 27.5897608\ttotal: 15.3s\tremaining: 5.58s\n",
      "733:\tlearn: 27.5871598\ttotal: 15.3s\tremaining: 5.56s\n",
      "734:\tlearn: 27.5868353\ttotal: 15.3s\tremaining: 5.53s\n",
      "735:\tlearn: 27.5860124\ttotal: 15.4s\tremaining: 5.51s\n",
      "736:\tlearn: 27.5848457\ttotal: 15.4s\tremaining: 5.49s\n",
      "737:\tlearn: 27.5794060\ttotal: 15.4s\tremaining: 5.47s\n",
      "738:\tlearn: 27.5781648\ttotal: 15.4s\tremaining: 5.45s\n",
      "739:\tlearn: 27.5739944\ttotal: 15.4s\tremaining: 5.43s\n",
      "740:\tlearn: 27.5330699\ttotal: 15.5s\tremaining: 5.41s\n",
      "741:\tlearn: 27.5310031\ttotal: 15.5s\tremaining: 5.39s\n",
      "742:\tlearn: 27.5295248\ttotal: 15.5s\tremaining: 5.37s\n",
      "743:\tlearn: 27.5288907\ttotal: 15.5s\tremaining: 5.34s\n",
      "744:\tlearn: 27.5273944\ttotal: 15.6s\tremaining: 5.32s\n",
      "745:\tlearn: 27.5270678\ttotal: 15.6s\tremaining: 5.3s\n",
      "746:\tlearn: 27.5257946\ttotal: 15.6s\tremaining: 5.28s\n",
      "747:\tlearn: 27.5225419\ttotal: 15.6s\tremaining: 5.26s\n",
      "748:\tlearn: 27.5136749\ttotal: 15.6s\tremaining: 5.24s\n",
      "749:\tlearn: 27.5046349\ttotal: 15.7s\tremaining: 5.22s\n",
      "750:\tlearn: 27.4945179\ttotal: 15.7s\tremaining: 5.2s\n",
      "751:\tlearn: 27.4811927\ttotal: 15.7s\tremaining: 5.18s\n",
      "752:\tlearn: 27.4775683\ttotal: 15.7s\tremaining: 5.16s\n",
      "753:\tlearn: 27.4366765\ttotal: 15.7s\tremaining: 5.14s\n",
      "754:\tlearn: 27.4294469\ttotal: 15.8s\tremaining: 5.12s\n",
      "755:\tlearn: 27.4243623\ttotal: 15.8s\tremaining: 5.09s\n",
      "756:\tlearn: 27.4112544\ttotal: 15.8s\tremaining: 5.07s\n",
      "757:\tlearn: 27.4010095\ttotal: 15.8s\tremaining: 5.05s\n",
      "758:\tlearn: 27.4000341\ttotal: 15.8s\tremaining: 5.03s\n",
      "759:\tlearn: 27.3995135\ttotal: 15.9s\tremaining: 5.01s\n",
      "760:\tlearn: 27.3965844\ttotal: 15.9s\tremaining: 4.99s\n",
      "761:\tlearn: 27.3942836\ttotal: 15.9s\tremaining: 4.97s\n",
      "762:\tlearn: 27.3931454\ttotal: 15.9s\tremaining: 4.95s\n",
      "763:\tlearn: 27.3861770\ttotal: 15.9s\tremaining: 4.93s\n",
      "764:\tlearn: 27.3856828\ttotal: 16s\tremaining: 4.9s\n",
      "765:\tlearn: 27.3797587\ttotal: 16s\tremaining: 4.88s\n",
      "766:\tlearn: 27.3788020\ttotal: 16s\tremaining: 4.86s\n",
      "767:\tlearn: 27.3778056\ttotal: 16s\tremaining: 4.84s\n",
      "768:\tlearn: 27.3706097\ttotal: 16s\tremaining: 4.82s\n",
      "769:\tlearn: 27.3683022\ttotal: 16.1s\tremaining: 4.8s\n",
      "770:\tlearn: 27.3465863\ttotal: 16.1s\tremaining: 4.78s\n",
      "771:\tlearn: 27.3459380\ttotal: 16.1s\tremaining: 4.76s\n",
      "772:\tlearn: 27.3379442\ttotal: 16.1s\tremaining: 4.74s\n",
      "773:\tlearn: 27.3362999\ttotal: 16.1s\tremaining: 4.71s\n",
      "774:\tlearn: 27.3342257\ttotal: 16.2s\tremaining: 4.69s\n",
      "775:\tlearn: 27.3334278\ttotal: 16.2s\tremaining: 4.67s\n",
      "776:\tlearn: 27.3323121\ttotal: 16.2s\tremaining: 4.65s\n",
      "777:\tlearn: 27.3306700\ttotal: 16.2s\tremaining: 4.63s\n",
      "778:\tlearn: 27.3191666\ttotal: 16.2s\tremaining: 4.61s\n",
      "779:\tlearn: 27.3134053\ttotal: 16.3s\tremaining: 4.59s\n",
      "780:\tlearn: 27.2952863\ttotal: 16.3s\tremaining: 4.57s\n",
      "781:\tlearn: 27.2941625\ttotal: 16.3s\tremaining: 4.55s\n",
      "782:\tlearn: 27.2918282\ttotal: 16.3s\tremaining: 4.53s\n",
      "783:\tlearn: 27.2904579\ttotal: 16.3s\tremaining: 4.5s\n",
      "784:\tlearn: 27.2761440\ttotal: 16.4s\tremaining: 4.48s\n",
      "785:\tlearn: 27.2655488\ttotal: 16.4s\tremaining: 4.46s\n",
      "786:\tlearn: 27.2645075\ttotal: 16.4s\tremaining: 4.44s\n",
      "787:\tlearn: 27.2631852\ttotal: 16.4s\tremaining: 4.42s\n",
      "788:\tlearn: 27.2360716\ttotal: 16.5s\tremaining: 4.4s\n",
      "789:\tlearn: 27.2345388\ttotal: 16.5s\tremaining: 4.38s\n",
      "790:\tlearn: 27.2331904\ttotal: 16.5s\tremaining: 4.36s\n",
      "791:\tlearn: 27.2068101\ttotal: 16.5s\tremaining: 4.34s\n",
      "792:\tlearn: 27.1943916\ttotal: 16.5s\tremaining: 4.32s\n",
      "793:\tlearn: 27.1859655\ttotal: 16.6s\tremaining: 4.3s\n",
      "794:\tlearn: 27.1846392\ttotal: 16.6s\tremaining: 4.28s\n",
      "795:\tlearn: 27.1833178\ttotal: 16.6s\tremaining: 4.26s\n",
      "796:\tlearn: 27.1788336\ttotal: 16.6s\tremaining: 4.24s\n",
      "797:\tlearn: 27.1703777\ttotal: 16.6s\tremaining: 4.21s\n",
      "798:\tlearn: 27.1689822\ttotal: 16.7s\tremaining: 4.19s\n",
      "799:\tlearn: 27.1466201\ttotal: 16.7s\tremaining: 4.17s\n",
      "800:\tlearn: 27.1456242\ttotal: 16.7s\tremaining: 4.15s\n",
      "801:\tlearn: 27.1344659\ttotal: 16.7s\tremaining: 4.13s\n",
      "802:\tlearn: 27.1256826\ttotal: 16.8s\tremaining: 4.11s\n",
      "803:\tlearn: 27.1067644\ttotal: 16.8s\tremaining: 4.11s\n",
      "804:\tlearn: 27.1047319\ttotal: 16.9s\tremaining: 4.08s\n",
      "805:\tlearn: 27.0932905\ttotal: 16.9s\tremaining: 4.07s\n",
      "806:\tlearn: 27.0924442\ttotal: 16.9s\tremaining: 4.04s\n",
      "807:\tlearn: 27.0867631\ttotal: 16.9s\tremaining: 4.02s\n",
      "808:\tlearn: 27.0438794\ttotal: 17s\tremaining: 4s\n",
      "809:\tlearn: 27.0427123\ttotal: 17s\tremaining: 3.98s\n",
      "810:\tlearn: 27.0407140\ttotal: 17s\tremaining: 3.96s\n",
      "811:\tlearn: 26.9796414\ttotal: 17s\tremaining: 3.94s\n",
      "812:\tlearn: 26.9652697\ttotal: 17s\tremaining: 3.92s\n",
      "813:\tlearn: 26.9601504\ttotal: 17.1s\tremaining: 3.9s\n",
      "814:\tlearn: 26.9590290\ttotal: 17.1s\tremaining: 3.88s\n",
      "815:\tlearn: 26.9445428\ttotal: 17.1s\tremaining: 3.86s\n",
      "816:\tlearn: 26.9211134\ttotal: 17.1s\tremaining: 3.84s\n",
      "817:\tlearn: 26.9193324\ttotal: 17.1s\tremaining: 3.81s\n",
      "818:\tlearn: 26.9185947\ttotal: 17.2s\tremaining: 3.79s\n",
      "819:\tlearn: 26.9170319\ttotal: 17.2s\tremaining: 3.77s\n",
      "820:\tlearn: 26.9156385\ttotal: 17.2s\tremaining: 3.75s\n",
      "821:\tlearn: 26.9082908\ttotal: 17.2s\tremaining: 3.73s\n",
      "822:\tlearn: 26.8918700\ttotal: 17.3s\tremaining: 3.71s\n",
      "823:\tlearn: 26.8833208\ttotal: 17.3s\tremaining: 3.69s\n",
      "824:\tlearn: 26.8826915\ttotal: 17.3s\tremaining: 3.67s\n",
      "825:\tlearn: 26.8807605\ttotal: 17.3s\tremaining: 3.65s\n",
      "826:\tlearn: 26.8790265\ttotal: 17.3s\tremaining: 3.63s\n",
      "827:\tlearn: 26.8784569\ttotal: 17.4s\tremaining: 3.6s\n",
      "828:\tlearn: 26.8717296\ttotal: 17.4s\tremaining: 3.58s\n",
      "829:\tlearn: 26.8715024\ttotal: 17.4s\tremaining: 3.56s\n",
      "830:\tlearn: 26.8657161\ttotal: 17.4s\tremaining: 3.54s\n",
      "831:\tlearn: 26.8614207\ttotal: 17.4s\tremaining: 3.52s\n",
      "832:\tlearn: 26.8506595\ttotal: 17.5s\tremaining: 3.5s\n",
      "833:\tlearn: 26.8496025\ttotal: 17.5s\tremaining: 3.48s\n",
      "834:\tlearn: 26.8438896\ttotal: 17.5s\tremaining: 3.46s\n",
      "835:\tlearn: 26.8302920\ttotal: 17.5s\tremaining: 3.44s\n",
      "836:\tlearn: 26.8297650\ttotal: 17.5s\tremaining: 3.41s\n",
      "837:\tlearn: 26.8180862\ttotal: 17.6s\tremaining: 3.39s\n",
      "838:\tlearn: 26.8171419\ttotal: 17.6s\tremaining: 3.37s\n",
      "839:\tlearn: 26.8165399\ttotal: 17.6s\tremaining: 3.35s\n",
      "840:\tlearn: 26.8156484\ttotal: 17.6s\tremaining: 3.33s\n",
      "841:\tlearn: 26.8122692\ttotal: 17.6s\tremaining: 3.31s\n",
      "842:\tlearn: 26.8110204\ttotal: 17.6s\tremaining: 3.29s\n",
      "843:\tlearn: 26.8098752\ttotal: 17.7s\tremaining: 3.26s\n",
      "844:\tlearn: 26.8085547\ttotal: 17.7s\tremaining: 3.24s\n",
      "845:\tlearn: 26.8003961\ttotal: 17.7s\tremaining: 3.22s\n",
      "846:\tlearn: 26.7994955\ttotal: 17.7s\tremaining: 3.2s\n",
      "847:\tlearn: 26.7975488\ttotal: 17.7s\tremaining: 3.18s\n",
      "848:\tlearn: 26.7892424\ttotal: 17.8s\tremaining: 3.16s\n",
      "849:\tlearn: 26.7874777\ttotal: 17.8s\tremaining: 3.14s\n",
      "850:\tlearn: 26.7864784\ttotal: 17.8s\tremaining: 3.12s\n",
      "851:\tlearn: 26.7851184\ttotal: 17.8s\tremaining: 3.1s\n",
      "852:\tlearn: 26.7842855\ttotal: 17.8s\tremaining: 3.08s\n",
      "853:\tlearn: 26.7758546\ttotal: 17.9s\tremaining: 3.05s\n",
      "854:\tlearn: 26.7466695\ttotal: 17.9s\tremaining: 3.03s\n",
      "855:\tlearn: 26.7458285\ttotal: 17.9s\tremaining: 3.01s\n",
      "856:\tlearn: 26.7442564\ttotal: 17.9s\tremaining: 2.99s\n",
      "857:\tlearn: 26.7427335\ttotal: 18s\tremaining: 2.97s\n",
      "858:\tlearn: 26.7405185\ttotal: 18s\tremaining: 2.95s\n",
      "859:\tlearn: 26.7389699\ttotal: 18s\tremaining: 2.93s\n",
      "860:\tlearn: 26.7278570\ttotal: 18s\tremaining: 2.91s\n",
      "861:\tlearn: 26.7228267\ttotal: 18s\tremaining: 2.89s\n",
      "862:\tlearn: 26.7222706\ttotal: 18.1s\tremaining: 2.87s\n",
      "863:\tlearn: 26.7188698\ttotal: 18.1s\tremaining: 2.85s\n",
      "864:\tlearn: 26.7170724\ttotal: 18.1s\tremaining: 2.83s\n",
      "865:\tlearn: 26.7148542\ttotal: 18.1s\tremaining: 2.8s\n",
      "866:\tlearn: 26.7140656\ttotal: 18.1s\tremaining: 2.78s\n",
      "867:\tlearn: 26.7128449\ttotal: 18.2s\tremaining: 2.76s\n",
      "868:\tlearn: 26.7069346\ttotal: 18.2s\tremaining: 2.74s\n",
      "869:\tlearn: 26.7002991\ttotal: 18.2s\tremaining: 2.72s\n",
      "870:\tlearn: 26.6826237\ttotal: 18.2s\tremaining: 2.7s\n",
      "871:\tlearn: 26.6719988\ttotal: 18.2s\tremaining: 2.68s\n",
      "872:\tlearn: 26.6585410\ttotal: 18.3s\tremaining: 2.66s\n",
      "873:\tlearn: 26.6289217\ttotal: 18.3s\tremaining: 2.63s\n",
      "874:\tlearn: 26.6195962\ttotal: 18.3s\tremaining: 2.61s\n",
      "875:\tlearn: 26.6176970\ttotal: 18.3s\tremaining: 2.59s\n",
      "876:\tlearn: 26.5904146\ttotal: 18.3s\tremaining: 2.57s\n",
      "877:\tlearn: 26.5898330\ttotal: 18.4s\tremaining: 2.55s\n",
      "878:\tlearn: 26.5726846\ttotal: 18.4s\tremaining: 2.53s\n",
      "879:\tlearn: 26.5715746\ttotal: 18.4s\tremaining: 2.51s\n",
      "880:\tlearn: 26.5706248\ttotal: 18.4s\tremaining: 2.49s\n",
      "881:\tlearn: 26.5624567\ttotal: 18.4s\tremaining: 2.47s\n",
      "882:\tlearn: 26.5514280\ttotal: 18.5s\tremaining: 2.45s\n",
      "883:\tlearn: 26.5188444\ttotal: 18.5s\tremaining: 2.43s\n",
      "884:\tlearn: 26.5160660\ttotal: 18.5s\tremaining: 2.4s\n",
      "885:\tlearn: 26.4936174\ttotal: 18.5s\tremaining: 2.38s\n",
      "886:\tlearn: 26.4849623\ttotal: 18.5s\tremaining: 2.36s\n",
      "887:\tlearn: 26.4487129\ttotal: 18.6s\tremaining: 2.34s\n",
      "888:\tlearn: 26.4465418\ttotal: 18.6s\tremaining: 2.32s\n",
      "889:\tlearn: 26.4261662\ttotal: 18.6s\tremaining: 2.3s\n",
      "890:\tlearn: 26.4207777\ttotal: 18.6s\tremaining: 2.28s\n",
      "891:\tlearn: 26.4167152\ttotal: 18.7s\tremaining: 2.26s\n",
      "892:\tlearn: 26.4085572\ttotal: 18.7s\tremaining: 2.24s\n",
      "893:\tlearn: 26.3962677\ttotal: 18.7s\tremaining: 2.22s\n",
      "894:\tlearn: 26.3890773\ttotal: 18.7s\tremaining: 2.2s\n",
      "895:\tlearn: 26.3886263\ttotal: 18.7s\tremaining: 2.17s\n",
      "896:\tlearn: 26.3841192\ttotal: 18.8s\tremaining: 2.15s\n",
      "897:\tlearn: 26.3834416\ttotal: 18.8s\tremaining: 2.13s\n",
      "898:\tlearn: 26.3765636\ttotal: 18.8s\tremaining: 2.11s\n",
      "899:\tlearn: 26.3756069\ttotal: 18.8s\tremaining: 2.09s\n",
      "900:\tlearn: 26.3666790\ttotal: 18.9s\tremaining: 2.07s\n",
      "901:\tlearn: 26.3656607\ttotal: 18.9s\tremaining: 2.05s\n",
      "902:\tlearn: 26.3500255\ttotal: 18.9s\tremaining: 2.03s\n",
      "903:\tlearn: 26.3273183\ttotal: 18.9s\tremaining: 2.01s\n",
      "904:\tlearn: 26.3171436\ttotal: 18.9s\tremaining: 1.99s\n",
      "905:\tlearn: 26.3162625\ttotal: 19s\tremaining: 1.97s\n",
      "906:\tlearn: 26.3063552\ttotal: 19s\tremaining: 1.95s\n",
      "907:\tlearn: 26.2988600\ttotal: 19s\tremaining: 1.92s\n",
      "908:\tlearn: 26.2976511\ttotal: 19s\tremaining: 1.9s\n",
      "909:\tlearn: 26.2968742\ttotal: 19s\tremaining: 1.88s\n",
      "910:\tlearn: 26.2902751\ttotal: 19.1s\tremaining: 1.86s\n",
      "911:\tlearn: 26.2890485\ttotal: 19.1s\tremaining: 1.84s\n",
      "912:\tlearn: 26.2884592\ttotal: 19.1s\tremaining: 1.82s\n",
      "913:\tlearn: 26.2876296\ttotal: 19.1s\tremaining: 1.8s\n",
      "914:\tlearn: 26.2799330\ttotal: 19.1s\tremaining: 1.78s\n",
      "915:\tlearn: 26.2790742\ttotal: 19.2s\tremaining: 1.76s\n",
      "916:\tlearn: 26.2782055\ttotal: 19.2s\tremaining: 1.74s\n",
      "917:\tlearn: 26.2635957\ttotal: 19.2s\tremaining: 1.71s\n",
      "918:\tlearn: 26.2597224\ttotal: 19.2s\tremaining: 1.69s\n",
      "919:\tlearn: 26.2342952\ttotal: 19.2s\tremaining: 1.67s\n",
      "920:\tlearn: 26.2335851\ttotal: 19.3s\tremaining: 1.65s\n",
      "921:\tlearn: 26.2076659\ttotal: 19.3s\tremaining: 1.63s\n",
      "922:\tlearn: 26.2058348\ttotal: 19.3s\tremaining: 1.61s\n",
      "923:\tlearn: 26.2042825\ttotal: 19.3s\tremaining: 1.59s\n",
      "924:\tlearn: 26.1949797\ttotal: 19.4s\tremaining: 1.57s\n",
      "925:\tlearn: 26.1722448\ttotal: 19.4s\tremaining: 1.55s\n",
      "926:\tlearn: 26.1615197\ttotal: 19.4s\tremaining: 1.53s\n",
      "927:\tlearn: 26.1590964\ttotal: 19.4s\tremaining: 1.51s\n",
      "928:\tlearn: 26.1568768\ttotal: 19.5s\tremaining: 1.49s\n",
      "929:\tlearn: 26.1235226\ttotal: 19.5s\tremaining: 1.47s\n",
      "930:\tlearn: 26.1228303\ttotal: 19.5s\tremaining: 1.45s\n",
      "931:\tlearn: 26.1219643\ttotal: 19.5s\tremaining: 1.42s\n",
      "932:\tlearn: 26.1179792\ttotal: 19.5s\tremaining: 1.4s\n",
      "933:\tlearn: 26.1077543\ttotal: 19.6s\tremaining: 1.38s\n",
      "934:\tlearn: 26.1024877\ttotal: 19.6s\tremaining: 1.36s\n",
      "935:\tlearn: 26.1018488\ttotal: 19.6s\tremaining: 1.34s\n",
      "936:\tlearn: 26.0910721\ttotal: 19.6s\tremaining: 1.32s\n",
      "937:\tlearn: 26.0829617\ttotal: 19.7s\tremaining: 1.3s\n",
      "938:\tlearn: 26.0629574\ttotal: 19.7s\tremaining: 1.28s\n",
      "939:\tlearn: 26.0620196\ttotal: 19.7s\tremaining: 1.26s\n",
      "940:\tlearn: 26.0611646\ttotal: 19.7s\tremaining: 1.24s\n",
      "941:\tlearn: 26.0524572\ttotal: 19.7s\tremaining: 1.22s\n",
      "942:\tlearn: 26.0378752\ttotal: 19.8s\tremaining: 1.19s\n",
      "943:\tlearn: 26.0368532\ttotal: 19.8s\tremaining: 1.17s\n",
      "944:\tlearn: 26.0366673\ttotal: 19.8s\tremaining: 1.15s\n",
      "945:\tlearn: 26.0244012\ttotal: 19.8s\tremaining: 1.13s\n",
      "946:\tlearn: 26.0188091\ttotal: 19.8s\tremaining: 1.11s\n",
      "947:\tlearn: 26.0097122\ttotal: 19.9s\tremaining: 1.09s\n",
      "948:\tlearn: 26.0088446\ttotal: 19.9s\tremaining: 1.07s\n",
      "949:\tlearn: 26.0075784\ttotal: 19.9s\tremaining: 1.05s\n",
      "950:\tlearn: 26.0008344\ttotal: 19.9s\tremaining: 1.03s\n",
      "951:\tlearn: 26.0000821\ttotal: 19.9s\tremaining: 1s\n",
      "952:\tlearn: 25.9993617\ttotal: 20s\tremaining: 985ms\n",
      "953:\tlearn: 25.9968601\ttotal: 20s\tremaining: 964ms\n",
      "954:\tlearn: 25.9852211\ttotal: 20s\tremaining: 943ms\n",
      "955:\tlearn: 25.9566565\ttotal: 20s\tremaining: 922ms\n",
      "956:\tlearn: 25.9519785\ttotal: 20.1s\tremaining: 901ms\n",
      "957:\tlearn: 25.9198906\ttotal: 20.1s\tremaining: 880ms\n",
      "958:\tlearn: 25.9175379\ttotal: 20.1s\tremaining: 859ms\n",
      "959:\tlearn: 25.9168585\ttotal: 20.1s\tremaining: 838ms\n",
      "960:\tlearn: 25.9161071\ttotal: 20.1s\tremaining: 817ms\n",
      "961:\tlearn: 25.9112747\ttotal: 20.2s\tremaining: 796ms\n",
      "962:\tlearn: 25.9068463\ttotal: 20.2s\tremaining: 775ms\n",
      "963:\tlearn: 25.9061181\ttotal: 20.2s\tremaining: 754ms\n",
      "964:\tlearn: 25.8951305\ttotal: 20.2s\tremaining: 733ms\n",
      "965:\tlearn: 25.8947747\ttotal: 20.2s\tremaining: 712ms\n",
      "966:\tlearn: 25.8663795\ttotal: 20.3s\tremaining: 691ms\n",
      "967:\tlearn: 25.8662257\ttotal: 20.3s\tremaining: 670ms\n",
      "968:\tlearn: 25.8542092\ttotal: 20.3s\tremaining: 649ms\n",
      "969:\tlearn: 25.8534901\ttotal: 20.3s\tremaining: 628ms\n",
      "970:\tlearn: 25.8520739\ttotal: 20.3s\tremaining: 607ms\n",
      "971:\tlearn: 25.8509418\ttotal: 20.4s\tremaining: 586ms\n",
      "972:\tlearn: 25.8501505\ttotal: 20.4s\tremaining: 565ms\n",
      "973:\tlearn: 25.8267503\ttotal: 20.4s\tremaining: 544ms\n",
      "974:\tlearn: 25.8215844\ttotal: 20.4s\tremaining: 523ms\n",
      "975:\tlearn: 25.8146574\ttotal: 20.4s\tremaining: 502ms\n",
      "976:\tlearn: 25.7843164\ttotal: 20.5s\tremaining: 482ms\n",
      "977:\tlearn: 25.7731451\ttotal: 20.5s\tremaining: 461ms\n",
      "978:\tlearn: 25.7681594\ttotal: 20.5s\tremaining: 440ms\n",
      "979:\tlearn: 25.7665267\ttotal: 20.5s\tremaining: 419ms\n",
      "980:\tlearn: 25.7592540\ttotal: 20.5s\tremaining: 398ms\n",
      "981:\tlearn: 25.7273109\ttotal: 20.6s\tremaining: 377ms\n",
      "982:\tlearn: 25.7234697\ttotal: 20.6s\tremaining: 356ms\n",
      "983:\tlearn: 25.7168682\ttotal: 20.6s\tremaining: 335ms\n",
      "984:\tlearn: 25.7009508\ttotal: 20.6s\tremaining: 314ms\n",
      "985:\tlearn: 25.6999963\ttotal: 20.6s\tremaining: 293ms\n",
      "986:\tlearn: 25.6956702\ttotal: 20.7s\tremaining: 272ms\n",
      "987:\tlearn: 25.6892452\ttotal: 20.7s\tremaining: 251ms\n",
      "988:\tlearn: 25.6870883\ttotal: 20.7s\tremaining: 230ms\n",
      "989:\tlearn: 25.6613846\ttotal: 20.7s\tremaining: 209ms\n",
      "990:\tlearn: 25.6596306\ttotal: 20.8s\tremaining: 188ms\n",
      "991:\tlearn: 25.6589533\ttotal: 20.8s\tremaining: 167ms\n",
      "992:\tlearn: 25.6536518\ttotal: 20.8s\tremaining: 147ms\n",
      "993:\tlearn: 25.6511420\ttotal: 20.8s\tremaining: 126ms\n",
      "994:\tlearn: 25.6478065\ttotal: 20.8s\tremaining: 105ms\n",
      "995:\tlearn: 25.6443128\ttotal: 20.9s\tremaining: 83.7ms\n",
      "996:\tlearn: 25.6355399\ttotal: 20.9s\tremaining: 62.8ms\n",
      "997:\tlearn: 25.6306573\ttotal: 20.9s\tremaining: 41.9ms\n",
      "998:\tlearn: 25.6222450\ttotal: 20.9s\tremaining: 20.9ms\n",
      "999:\tlearn: 25.6113002\ttotal: 20.9s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "def random_forrest_regressor(train, valid, test):\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(train, valid, test)\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    res = X_valid.copy()\n",
    "    res[\"actual\"] = y_valid\n",
    "    res[\"pred\"] = y_pred\n",
    "    \n",
    "    #res.to_csv(\"results/pred_random_forrest_regressor_all.csv\")\n",
    "    return model, res\n",
    "\n",
    "def gradient_boosting_regression(train, valid, test):\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(train, valid, test)\n",
    "\n",
    "    model = GradientBoostingRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    res = X_valid.copy()\n",
    "    res[\"actual\"] = y_valid\n",
    "    res[\"pred\"] = y_pred\n",
    "    \n",
    "    #res.to_csv(\"results/pred_gradient_boosting_regressor_all.csv\")\n",
    "    return model, res\n",
    "\n",
    "def tensor_flow(train, valid, test):\n",
    "    \n",
    "    def model_prep(train, valid, test):\n",
    "        df_train = train.copy()\n",
    "        df_valid = valid.copy()\n",
    "        df_test = test.copy()\n",
    "        \n",
    "        # One hot encoding of Boolean variables\n",
    "        encoder = OneHotEncoder()\n",
    "        encoded = pd.DataFrame(encoder.fit_transform(df_train[['is_holiday', 'is_weekend']]).toarray(), columns=encoder.get_feature_names_out(['is_holiday', 'is_weekend']))\n",
    "        df_train = df_train.drop(columns=['is_holiday', 'is_weekend'])\n",
    "        df_train = df_train.join(encoded)\n",
    "        encoded = pd.DataFrame(encoder.transform(df_valid[['is_holiday', 'is_weekend']]).toarray(), columns=encoder.get_feature_names_out(['is_holiday', 'is_weekend']))\n",
    "        df_valid = df_valid.drop(columns=['is_holiday', 'is_weekend'])\n",
    "        df_valid = df_valid.join(encoded)\n",
    "        encoded = pd.DataFrame(encoder.transform(df_test[['is_holiday', 'is_weekend']]).toarray(), columns=encoder.get_feature_names_out(['is_holiday', 'is_weekend']))\n",
    "        df_test = df_test.drop(columns=['is_holiday', 'is_weekend'])\n",
    "        df_test = df_test.join(encoded)\n",
    "        \n",
    "        # Standard scaler for continuous variables\n",
    "        scaler = StandardScaler()\n",
    "        df_train[['duration_sec', 'mean_temperature', 'total_precipitation']] = scaler.fit_transform(df_train[['duration_sec', 'mean_temperature', 'total_precipitation']])\n",
    "        df_valid[['duration_sec', 'mean_temperature', 'total_precipitation']] = scaler.transform(df_valid[['duration_sec', 'mean_temperature', 'total_precipitation']])\n",
    "        df_test[['duration_sec', 'mean_temperature', 'total_precipitation']] = scaler.transform(df_test[['duration_sec', 'mean_temperature', 'total_precipitation']])\n",
    "        \n",
    "        # Minmax scaler for station cluster ids\n",
    "        scaler = MinMaxScaler()\n",
    "        df_train[['start_station_cluster', 'end_station_cluster']] = scaler.fit_transform(df_train[['start_station_cluster', 'end_station_cluster']])\n",
    "        df_valid[['start_station_cluster', 'end_station_cluster']] = scaler.transform(df_valid[['start_station_cluster', 'end_station_cluster']])\n",
    "        df_test[['start_station_cluster', 'end_station_cluster']] = scaler.transform(df_test[['start_station_cluster', 'end_station_cluster']])\n",
    "        \n",
    "        return df_train, df_valid, df_test\n",
    "    \n",
    "    train, valid, test = model_prep(train, valid, test)\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(train, valid, test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_valid, y_valid))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    res = X_test.copy()\n",
    "    res[\"actual\"] = y_test\n",
    "    res[\"pred\"] = y_pred\n",
    "    \n",
    "    #res.to_csv(\"results/pred_tensorflow_all.csv\")\n",
    "    return model, res\n",
    "\n",
    "def cat_boost(train, valid, test):\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(train, valid, test)\n",
    "    \n",
    "    model = CatBoostRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    res = X_valid.copy()\n",
    "    res[\"actual\"] = y_valid\n",
    "    res[\"pred\"] = y_pred\n",
    "    \n",
    "    #res.to_csv(\"results/pred_cat_boost_all.csv\")\n",
    "    return model, res\n",
    "\n",
    "rfr_mod, rfr_res = random_forrest_regressor(df_train, df_valid, df_test)\n",
    "gbr_mod, gbr_res = gradient_boosting_regression(df_train, df_valid, df_test)\n",
    "tsf_mod, tsf_res = tensor_flow(df_train, df_valid, df_test)\n",
    "cbt_mod, cbt_res = cat_boost(df_train, df_valid, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfed01a-6146-4f15-b972-614422c732a0",
   "metadata": {},
   "source": [
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45da095-6f0c-4d62-b6b7-5e474b583fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model       RMSE          MSE   \n",
      "0    Random Forrest Regressor  30.624997   937.890438  \\\n",
      "1  GradientBoosting Regressor  59.287515  3515.009493   \n",
      "2                  TensorFlow  84.764862  7185.081801   \n",
      "3                    CatBoost  37.118327  1377.770164   \n",
      "\n",
      "   Correlation Coefficient  R-squared  \n",
      "0                 0.901788   0.791894  \n",
      "1                 0.519801   0.220066  \n",
      "2                 0.461377   0.162625  \n",
      "3                 0.859596   0.694291  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def evaluate(df):\n",
    "    actual_values = df['actual']\n",
    "    predicted_values = df['pred']\n",
    "    \n",
    "    mse = mean_squared_error(actual_values, predicted_values)\n",
    "    rmse = np.sqrt(mse)\n",
    "    correlation_coefficient, p_value = pearsonr(actual_values, predicted_values)\n",
    "    r2 = r2_score(actual_values, predicted_values)\n",
    "    \n",
    "    return rmse, mse, correlation_coefficient, r2\n",
    "\n",
    "def compare_results(all_results):    \n",
    "    results = []\n",
    "    for name, df in all_results.items():\n",
    "        rmse, mse, correlation_coefficient, r2 = evaluate(df)\n",
    "        result = {\n",
    "            'Model': name,\n",
    "            'RMSE': rmse,\n",
    "            'MSE': mse,\n",
    "            'Correlation Coefficient': correlation_coefficient,\n",
    "            'R-squared': r2\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    #results_df.to_csv(\"results/evaluations.csv\")\n",
    "    return results_df\n",
    "\n",
    "all_results = {\n",
    "    \"Random Forrest Regressor\": rfr_res,\n",
    "    \"GradientBoosting Regressor\": gbr_res,\n",
    "    \"TensorFlow\": tsf_res,\n",
    "    \"CatBoost\": cbt_res\n",
    "}\n",
    "\n",
    "print(compare_results(all_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75418527-3ee4-420f-9180-03136a336a5f",
   "metadata": {},
   "source": [
    "## Hyperparametertuning (RandomForrestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c97b88-ff2d-40b8-a6bd-7310c55be1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None}\n",
      "Best Score: -419.3617432098575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def hpt_random_forrest(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['auto', 'sqrt']\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        rf, param_distributions=param_grid, n_iter=5, scoring=scorer, cv=5, random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)\n",
    "    \n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    res = X_test.copy()\n",
    "    res[\"actual\"] = y_test\n",
    "    res[\"pred\"] = predictions\n",
    "    \n",
    "    return best_model, res\n",
    "\n",
    "best_model, predictions = hpt_random_forrest(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a00fdcf-4a3a-42e3-8409-a1e90cac7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model       RMSE          MSE  Correlation Coefficient   \n",
      "0          Hpt predictions  30.028352   901.701926                 0.907263  \\\n",
      "1  Best model new training  51.010210  2602.041503                 0.934137   \n",
      "2       Default parameters  30.624997   937.890438                 0.901788   \n",
      "\n",
      "   R-squared  \n",
      "0   0.799924  \n",
      "1   0.696749  \n",
      "2   0.791894  \n"
     ]
    }
   ],
   "source": [
    "X_train_combined = pd.concat([X_train, X_valid])\n",
    "y_train_combined = pd.concat([y_train, y_valid])\n",
    "\n",
    "best_model.fit(X_train_combined, y_train_combined)\n",
    "new_predictions = best_model.predict(X_test)\n",
    "\n",
    "res = X_test.copy()\n",
    "res[\"actual\"] = y_test\n",
    "res[\"pred\"] = new_predictions\n",
    "\n",
    "hpt_comparison = {\n",
    "    \"Hpt predictions\" : predictions, \n",
    "    \"Best model new training\": res,\n",
    "    \"Default parameters\": rfr_res\n",
    "}\n",
    "\n",
    "print(compare_results(hpt_comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a9ae7-9cd3-4095-807e-98feab4f3dfa",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0537fd0c-54a8-4d97-9367-22a0f51c9404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model       RMSE          MSE  Correlation Coefficient   \n",
      "0          Hpt predictions  30.028352   901.701926                 0.907263  \\\n",
      "1  Best model new training  51.010210  2602.041503                 0.934137   \n",
      "2       Default parameters  30.624997   937.890438                 0.901788   \n",
      "3                 Baseline  62.826382  3947.154302                 0.920783   \n",
      "\n",
      "   R-squared  \n",
      "0   0.799924  \n",
      "1   0.696749  \n",
      "2   0.791894  \n",
      "3   0.621416  \n"
     ]
    }
   ],
   "source": [
    "def baseline(X_train, y_train, X_test, y_test):\n",
    "    baseline = X_test.copy()\n",
    "    baseline[\"count\"] = y_test\n",
    "    baseline = baseline[[\"start_station_cluster\", \"end_station_cluster\", \"count\"]]\n",
    "\n",
    "    traning_df = X_train.copy()\n",
    "    traning_df[\"count\"] = y_train\n",
    "    traning_df = traning_df[[\"start_station_cluster\", \"end_station_cluster\", \"count\"]]\n",
    "    \n",
    "    mean_df = traning_df.groupby([\"start_station_cluster\", \"end_station_cluster\"]).mean()[[\"count\"]]\n",
    "    \n",
    "    merged_df = pd.merge(baseline, mean_df, left_on=['start_station_cluster', 'end_station_cluster'], right_on=['start_station_cluster', 'end_station_cluster'])\n",
    "    merged_df = merged_df.rename(columns={'count_x': 'actual', 'count_y': 'pred'})\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "hpt_comparison[\"Baseline\"] = baseline(X_train, y_train, X_test, y_test)\n",
    "print(compare_results(hpt_comparison))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
