{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea5435bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import cos, sin, arcsin, sqrt\n",
    "from math import radians\n",
    "from datetime import date\n",
    "import holidays\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9735d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with files for stations 2022\n",
    "stations2022_list = ['data/stations_2022/20220104_stations.csv','data/stations_2022/20220105_stations.csv','data/stations_2022/20220106_stations.csv','data/stations_2022/20220107_stations.csv','data/stations_2022/20220108_stations.csv','data/stations_2022/20220109_stations.csv','data/stations_2022/20220110_stations.csv','data/stations_2022/20220111_stations.csv']\n",
    "\n",
    "df_stations_2022 = []\n",
    "\n",
    "for file in stations2022_list:\n",
    "    df = pd.read_csv(file)\n",
    "    df_stations_2022.append(df)\n",
    "\n",
    "# Remove Duplicates\n",
    "df_stations_2022 = pd.concat(df_stations_2022, ignore_index= True)\n",
    "df_stations_2022 = df_stations_2022.drop_duplicates()\n",
    "\n",
    "df_stations_2022.to_csv('data/stations/Stations_2022.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f2c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesing_task2(data, n_clusters):\n",
    "    data =  data.dropna()\n",
    "    coordinates = data[['latitude', 'longitude']]\n",
    "\n",
    "    aggregations = {\n",
    "        'rides_count': 'sum',  \n",
    "        'mean_temperature': 'mean',  \n",
    "        'total_precipitation': 'mean',  \n",
    "        'isHoliday': lambda x: round(x.mean()), \n",
    "        'isWeekend': lambda x: round(x.mean()), \n",
    "    }\n",
    "\n",
    "    column_order = ['year', 'month', 'day', 'mean_temperature', 'total_precipitation', 'isHoliday', 'isWeekend', 'stations_cluster', 'rides_count']\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(coordinates)\n",
    "    data['stations_cluster'] =  kmeans.labels_\n",
    "\n",
    "    stations_cluster = data.groupby(['year', 'month', 'day', 'am_pm', 'stations_cluster']).agg(aggregations).reset_index().reindex(columns=column_order)\n",
    "\n",
    "    stations_cluster['isHoliday'] = stations_cluster['isHoliday'].astype(bool)\n",
    "    stations_cluster['isWeekend'] = stations_cluster['isWeekend'].astype(bool)\n",
    "\n",
    "    return stations_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "611ca171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(rides_file_path, stations_file_path):\n",
    "\n",
    "    df_rides = pd.read_csv(rides_file_path, parse_dates=[0, 1, 2, 3])\n",
    "    df_stations = pd.read_csv(stations_file_path)\n",
    "\n",
    "    df_rides.columns = df_rides.columns.str.lower()\n",
    "    df_stations.columns = df_stations.columns.str.lower()\n",
    "    \n",
    "    # Rename Columns in some Stations files due to inconsistency in naming\n",
    "    if 'start_station_code' not in df_rides.columns:\n",
    "        df_rides = df_rides.rename(columns={'emplacement_pk_start': 'start_station_code',\n",
    "                                        'emplacement_pk_end': 'end_station_code'})\n",
    "    \n",
    "    if 'code' not in df_stations.columns:\n",
    "        df_stations = df_stations.rename(columns={'pk': 'code'})\n",
    "\n",
    "    # Problems in Aug 2019 cause station codes aren't of type int\n",
    "    if df_rides['start_station_code'].dtype != 'int':\n",
    "\n",
    "        def to_int_or_Err(val):\n",
    "            try:\n",
    "                return int(val)\n",
    "            except ValueError:\n",
    "                return None\n",
    "\n",
    "        df_rides['start_station_code_int'] = df_rides['start_station_code'].apply(to_int_or_Err)\n",
    "        df_rides['end_station_code_int'] = df_rides['end_station_code'].apply(to_int_or_Err)\n",
    "\n",
    "        # drop every row where station code which couldn't be converted to int\n",
    "        df_rides = df_rides.dropna()\n",
    "        df_rides['start_station_code'] = df_rides['start_station_code_int'].astype(int)\n",
    "        df_rides['end_station_code'] = df_rides['end_station_code_int'].astype(int)\n",
    "        df_rides = df_rides.drop(columns=['start_station_code_int', 'end_station_code_int'])\n",
    "\n",
    "    # add year, month and weekday\n",
    "    df_rides['year'] = df_rides['start_date'].dt.year\n",
    "    df_rides['month'] = df_rides['start_date'].dt.month\n",
    "    df_rides['weekday'] = df_rides['start_date'].dt.weekday\n",
    "\n",
    "    # Sum up rides between Midnight and 12 and 12:00 AM to Midnight\n",
    "    df_rides_count = df_rides.groupby([pd.Grouper(key='start_date', freq='12h'), 'start_station_code'])['end_date'].count()\n",
    "    df_rides_count = df_rides_count.to_frame().rename(columns={'end_date': 'rides_count'}).reset_index()\n",
    "\n",
    "    # add boolean am/pm (am = 0, pm = 1\n",
    "    df_rides_count['am_pm'] = df_rides_count['start_date'].dt.hour < 12\n",
    "\n",
    "    # add total count of stations per year \n",
    "    df_stations_count = len(df_stations['code'].unique())\n",
    "    df_rides_count['stations_count'] = df_stations_count\n",
    "\n",
    "    # add isHoliday column as boolean\n",
    "    holidaysCanada = holidays.country_holidays('CA', subdiv='QC')\n",
    "    df_rides_count['isHoliday'] = df_rides_count['start_date'].apply(lambda x: x.date() in holidaysCanada)\n",
    "\n",
    "    # add isWeekend column as boolean\n",
    "    df_rides_count['isWeekend'] = df_rides_count['start_date'].dt.weekday > 4\n",
    "\n",
    "    # add distance to center of Montreal\n",
    "    def distanceToCenter(row):\n",
    "        lon1 = -73.554167\n",
    "        lat1 = 45.508888\n",
    "        lon2 = row['longitude']\n",
    "        lat2 = row['latitude']\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "        dlon = lon2 - lon1 \n",
    "        dlat = lat2 - lat1 \n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * arcsin(sqrt(a)) \n",
    "        km = 6367 * c\n",
    "        return km\n",
    "    \n",
    "    df_rides_count = df_rides_count.merge(df_stations, left_on='start_station_code', right_on='code', how='left')\n",
    "    df_rides_count['distance_to_center'] = df_rides_count.apply(lambda row: distanceToCenter(row), axis=1)\n",
    "\n",
    "    # add weather data\n",
    "    df_weather = pd.read_csv('data/preprocessed_data/weather.csv', parse_dates=[4])\n",
    "    df_weather.columns = df_weather.columns.str.lower()\n",
    "    df_weather = df_weather[[\"date/time\", \"mean temp (°c)\", \"total precip (mm)\"]]\n",
    "    df_weather = df_weather.rename(columns={\"date/time\": \"tmp_date\",'mean temp (°c)': 'mean_temperature','total precip (mm)': 'total_precipitation'})\n",
    "    df_weather['tmp_date'] = pd.to_datetime(df_weather['tmp_date']).dt.date\n",
    "    \n",
    "    # interpolate missing data\n",
    "    df_weather[['mean_temperature','total_precipitation']] = df_weather[['mean_temperature','total_precipitation']].interpolate()\n",
    "\n",
    "    # add attribute and join dataframes\n",
    "    df_rides_count['date'] = pd.to_datetime(df_rides_count['start_date']).dt.date\n",
    "    df_rides_count = df_rides_count.merge(df_weather, left_on='date', right_on='tmp_date', how='left')\n",
    "    \n",
    "    # Create more date related columns\n",
    "    df_rides_count['year'], df_rides_count['month'], df_rides_count['day'], df_rides_count['weekday'] = df_rides_count['start_date'].dt.year, df_rides_count['start_date'].dt.month, df_rides_count['start_date'].dt.day, df_rides_count['start_date'].dt.dayofweek\n",
    "    \n",
    "    # drop na colums\n",
    "    df_rides_count = df_rides_count[[\n",
    "        'latitude','longitude','distance_to_center','year','month','day','weekday','am_pm','isHoliday','isWeekend','mean_temperature','total_precipitation',\n",
    "        'stations_count','rides_count'\n",
    "    ]]\n",
    "\n",
    "    return df_rides_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6618ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data from year 2014 till 2018\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "for year in range(2014, 2018):\n",
    "    stations_file_path = f'data/stations/Stations_{year}.csv'\n",
    "    for month in range(4, 11):\n",
    "        rides_file_path = f'data/bike_rides/OD_{year}-{month:02d}.csv'\n",
    "        df_month = preprocess_data(rides_file_path, stations_file_path)\n",
    "        df_train = pd.concat([df_train, df_month]).reset_index(drop=True)\n",
    "# save file\n",
    "df_train.to_csv('data/preprocessed_data/train.csv', index=False)\n",
    "df_train = preprocesing_task2(df_train, 100)\n",
    "df_train.to_csv('data/preprocessed_data/t2_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bc282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data from year 2019\n",
    "\n",
    "df_val = pd.DataFrame()\n",
    "stations_file_path = f'data/stations/Stations_2019.csv'\n",
    "for month in range(4, 11):\n",
    "    rides_file_path = f'data/bike_rides/OD_2019-{month:02d}.csv'\n",
    "    df_month = preprocess_data(rides_file_path, stations_file_path)\n",
    "    df_val = pd.concat([df_val, df_month]).reset_index(drop=True)\n",
    "# save file\n",
    "df_val.to_csv('data/preprocessed_data/valid.csv', index=False)\n",
    "df_val = preprocesing_task2(df_val, 100)\n",
    "df_val.to_csv('data/preprocessed_data/t2_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6163fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Covid data from year 2020 till 2021\n",
    "\n",
    "df_covid = pd.DataFrame()\n",
    "for year in range(2020, 2021):\n",
    "    stations_file_path = f'data/stations/Stations_{year}.csv'\n",
    "    rides_file_path = f'data/bike_rides/OD_{year}.csv'\n",
    "    df_month = preprocess_data(rides_file_path, stations_file_path)\n",
    "    df_covid = pd.concat([df_covid, df_month]).reset_index(drop=True)\n",
    "# save file\n",
    "df_covid.to_csv('data/preprocessed_data/covid.csv', index=False)\n",
    "df_covid = preprocesing_task2(df_covid, 100)\n",
    "df_covid.to_csv('data/preprocessed_data/t2_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cddd3c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test data from year 2022\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "stations_file_path = f'data/stations/Stations_2022.csv'\n",
    "for month in range(4, 11):\n",
    "    rides_file_path = f'data/bike_rides/OD_2022-{month:02d}.csv'\n",
    "    df_month = preprocess_data(rides_file_path, stations_file_path)\n",
    "    df_test = pd.concat([df_test, df_month]).reset_index(drop=True)\n",
    "# save file\n",
    "df_test.to_csv('data/preprocessed_data/test.csv', index=False)\n",
    "df_test = preprocesing_task2(df_test, 100)\n",
    "df_test.to_csv('data/preprocessed_data/t2_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
