{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2ef098fd-ee40-4773-97a8-8c1b70ff6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import cos, sin, arcsin, sqrt\n",
    "from math import radians\n",
    "from datetime import date\n",
    "import holidays\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d10650-768f-4a33-8a23-c541d3cf7d9a",
   "metadata": {},
   "source": [
    "## Train, test and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3e234c50-a401-4ca2-a907-9709ef5a213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/regression_analysis/pre_task2_2014_2018.csv\", index_col=0)\n",
    "date_train = df_train['start_date']\n",
    "df_train = df_train.drop([\"start_date\"], axis=1)\n",
    "\n",
    "df_valid = pd.read_csv(\"data/regression_analysis/pre_task2_2019.csv\", index_col=0)\n",
    "date_valid = df_valid['start_date']\n",
    "df_valid = df_valid.drop([\"start_date\"], axis=1)\n",
    "\n",
    "df_test = pd.read_csv(\"data/regression_analysis/pre_task2_2022.csv\", index_col=0)\n",
    "date_test = df_test['start_date']\n",
    "df_test = df_test.drop([\"start_date\"], axis=1)\n",
    "\n",
    "def df_split(train, valid, test):\n",
    "    X_train = train.copy()\n",
    "    y_train = X_train['count']\n",
    "    X_train = X_train.drop([\"count\", 'duration_sec'], axis=1)\n",
    "    \n",
    "    X_valid = valid.copy()\n",
    "    y_valid = X_valid['count']\n",
    "    X_valid = X_valid.drop([\"count\", 'duration_sec'], axis=1)\n",
    "    \n",
    "    X_test = test.copy()\n",
    "    y_test = X_test['count']\n",
    "    X_test = X_test.drop([\"count\", 'duration_sec'], axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(df_train, df_valid, df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46535f9e-28c8-48ee-a7bb-75797f41acf2",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "In the following block we have made functions for 4 different models:\n",
    "- RandomForrestRegressor\n",
    "- GradientBoostingRegressor\n",
    "- TensorFlow\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6bf0ac1d-7dfb-4a33-a220-b4f329504885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12440/12440 [==============================] - 6s 437us/step - loss: 3859.4885 - val_loss: 4419.4785\n",
      "Epoch 2/20\n",
      "12440/12440 [==============================] - 5s 429us/step - loss: 3804.1550 - val_loss: 4369.2397\n",
      "Epoch 3/20\n",
      "12440/12440 [==============================] - 5s 430us/step - loss: 3743.8384 - val_loss: 4304.7441\n",
      "Epoch 4/20\n",
      "12440/12440 [==============================] - 5s 425us/step - loss: 3661.0210 - val_loss: 4180.8149\n",
      "Epoch 5/20\n",
      "12440/12440 [==============================] - 5s 425us/step - loss: 3541.0557 - val_loss: 4090.9124\n",
      "Epoch 6/20\n",
      "12440/12440 [==============================] - 5s 427us/step - loss: 3450.2615 - val_loss: 4061.3459\n",
      "Epoch 7/20\n",
      "12440/12440 [==============================] - 5s 432us/step - loss: 3400.4744 - val_loss: 3933.2476\n",
      "Epoch 8/20\n",
      "12440/12440 [==============================] - 5s 426us/step - loss: 3351.8752 - val_loss: 3897.3120\n",
      "Epoch 9/20\n",
      "12440/12440 [==============================] - 5s 431us/step - loss: 3316.3608 - val_loss: 3817.4714\n",
      "Epoch 10/20\n",
      "12440/12440 [==============================] - 5s 423us/step - loss: 3271.7886 - val_loss: 3747.0261\n",
      "Epoch 11/20\n",
      "12440/12440 [==============================] - 5s 425us/step - loss: 3231.3767 - val_loss: 3682.7068\n",
      "Epoch 12/20\n",
      "12440/12440 [==============================] - 5s 429us/step - loss: 3184.7368 - val_loss: 3643.0303\n",
      "Epoch 13/20\n",
      "12440/12440 [==============================] - 5s 427us/step - loss: 3116.6533 - val_loss: 3648.3992\n",
      "Epoch 14/20\n",
      "12440/12440 [==============================] - 6s 443us/step - loss: 3059.0183 - val_loss: 3485.8391\n",
      "Epoch 15/20\n",
      "12440/12440 [==============================] - 6s 449us/step - loss: 3013.2793 - val_loss: 3834.6252\n",
      "Epoch 16/20\n",
      "12440/12440 [==============================] - 5s 424us/step - loss: 2980.2527 - val_loss: 3438.1174\n",
      "Epoch 17/20\n",
      "12440/12440 [==============================] - 5s 429us/step - loss: 2942.3481 - val_loss: 3420.9751\n",
      "Epoch 18/20\n",
      "12440/12440 [==============================] - 6s 456us/step - loss: 2904.0945 - val_loss: 3336.5012\n",
      "Epoch 19/20\n",
      "12440/12440 [==============================] - 5s 430us/step - loss: 2874.3040 - val_loss: 3368.5054\n",
      "Epoch 20/20\n",
      "12440/12440 [==============================] - 5s 436us/step - loss: 2854.8184 - val_loss: 3436.4966\n",
      "6857/6857 [==============================] - 2s 231us/step\n",
      "Learning rate set to 0.121413\n",
      "0:\tlearn: 62.6754924\ttotal: 43.9ms\tremaining: 43.9s\n",
      "1:\tlearn: 62.1563048\ttotal: 69.4ms\tremaining: 34.6s\n",
      "2:\tlearn: 61.5915647\ttotal: 106ms\tremaining: 35.3s\n",
      "3:\tlearn: 60.8648934\ttotal: 133ms\tremaining: 33.2s\n",
      "4:\tlearn: 60.4278915\ttotal: 160ms\tremaining: 31.8s\n",
      "5:\tlearn: 59.9358057\ttotal: 197ms\tremaining: 32.6s\n",
      "6:\tlearn: 59.5217106\ttotal: 224ms\tremaining: 31.8s\n",
      "7:\tlearn: 58.9365875\ttotal: 255ms\tremaining: 31.6s\n",
      "8:\tlearn: 58.4883733\ttotal: 285ms\tremaining: 31.4s\n",
      "9:\tlearn: 58.2273121\ttotal: 319ms\tremaining: 31.6s\n",
      "10:\tlearn: 57.9856311\ttotal: 350ms\tremaining: 31.5s\n",
      "11:\tlearn: 57.7709592\ttotal: 376ms\tremaining: 31s\n",
      "12:\tlearn: 57.5562120\ttotal: 404ms\tremaining: 30.7s\n",
      "13:\tlearn: 57.0106052\ttotal: 433ms\tremaining: 30.5s\n",
      "14:\tlearn: 56.8133586\ttotal: 457ms\tremaining: 30s\n",
      "15:\tlearn: 56.5362117\ttotal: 486ms\tremaining: 29.9s\n",
      "16:\tlearn: 56.3814413\ttotal: 510ms\tremaining: 29.5s\n",
      "17:\tlearn: 56.2117121\ttotal: 537ms\tremaining: 29.3s\n",
      "18:\tlearn: 56.0659605\ttotal: 562ms\tremaining: 29s\n",
      "19:\tlearn: 55.7380298\ttotal: 590ms\tremaining: 28.9s\n",
      "20:\tlearn: 55.4935774\ttotal: 613ms\tremaining: 28.6s\n",
      "21:\tlearn: 55.3549344\ttotal: 637ms\tremaining: 28.3s\n",
      "22:\tlearn: 54.9844912\ttotal: 665ms\tremaining: 28.3s\n",
      "23:\tlearn: 54.6856677\ttotal: 690ms\tremaining: 28.1s\n",
      "24:\tlearn: 54.4944303\ttotal: 718ms\tremaining: 28s\n",
      "25:\tlearn: 54.3480510\ttotal: 743ms\tremaining: 27.8s\n",
      "26:\tlearn: 54.0936223\ttotal: 770ms\tremaining: 27.7s\n",
      "27:\tlearn: 53.9343154\ttotal: 798ms\tremaining: 27.7s\n",
      "28:\tlearn: 53.8209993\ttotal: 820ms\tremaining: 27.5s\n",
      "29:\tlearn: 53.7206890\ttotal: 842ms\tremaining: 27.2s\n",
      "30:\tlearn: 53.4010211\ttotal: 872ms\tremaining: 27.2s\n",
      "31:\tlearn: 52.9486187\ttotal: 900ms\tremaining: 27.2s\n",
      "32:\tlearn: 52.8353155\ttotal: 924ms\tremaining: 27.1s\n",
      "33:\tlearn: 52.7449749\ttotal: 946ms\tremaining: 26.9s\n",
      "34:\tlearn: 52.4824394\ttotal: 975ms\tremaining: 26.9s\n",
      "35:\tlearn: 52.2548609\ttotal: 1.01s\tremaining: 26.9s\n",
      "36:\tlearn: 51.9525924\ttotal: 1.04s\tremaining: 27s\n",
      "37:\tlearn: 51.7729792\ttotal: 1.07s\tremaining: 27s\n",
      "38:\tlearn: 51.5235834\ttotal: 1.1s\tremaining: 27.1s\n",
      "39:\tlearn: 51.1232421\ttotal: 1.15s\tremaining: 27.6s\n",
      "40:\tlearn: 50.9894253\ttotal: 1.18s\tremaining: 27.5s\n",
      "41:\tlearn: 50.8365765\ttotal: 1.2s\tremaining: 27.5s\n",
      "42:\tlearn: 50.6845352\ttotal: 1.23s\tremaining: 27.4s\n",
      "43:\tlearn: 50.5008253\ttotal: 1.27s\tremaining: 27.6s\n",
      "44:\tlearn: 50.4242358\ttotal: 1.3s\tremaining: 27.6s\n",
      "45:\tlearn: 50.3306939\ttotal: 1.33s\tremaining: 27.6s\n",
      "46:\tlearn: 50.2806270\ttotal: 1.36s\tremaining: 27.5s\n",
      "47:\tlearn: 50.0670489\ttotal: 1.39s\tremaining: 27.6s\n",
      "48:\tlearn: 49.7426089\ttotal: 1.42s\tremaining: 27.5s\n",
      "49:\tlearn: 49.4999413\ttotal: 1.45s\tremaining: 27.5s\n",
      "50:\tlearn: 49.4264074\ttotal: 1.47s\tremaining: 27.3s\n",
      "51:\tlearn: 49.1765970\ttotal: 1.5s\tremaining: 27.3s\n",
      "52:\tlearn: 49.0954879\ttotal: 1.52s\tremaining: 27.2s\n",
      "53:\tlearn: 48.9934600\ttotal: 1.55s\tremaining: 27.1s\n",
      "54:\tlearn: 48.9414942\ttotal: 1.58s\tremaining: 27.2s\n",
      "55:\tlearn: 48.8163939\ttotal: 1.61s\tremaining: 27.2s\n",
      "56:\tlearn: 48.6840369\ttotal: 1.65s\tremaining: 27.2s\n",
      "57:\tlearn: 48.5735648\ttotal: 1.68s\tremaining: 27.3s\n",
      "58:\tlearn: 48.5400699\ttotal: 1.71s\tremaining: 27.2s\n",
      "59:\tlearn: 48.4142417\ttotal: 1.73s\tremaining: 27.2s\n",
      "60:\tlearn: 48.3555971\ttotal: 1.76s\tremaining: 27.1s\n",
      "61:\tlearn: 48.1426360\ttotal: 1.79s\tremaining: 27.1s\n",
      "62:\tlearn: 48.0714684\ttotal: 1.82s\tremaining: 27.1s\n",
      "63:\tlearn: 47.9695832\ttotal: 1.85s\tremaining: 27s\n",
      "64:\tlearn: 47.8603910\ttotal: 1.88s\tremaining: 27s\n",
      "65:\tlearn: 47.8034370\ttotal: 1.9s\tremaining: 26.9s\n",
      "66:\tlearn: 47.6254042\ttotal: 1.93s\tremaining: 26.9s\n",
      "67:\tlearn: 47.5051232\ttotal: 1.95s\tremaining: 26.7s\n",
      "68:\tlearn: 47.4569392\ttotal: 1.98s\tremaining: 26.7s\n",
      "69:\tlearn: 47.3771312\ttotal: 2s\tremaining: 26.6s\n",
      "70:\tlearn: 47.1633892\ttotal: 2.03s\tremaining: 26.6s\n",
      "71:\tlearn: 47.0710450\ttotal: 2.05s\tremaining: 26.4s\n",
      "72:\tlearn: 46.9325920\ttotal: 2.07s\tremaining: 26.3s\n",
      "73:\tlearn: 46.8515283\ttotal: 2.1s\tremaining: 26.3s\n",
      "74:\tlearn: 46.7873713\ttotal: 2.13s\tremaining: 26.2s\n",
      "75:\tlearn: 46.7020123\ttotal: 2.15s\tremaining: 26.2s\n",
      "76:\tlearn: 46.5827155\ttotal: 2.17s\tremaining: 26.1s\n",
      "77:\tlearn: 46.5100002\ttotal: 2.2s\tremaining: 26s\n",
      "78:\tlearn: 46.3951739\ttotal: 2.23s\tremaining: 25.9s\n",
      "79:\tlearn: 46.3682142\ttotal: 2.25s\tremaining: 25.8s\n",
      "80:\tlearn: 46.2692226\ttotal: 2.27s\tremaining: 25.7s\n",
      "81:\tlearn: 46.2224607\ttotal: 2.29s\tremaining: 25.6s\n",
      "82:\tlearn: 46.1663760\ttotal: 2.31s\tremaining: 25.6s\n",
      "83:\tlearn: 46.1362486\ttotal: 2.34s\tremaining: 25.5s\n",
      "84:\tlearn: 46.0844973\ttotal: 2.37s\tremaining: 25.6s\n",
      "85:\tlearn: 46.0475604\ttotal: 2.4s\tremaining: 25.5s\n",
      "86:\tlearn: 45.9170036\ttotal: 2.42s\tremaining: 25.4s\n",
      "87:\tlearn: 45.8601294\ttotal: 2.45s\tremaining: 25.4s\n",
      "88:\tlearn: 45.6630063\ttotal: 2.48s\tremaining: 25.4s\n",
      "89:\tlearn: 45.5706063\ttotal: 2.5s\tremaining: 25.3s\n",
      "90:\tlearn: 45.4904710\ttotal: 2.53s\tremaining: 25.2s\n",
      "91:\tlearn: 45.4611232\ttotal: 2.55s\tremaining: 25.2s\n",
      "92:\tlearn: 45.4138940\ttotal: 2.58s\tremaining: 25.1s\n",
      "93:\tlearn: 45.3711062\ttotal: 2.6s\tremaining: 25.1s\n",
      "94:\tlearn: 45.2766154\ttotal: 2.63s\tremaining: 25s\n",
      "95:\tlearn: 45.2282822\ttotal: 2.65s\tremaining: 25s\n",
      "96:\tlearn: 45.0770846\ttotal: 2.68s\tremaining: 25s\n",
      "97:\tlearn: 44.8425280\ttotal: 2.71s\tremaining: 24.9s\n",
      "98:\tlearn: 44.8249539\ttotal: 2.73s\tremaining: 24.9s\n",
      "99:\tlearn: 44.6948979\ttotal: 2.76s\tremaining: 24.8s\n",
      "100:\tlearn: 44.6631625\ttotal: 2.78s\tremaining: 24.8s\n",
      "101:\tlearn: 44.5026421\ttotal: 2.81s\tremaining: 24.8s\n",
      "102:\tlearn: 44.4253457\ttotal: 2.83s\tremaining: 24.7s\n",
      "103:\tlearn: 44.3625105\ttotal: 2.86s\tremaining: 24.6s\n",
      "104:\tlearn: 44.3406063\ttotal: 2.88s\tremaining: 24.6s\n",
      "105:\tlearn: 44.1536596\ttotal: 2.91s\tremaining: 24.6s\n",
      "106:\tlearn: 44.1061220\ttotal: 2.93s\tremaining: 24.5s\n",
      "107:\tlearn: 43.9684410\ttotal: 2.96s\tremaining: 24.4s\n",
      "108:\tlearn: 43.9464416\ttotal: 2.98s\tremaining: 24.4s\n",
      "109:\tlearn: 43.9101291\ttotal: 3.01s\tremaining: 24.3s\n",
      "110:\tlearn: 43.8725022\ttotal: 3.03s\tremaining: 24.3s\n",
      "111:\tlearn: 43.7837013\ttotal: 3.06s\tremaining: 24.2s\n",
      "112:\tlearn: 43.5338536\ttotal: 3.08s\tremaining: 24.2s\n",
      "113:\tlearn: 43.4641397\ttotal: 3.11s\tremaining: 24.2s\n",
      "114:\tlearn: 43.3652427\ttotal: 3.13s\tremaining: 24.1s\n",
      "115:\tlearn: 43.2279585\ttotal: 3.16s\tremaining: 24.1s\n",
      "116:\tlearn: 43.1941408\ttotal: 3.18s\tremaining: 24s\n",
      "117:\tlearn: 43.1592413\ttotal: 3.2s\tremaining: 23.9s\n",
      "118:\tlearn: 42.8922030\ttotal: 3.23s\tremaining: 23.9s\n",
      "119:\tlearn: 42.8539213\ttotal: 3.26s\tremaining: 23.9s\n",
      "120:\tlearn: 42.7904174\ttotal: 3.28s\tremaining: 23.8s\n",
      "121:\tlearn: 42.7572115\ttotal: 3.3s\tremaining: 23.8s\n",
      "122:\tlearn: 42.4525618\ttotal: 3.33s\tremaining: 23.8s\n",
      "123:\tlearn: 42.3950859\ttotal: 3.36s\tremaining: 23.7s\n",
      "124:\tlearn: 42.3259824\ttotal: 3.38s\tremaining: 23.7s\n",
      "125:\tlearn: 42.1771162\ttotal: 3.41s\tremaining: 23.7s\n",
      "126:\tlearn: 42.1470205\ttotal: 3.43s\tremaining: 23.6s\n",
      "127:\tlearn: 42.1156715\ttotal: 3.46s\tremaining: 23.5s\n",
      "128:\tlearn: 42.1041302\ttotal: 3.48s\tremaining: 23.5s\n",
      "129:\tlearn: 42.0747673\ttotal: 3.5s\tremaining: 23.4s\n",
      "130:\tlearn: 42.0267629\ttotal: 3.52s\tremaining: 23.4s\n",
      "131:\tlearn: 41.9417510\ttotal: 3.55s\tremaining: 23.3s\n",
      "132:\tlearn: 41.8252988\ttotal: 3.58s\tremaining: 23.3s\n",
      "133:\tlearn: 41.7781928\ttotal: 3.6s\tremaining: 23.3s\n",
      "134:\tlearn: 41.7107616\ttotal: 3.63s\tremaining: 23.2s\n",
      "135:\tlearn: 41.6687083\ttotal: 3.65s\tremaining: 23.2s\n",
      "136:\tlearn: 41.5719127\ttotal: 3.68s\tremaining: 23.2s\n",
      "137:\tlearn: 41.4850460\ttotal: 3.71s\tremaining: 23.1s\n",
      "138:\tlearn: 41.4405219\ttotal: 3.73s\tremaining: 23.1s\n",
      "139:\tlearn: 41.4031613\ttotal: 3.75s\tremaining: 23.1s\n",
      "140:\tlearn: 41.3957072\ttotal: 3.78s\tremaining: 23s\n",
      "141:\tlearn: 41.3785381\ttotal: 3.8s\tremaining: 23s\n",
      "142:\tlearn: 41.3487910\ttotal: 3.83s\tremaining: 22.9s\n",
      "143:\tlearn: 41.2714984\ttotal: 3.85s\tremaining: 22.9s\n",
      "144:\tlearn: 41.2580873\ttotal: 3.87s\tremaining: 22.8s\n",
      "145:\tlearn: 41.0174896\ttotal: 3.9s\tremaining: 22.8s\n",
      "146:\tlearn: 40.9335244\ttotal: 3.93s\tremaining: 22.8s\n",
      "147:\tlearn: 40.8003183\ttotal: 3.95s\tremaining: 22.8s\n",
      "148:\tlearn: 40.7187336\ttotal: 3.98s\tremaining: 22.7s\n",
      "149:\tlearn: 40.6694350\ttotal: 4s\tremaining: 22.7s\n",
      "150:\tlearn: 40.5719735\ttotal: 4.02s\tremaining: 22.6s\n",
      "151:\tlearn: 40.5377951\ttotal: 4.05s\tremaining: 22.6s\n",
      "152:\tlearn: 40.4768348\ttotal: 4.07s\tremaining: 22.5s\n",
      "153:\tlearn: 40.4612113\ttotal: 4.09s\tremaining: 22.5s\n",
      "154:\tlearn: 40.4389549\ttotal: 4.12s\tremaining: 22.5s\n",
      "155:\tlearn: 40.3908057\ttotal: 4.15s\tremaining: 22.4s\n",
      "156:\tlearn: 40.3503108\ttotal: 4.17s\tremaining: 22.4s\n",
      "157:\tlearn: 40.3028038\ttotal: 4.19s\tremaining: 22.3s\n",
      "158:\tlearn: 40.1620943\ttotal: 4.22s\tremaining: 22.3s\n",
      "159:\tlearn: 40.0562943\ttotal: 4.25s\tremaining: 22.3s\n",
      "160:\tlearn: 40.0330387\ttotal: 4.27s\tremaining: 22.3s\n",
      "161:\tlearn: 40.0197675\ttotal: 4.29s\tremaining: 22.2s\n",
      "162:\tlearn: 40.0056230\ttotal: 4.32s\tremaining: 22.2s\n",
      "163:\tlearn: 39.9298366\ttotal: 4.34s\tremaining: 22.2s\n",
      "164:\tlearn: 39.8396101\ttotal: 4.37s\tremaining: 22.1s\n",
      "165:\tlearn: 39.7743177\ttotal: 4.4s\tremaining: 22.1s\n",
      "166:\tlearn: 39.7417876\ttotal: 4.42s\tremaining: 22.1s\n",
      "167:\tlearn: 39.7327492\ttotal: 4.44s\tremaining: 22s\n",
      "168:\tlearn: 39.7017533\ttotal: 4.46s\tremaining: 21.9s\n",
      "169:\tlearn: 39.6617132\ttotal: 4.49s\tremaining: 21.9s\n",
      "170:\tlearn: 39.6306036\ttotal: 4.51s\tremaining: 21.9s\n",
      "171:\tlearn: 39.5558210\ttotal: 4.54s\tremaining: 21.8s\n",
      "172:\tlearn: 39.4490190\ttotal: 4.56s\tremaining: 21.8s\n",
      "173:\tlearn: 39.4136465\ttotal: 4.59s\tremaining: 21.8s\n",
      "174:\tlearn: 39.3915879\ttotal: 4.61s\tremaining: 21.8s\n",
      "175:\tlearn: 39.3556524\ttotal: 4.64s\tremaining: 21.7s\n",
      "176:\tlearn: 39.1724765\ttotal: 4.67s\tremaining: 21.7s\n",
      "177:\tlearn: 39.1279675\ttotal: 4.7s\tremaining: 21.7s\n",
      "178:\tlearn: 39.1220807\ttotal: 4.72s\tremaining: 21.6s\n",
      "179:\tlearn: 39.0850335\ttotal: 4.74s\tremaining: 21.6s\n",
      "180:\tlearn: 39.0605193\ttotal: 4.77s\tremaining: 21.6s\n",
      "181:\tlearn: 39.0430997\ttotal: 4.79s\tremaining: 21.6s\n",
      "182:\tlearn: 38.9500092\ttotal: 4.82s\tremaining: 21.5s\n",
      "183:\tlearn: 38.8983552\ttotal: 4.85s\tremaining: 21.5s\n",
      "184:\tlearn: 38.8145136\ttotal: 4.88s\tremaining: 21.5s\n",
      "185:\tlearn: 38.7486035\ttotal: 4.9s\tremaining: 21.4s\n",
      "186:\tlearn: 38.6400287\ttotal: 4.92s\tremaining: 21.4s\n",
      "187:\tlearn: 38.5508230\ttotal: 4.95s\tremaining: 21.4s\n",
      "188:\tlearn: 38.5197739\ttotal: 4.97s\tremaining: 21.3s\n",
      "189:\tlearn: 38.4794357\ttotal: 5s\tremaining: 21.3s\n",
      "190:\tlearn: 38.4666052\ttotal: 5.02s\tremaining: 21.3s\n",
      "191:\tlearn: 38.3882950\ttotal: 5.05s\tremaining: 21.3s\n",
      "192:\tlearn: 38.3813805\ttotal: 5.07s\tremaining: 21.2s\n",
      "193:\tlearn: 38.3519744\ttotal: 5.1s\tremaining: 21.2s\n",
      "194:\tlearn: 38.3028418\ttotal: 5.12s\tremaining: 21.1s\n",
      "195:\tlearn: 38.2870012\ttotal: 5.15s\tremaining: 21.1s\n",
      "196:\tlearn: 38.2453691\ttotal: 5.17s\tremaining: 21.1s\n",
      "197:\tlearn: 38.2297546\ttotal: 5.19s\tremaining: 21s\n",
      "198:\tlearn: 38.1995065\ttotal: 5.21s\tremaining: 21s\n",
      "199:\tlearn: 38.1752575\ttotal: 5.24s\tremaining: 21s\n",
      "200:\tlearn: 38.1281437\ttotal: 5.26s\tremaining: 20.9s\n",
      "201:\tlearn: 38.1255551\ttotal: 5.28s\tremaining: 20.9s\n",
      "202:\tlearn: 38.0853045\ttotal: 5.3s\tremaining: 20.8s\n",
      "203:\tlearn: 38.0632474\ttotal: 5.33s\tremaining: 20.8s\n",
      "204:\tlearn: 38.0338732\ttotal: 5.36s\tremaining: 20.8s\n",
      "205:\tlearn: 37.9945449\ttotal: 5.38s\tremaining: 20.7s\n",
      "206:\tlearn: 37.9708490\ttotal: 5.41s\tremaining: 20.7s\n",
      "207:\tlearn: 37.8966364\ttotal: 5.43s\tremaining: 20.7s\n",
      "208:\tlearn: 37.8771378\ttotal: 5.46s\tremaining: 20.7s\n",
      "209:\tlearn: 37.8122505\ttotal: 5.48s\tremaining: 20.6s\n",
      "210:\tlearn: 37.7967074\ttotal: 5.51s\tremaining: 20.6s\n",
      "211:\tlearn: 37.6901606\ttotal: 5.53s\tremaining: 20.6s\n",
      "212:\tlearn: 37.6663270\ttotal: 5.55s\tremaining: 20.5s\n",
      "213:\tlearn: 37.5874747\ttotal: 5.58s\tremaining: 20.5s\n",
      "214:\tlearn: 37.5398521\ttotal: 5.6s\tremaining: 20.5s\n",
      "215:\tlearn: 37.4705832\ttotal: 5.63s\tremaining: 20.4s\n",
      "216:\tlearn: 37.4171522\ttotal: 5.67s\tremaining: 20.5s\n",
      "217:\tlearn: 37.3833265\ttotal: 5.71s\tremaining: 20.5s\n",
      "218:\tlearn: 37.3776146\ttotal: 5.73s\tremaining: 20.4s\n",
      "219:\tlearn: 37.3426373\ttotal: 5.76s\tremaining: 20.4s\n",
      "220:\tlearn: 37.2871394\ttotal: 5.78s\tremaining: 20.4s\n",
      "221:\tlearn: 37.2833708\ttotal: 5.8s\tremaining: 20.3s\n",
      "222:\tlearn: 37.2337540\ttotal: 5.83s\tremaining: 20.3s\n",
      "223:\tlearn: 37.1965490\ttotal: 5.85s\tremaining: 20.3s\n",
      "224:\tlearn: 37.1754006\ttotal: 5.88s\tremaining: 20.2s\n",
      "225:\tlearn: 37.1409233\ttotal: 5.9s\tremaining: 20.2s\n",
      "226:\tlearn: 37.0801941\ttotal: 5.93s\tremaining: 20.2s\n",
      "227:\tlearn: 37.0380961\ttotal: 5.95s\tremaining: 20.2s\n",
      "228:\tlearn: 37.0139079\ttotal: 5.98s\tremaining: 20.1s\n",
      "229:\tlearn: 36.9905658\ttotal: 6s\tremaining: 20.1s\n",
      "230:\tlearn: 36.9584576\ttotal: 6.04s\tremaining: 20.1s\n",
      "231:\tlearn: 36.9405633\ttotal: 6.06s\tremaining: 20.1s\n",
      "232:\tlearn: 36.8573723\ttotal: 6.09s\tremaining: 20.1s\n",
      "233:\tlearn: 36.8464495\ttotal: 6.12s\tremaining: 20s\n",
      "234:\tlearn: 36.8219349\ttotal: 6.15s\tremaining: 20s\n",
      "235:\tlearn: 36.7967873\ttotal: 6.17s\tremaining: 20s\n",
      "236:\tlearn: 36.7394523\ttotal: 6.2s\tremaining: 20s\n",
      "237:\tlearn: 36.6981441\ttotal: 6.23s\tremaining: 19.9s\n",
      "238:\tlearn: 36.6907944\ttotal: 6.25s\tremaining: 19.9s\n",
      "239:\tlearn: 36.6783641\ttotal: 6.27s\tremaining: 19.9s\n",
      "240:\tlearn: 36.6176520\ttotal: 6.29s\tremaining: 19.8s\n",
      "241:\tlearn: 36.5600619\ttotal: 6.32s\tremaining: 19.8s\n",
      "242:\tlearn: 36.5077902\ttotal: 6.35s\tremaining: 19.8s\n",
      "243:\tlearn: 36.4996860\ttotal: 6.38s\tremaining: 19.8s\n",
      "244:\tlearn: 36.4847223\ttotal: 6.4s\tremaining: 19.7s\n",
      "245:\tlearn: 36.4527239\ttotal: 6.44s\tremaining: 19.7s\n",
      "246:\tlearn: 36.4400480\ttotal: 6.46s\tremaining: 19.7s\n",
      "247:\tlearn: 36.4128976\ttotal: 6.49s\tremaining: 19.7s\n",
      "248:\tlearn: 36.4029637\ttotal: 6.52s\tremaining: 19.7s\n",
      "249:\tlearn: 36.3604317\ttotal: 6.54s\tremaining: 19.6s\n",
      "250:\tlearn: 36.3462005\ttotal: 6.57s\tremaining: 19.6s\n",
      "251:\tlearn: 36.3266377\ttotal: 6.6s\tremaining: 19.6s\n",
      "252:\tlearn: 36.3172857\ttotal: 6.63s\tremaining: 19.6s\n",
      "253:\tlearn: 36.2742126\ttotal: 6.66s\tremaining: 19.6s\n",
      "254:\tlearn: 36.2684285\ttotal: 6.68s\tremaining: 19.5s\n",
      "255:\tlearn: 36.2559066\ttotal: 6.71s\tremaining: 19.5s\n",
      "256:\tlearn: 36.2380839\ttotal: 6.74s\tremaining: 19.5s\n",
      "257:\tlearn: 36.1962813\ttotal: 6.77s\tremaining: 19.5s\n",
      "258:\tlearn: 36.1933845\ttotal: 6.79s\tremaining: 19.4s\n",
      "259:\tlearn: 36.1229735\ttotal: 6.83s\tremaining: 19.4s\n",
      "260:\tlearn: 36.0871418\ttotal: 6.86s\tremaining: 19.4s\n",
      "261:\tlearn: 36.0414551\ttotal: 6.9s\tremaining: 19.4s\n",
      "262:\tlearn: 36.0090200\ttotal: 6.92s\tremaining: 19.4s\n",
      "263:\tlearn: 35.9886240\ttotal: 6.95s\tremaining: 19.4s\n",
      "264:\tlearn: 35.9205141\ttotal: 6.99s\tremaining: 19.4s\n",
      "265:\tlearn: 35.8345700\ttotal: 7.03s\tremaining: 19.4s\n",
      "266:\tlearn: 35.8056430\ttotal: 7.05s\tremaining: 19.4s\n",
      "267:\tlearn: 35.7616711\ttotal: 7.08s\tremaining: 19.3s\n",
      "268:\tlearn: 35.7514754\ttotal: 7.11s\tremaining: 19.3s\n",
      "269:\tlearn: 35.7449600\ttotal: 7.13s\tremaining: 19.3s\n",
      "270:\tlearn: 35.7378809\ttotal: 7.15s\tremaining: 19.2s\n",
      "271:\tlearn: 35.7285771\ttotal: 7.18s\tremaining: 19.2s\n",
      "272:\tlearn: 35.6831397\ttotal: 7.21s\tremaining: 19.2s\n",
      "273:\tlearn: 35.5971732\ttotal: 7.24s\tremaining: 19.2s\n",
      "274:\tlearn: 35.5485955\ttotal: 7.26s\tremaining: 19.2s\n",
      "275:\tlearn: 35.5058236\ttotal: 7.29s\tremaining: 19.1s\n",
      "276:\tlearn: 35.4761615\ttotal: 7.31s\tremaining: 19.1s\n",
      "277:\tlearn: 35.4743606\ttotal: 7.33s\tremaining: 19s\n",
      "278:\tlearn: 35.4468126\ttotal: 7.36s\tremaining: 19s\n",
      "279:\tlearn: 35.4246270\ttotal: 7.38s\tremaining: 19s\n",
      "280:\tlearn: 35.3708701\ttotal: 7.41s\tremaining: 19s\n",
      "281:\tlearn: 35.3619328\ttotal: 7.43s\tremaining: 18.9s\n",
      "282:\tlearn: 35.3601391\ttotal: 7.45s\tremaining: 18.9s\n",
      "283:\tlearn: 35.2920433\ttotal: 7.48s\tremaining: 18.9s\n",
      "284:\tlearn: 35.2682319\ttotal: 7.5s\tremaining: 18.8s\n",
      "285:\tlearn: 35.2499917\ttotal: 7.52s\tremaining: 18.8s\n",
      "286:\tlearn: 35.2235723\ttotal: 7.54s\tremaining: 18.7s\n",
      "287:\tlearn: 35.2092346\ttotal: 7.57s\tremaining: 18.7s\n",
      "288:\tlearn: 35.1852120\ttotal: 7.6s\tremaining: 18.7s\n",
      "289:\tlearn: 35.1799200\ttotal: 7.62s\tremaining: 18.7s\n",
      "290:\tlearn: 35.1752854\ttotal: 7.65s\tremaining: 18.6s\n",
      "291:\tlearn: 35.1662822\ttotal: 7.67s\tremaining: 18.6s\n",
      "292:\tlearn: 35.1150012\ttotal: 7.7s\tremaining: 18.6s\n",
      "293:\tlearn: 35.0817512\ttotal: 7.73s\tremaining: 18.6s\n",
      "294:\tlearn: 35.0361807\ttotal: 7.76s\tremaining: 18.5s\n",
      "295:\tlearn: 35.0169596\ttotal: 7.78s\tremaining: 18.5s\n",
      "296:\tlearn: 34.8582611\ttotal: 7.82s\tremaining: 18.5s\n",
      "297:\tlearn: 34.8311077\ttotal: 7.84s\tremaining: 18.5s\n",
      "298:\tlearn: 34.7749311\ttotal: 7.87s\tremaining: 18.5s\n",
      "299:\tlearn: 34.7268183\ttotal: 7.91s\tremaining: 18.4s\n",
      "300:\tlearn: 34.7071002\ttotal: 7.93s\tremaining: 18.4s\n",
      "301:\tlearn: 34.6706114\ttotal: 7.97s\tremaining: 18.4s\n",
      "302:\tlearn: 34.6475166\ttotal: 8s\tremaining: 18.4s\n",
      "303:\tlearn: 34.6097636\ttotal: 8.03s\tremaining: 18.4s\n",
      "304:\tlearn: 34.6072725\ttotal: 8.05s\tremaining: 18.3s\n",
      "305:\tlearn: 34.6057674\ttotal: 8.07s\tremaining: 18.3s\n",
      "306:\tlearn: 34.5928650\ttotal: 8.09s\tremaining: 18.3s\n",
      "307:\tlearn: 34.5793700\ttotal: 8.12s\tremaining: 18.2s\n",
      "308:\tlearn: 34.5737926\ttotal: 8.14s\tremaining: 18.2s\n",
      "309:\tlearn: 34.5309643\ttotal: 8.17s\tremaining: 18.2s\n",
      "310:\tlearn: 34.5160948\ttotal: 8.2s\tremaining: 18.2s\n",
      "311:\tlearn: 34.4888108\ttotal: 8.23s\tremaining: 18.1s\n",
      "312:\tlearn: 34.4687796\ttotal: 8.26s\tremaining: 18.1s\n",
      "313:\tlearn: 34.4583519\ttotal: 8.28s\tremaining: 18.1s\n",
      "314:\tlearn: 34.4114685\ttotal: 8.31s\tremaining: 18.1s\n",
      "315:\tlearn: 34.3603848\ttotal: 8.34s\tremaining: 18s\n",
      "316:\tlearn: 34.3520847\ttotal: 8.36s\tremaining: 18s\n",
      "317:\tlearn: 34.3378573\ttotal: 8.39s\tremaining: 18s\n",
      "318:\tlearn: 34.3153943\ttotal: 8.42s\tremaining: 18s\n",
      "319:\tlearn: 34.2037662\ttotal: 8.45s\tremaining: 18s\n",
      "320:\tlearn: 34.1930972\ttotal: 8.47s\tremaining: 17.9s\n",
      "321:\tlearn: 34.1556866\ttotal: 8.5s\tremaining: 17.9s\n",
      "322:\tlearn: 34.1332433\ttotal: 8.52s\tremaining: 17.9s\n",
      "323:\tlearn: 34.0900859\ttotal: 8.55s\tremaining: 17.8s\n",
      "324:\tlearn: 34.0434825\ttotal: 8.57s\tremaining: 17.8s\n",
      "325:\tlearn: 34.0086887\ttotal: 8.6s\tremaining: 17.8s\n",
      "326:\tlearn: 33.9960346\ttotal: 8.62s\tremaining: 17.7s\n",
      "327:\tlearn: 33.9657756\ttotal: 8.65s\tremaining: 17.7s\n",
      "328:\tlearn: 33.9355614\ttotal: 8.67s\tremaining: 17.7s\n",
      "329:\tlearn: 33.9006615\ttotal: 8.7s\tremaining: 17.7s\n",
      "330:\tlearn: 33.8701317\ttotal: 8.72s\tremaining: 17.6s\n",
      "331:\tlearn: 33.8554527\ttotal: 8.75s\tremaining: 17.6s\n",
      "332:\tlearn: 33.8487900\ttotal: 8.77s\tremaining: 17.6s\n",
      "333:\tlearn: 33.8332589\ttotal: 8.8s\tremaining: 17.5s\n",
      "334:\tlearn: 33.8318268\ttotal: 8.82s\tremaining: 17.5s\n",
      "335:\tlearn: 33.7910255\ttotal: 8.84s\tremaining: 17.5s\n",
      "336:\tlearn: 33.7805587\ttotal: 8.87s\tremaining: 17.4s\n",
      "337:\tlearn: 33.7568022\ttotal: 8.89s\tremaining: 17.4s\n",
      "338:\tlearn: 33.7175215\ttotal: 8.92s\tremaining: 17.4s\n",
      "339:\tlearn: 33.7077678\ttotal: 8.95s\tremaining: 17.4s\n",
      "340:\tlearn: 33.7048881\ttotal: 8.97s\tremaining: 17.3s\n",
      "341:\tlearn: 33.7028277\ttotal: 8.99s\tremaining: 17.3s\n",
      "342:\tlearn: 33.6590134\ttotal: 9.02s\tremaining: 17.3s\n",
      "343:\tlearn: 33.6436993\ttotal: 9.04s\tremaining: 17.2s\n",
      "344:\tlearn: 33.6135553\ttotal: 9.07s\tremaining: 17.2s\n",
      "345:\tlearn: 33.5790279\ttotal: 9.1s\tremaining: 17.2s\n",
      "346:\tlearn: 33.5591078\ttotal: 9.13s\tremaining: 17.2s\n",
      "347:\tlearn: 33.5099799\ttotal: 9.16s\tremaining: 17.2s\n",
      "348:\tlearn: 33.4885211\ttotal: 9.19s\tremaining: 17.1s\n",
      "349:\tlearn: 33.4859238\ttotal: 9.21s\tremaining: 17.1s\n",
      "350:\tlearn: 33.4712048\ttotal: 9.24s\tremaining: 17.1s\n",
      "351:\tlearn: 33.4577825\ttotal: 9.27s\tremaining: 17.1s\n",
      "352:\tlearn: 33.3827230\ttotal: 9.3s\tremaining: 17s\n",
      "353:\tlearn: 33.3686700\ttotal: 9.33s\tremaining: 17s\n",
      "354:\tlearn: 33.3633140\ttotal: 9.35s\tremaining: 17s\n",
      "355:\tlearn: 33.3602081\ttotal: 9.38s\tremaining: 17s\n",
      "356:\tlearn: 33.3472333\ttotal: 9.4s\tremaining: 16.9s\n",
      "357:\tlearn: 33.3262045\ttotal: 9.42s\tremaining: 16.9s\n",
      "358:\tlearn: 33.3246060\ttotal: 9.44s\tremaining: 16.9s\n",
      "359:\tlearn: 33.3120256\ttotal: 9.47s\tremaining: 16.8s\n",
      "360:\tlearn: 33.2627849\ttotal: 9.49s\tremaining: 16.8s\n",
      "361:\tlearn: 33.2547424\ttotal: 9.52s\tremaining: 16.8s\n",
      "362:\tlearn: 33.2366487\ttotal: 9.54s\tremaining: 16.7s\n",
      "363:\tlearn: 33.1926001\ttotal: 9.56s\tremaining: 16.7s\n",
      "364:\tlearn: 33.1907116\ttotal: 9.58s\tremaining: 16.7s\n",
      "365:\tlearn: 33.1765061\ttotal: 9.61s\tremaining: 16.6s\n",
      "366:\tlearn: 33.1733922\ttotal: 9.63s\tremaining: 16.6s\n",
      "367:\tlearn: 33.1706485\ttotal: 9.65s\tremaining: 16.6s\n",
      "368:\tlearn: 33.1664620\ttotal: 9.67s\tremaining: 16.5s\n",
      "369:\tlearn: 33.1454304\ttotal: 9.7s\tremaining: 16.5s\n",
      "370:\tlearn: 33.1269085\ttotal: 9.72s\tremaining: 16.5s\n",
      "371:\tlearn: 33.1032598\ttotal: 9.75s\tremaining: 16.5s\n",
      "372:\tlearn: 33.0897654\ttotal: 9.78s\tremaining: 16.4s\n",
      "373:\tlearn: 33.0823542\ttotal: 9.81s\tremaining: 16.4s\n",
      "374:\tlearn: 33.0612406\ttotal: 9.84s\tremaining: 16.4s\n",
      "375:\tlearn: 33.0600353\ttotal: 9.86s\tremaining: 16.4s\n",
      "376:\tlearn: 33.0349198\ttotal: 9.89s\tremaining: 16.3s\n",
      "377:\tlearn: 33.0287369\ttotal: 9.92s\tremaining: 16.3s\n",
      "378:\tlearn: 32.9704262\ttotal: 9.97s\tremaining: 16.3s\n",
      "379:\tlearn: 32.9602907\ttotal: 10s\tremaining: 16.3s\n",
      "380:\tlearn: 32.9061322\ttotal: 10s\tremaining: 16.3s\n",
      "381:\tlearn: 32.9037502\ttotal: 10.1s\tremaining: 16.3s\n",
      "382:\tlearn: 32.8899342\ttotal: 10.1s\tremaining: 16.3s\n",
      "383:\tlearn: 32.8692362\ttotal: 10.1s\tremaining: 16.2s\n",
      "384:\tlearn: 32.8529191\ttotal: 10.1s\tremaining: 16.2s\n",
      "385:\tlearn: 32.8070743\ttotal: 10.2s\tremaining: 16.2s\n",
      "386:\tlearn: 32.7979483\ttotal: 10.2s\tremaining: 16.2s\n",
      "387:\tlearn: 32.7859078\ttotal: 10.2s\tremaining: 16.1s\n",
      "388:\tlearn: 32.7674975\ttotal: 10.3s\tremaining: 16.1s\n",
      "389:\tlearn: 32.7647894\ttotal: 10.3s\tremaining: 16.1s\n",
      "390:\tlearn: 32.7307638\ttotal: 10.3s\tremaining: 16.1s\n",
      "391:\tlearn: 32.7241009\ttotal: 10.3s\tremaining: 16s\n",
      "392:\tlearn: 32.6969289\ttotal: 10.4s\tremaining: 16s\n",
      "393:\tlearn: 32.6610376\ttotal: 10.4s\tremaining: 16s\n",
      "394:\tlearn: 32.6600100\ttotal: 10.4s\tremaining: 16s\n",
      "395:\tlearn: 32.6339001\ttotal: 10.4s\tremaining: 15.9s\n",
      "396:\tlearn: 32.6209621\ttotal: 10.5s\tremaining: 15.9s\n",
      "397:\tlearn: 32.6198859\ttotal: 10.5s\tremaining: 15.9s\n",
      "398:\tlearn: 32.5933891\ttotal: 10.5s\tremaining: 15.8s\n",
      "399:\tlearn: 32.5725756\ttotal: 10.5s\tremaining: 15.8s\n",
      "400:\tlearn: 32.5598370\ttotal: 10.6s\tremaining: 15.8s\n",
      "401:\tlearn: 32.5481156\ttotal: 10.6s\tremaining: 15.8s\n",
      "402:\tlearn: 32.5195869\ttotal: 10.6s\tremaining: 15.8s\n",
      "403:\tlearn: 32.4868642\ttotal: 10.7s\tremaining: 15.8s\n",
      "404:\tlearn: 32.4835042\ttotal: 10.7s\tremaining: 15.7s\n",
      "405:\tlearn: 32.4487684\ttotal: 10.7s\tremaining: 15.7s\n",
      "406:\tlearn: 32.4460652\ttotal: 10.8s\tremaining: 15.7s\n",
      "407:\tlearn: 32.4265088\ttotal: 10.8s\tremaining: 15.7s\n",
      "408:\tlearn: 32.3811788\ttotal: 10.8s\tremaining: 15.7s\n",
      "409:\tlearn: 32.3793098\ttotal: 10.9s\tremaining: 15.6s\n",
      "410:\tlearn: 32.3768855\ttotal: 10.9s\tremaining: 15.6s\n",
      "411:\tlearn: 32.3729805\ttotal: 10.9s\tremaining: 15.6s\n",
      "412:\tlearn: 32.3477068\ttotal: 10.9s\tremaining: 15.6s\n",
      "413:\tlearn: 32.3289381\ttotal: 11s\tremaining: 15.5s\n",
      "414:\tlearn: 32.3194790\ttotal: 11s\tremaining: 15.5s\n",
      "415:\tlearn: 32.2854519\ttotal: 11s\tremaining: 15.5s\n",
      "416:\tlearn: 32.2822343\ttotal: 11s\tremaining: 15.4s\n",
      "417:\tlearn: 32.2554298\ttotal: 11.1s\tremaining: 15.4s\n",
      "418:\tlearn: 32.2406960\ttotal: 11.1s\tremaining: 15.4s\n",
      "419:\tlearn: 32.2277395\ttotal: 11.1s\tremaining: 15.4s\n",
      "420:\tlearn: 32.1124631\ttotal: 11.2s\tremaining: 15.3s\n",
      "421:\tlearn: 32.0895945\ttotal: 11.2s\tremaining: 15.3s\n",
      "422:\tlearn: 32.0847429\ttotal: 11.2s\tremaining: 15.3s\n",
      "423:\tlearn: 32.0823012\ttotal: 11.2s\tremaining: 15.3s\n",
      "424:\tlearn: 32.0748131\ttotal: 11.3s\tremaining: 15.2s\n",
      "425:\tlearn: 32.0732247\ttotal: 11.3s\tremaining: 15.2s\n",
      "426:\tlearn: 32.0541578\ttotal: 11.3s\tremaining: 15.2s\n",
      "427:\tlearn: 32.0533261\ttotal: 11.3s\tremaining: 15.1s\n",
      "428:\tlearn: 32.0391985\ttotal: 11.4s\tremaining: 15.1s\n",
      "429:\tlearn: 32.0356766\ttotal: 11.4s\tremaining: 15.1s\n",
      "430:\tlearn: 32.0291547\ttotal: 11.4s\tremaining: 15.1s\n",
      "431:\tlearn: 32.0095311\ttotal: 11.4s\tremaining: 15s\n",
      "432:\tlearn: 31.9760621\ttotal: 11.5s\tremaining: 15s\n",
      "433:\tlearn: 31.9735114\ttotal: 11.5s\tremaining: 15s\n",
      "434:\tlearn: 31.9602517\ttotal: 11.5s\tremaining: 15s\n",
      "435:\tlearn: 31.9595084\ttotal: 11.5s\tremaining: 14.9s\n",
      "436:\tlearn: 31.9431260\ttotal: 11.6s\tremaining: 14.9s\n",
      "437:\tlearn: 31.9315547\ttotal: 11.6s\tremaining: 14.9s\n",
      "438:\tlearn: 31.9125148\ttotal: 11.6s\tremaining: 14.8s\n",
      "439:\tlearn: 31.9111003\ttotal: 11.6s\tremaining: 14.8s\n",
      "440:\tlearn: 31.8959244\ttotal: 11.7s\tremaining: 14.8s\n",
      "441:\tlearn: 31.8892346\ttotal: 11.7s\tremaining: 14.8s\n",
      "442:\tlearn: 31.8865918\ttotal: 11.7s\tremaining: 14.7s\n",
      "443:\tlearn: 31.8840906\ttotal: 11.7s\tremaining: 14.7s\n",
      "444:\tlearn: 31.8780238\ttotal: 11.8s\tremaining: 14.7s\n",
      "445:\tlearn: 31.8471436\ttotal: 11.8s\tremaining: 14.7s\n",
      "446:\tlearn: 31.8415387\ttotal: 11.8s\tremaining: 14.6s\n",
      "447:\tlearn: 31.8226386\ttotal: 11.8s\tremaining: 14.6s\n",
      "448:\tlearn: 31.8153102\ttotal: 11.9s\tremaining: 14.6s\n",
      "449:\tlearn: 31.8050890\ttotal: 11.9s\tremaining: 14.5s\n",
      "450:\tlearn: 31.8026571\ttotal: 11.9s\tremaining: 14.5s\n",
      "451:\tlearn: 31.8003956\ttotal: 11.9s\tremaining: 14.5s\n",
      "452:\tlearn: 31.7982893\ttotal: 12s\tremaining: 14.5s\n",
      "453:\tlearn: 31.7967215\ttotal: 12s\tremaining: 14.4s\n",
      "454:\tlearn: 31.7522832\ttotal: 12s\tremaining: 14.4s\n",
      "455:\tlearn: 31.7518202\ttotal: 12s\tremaining: 14.4s\n",
      "456:\tlearn: 31.7355043\ttotal: 12.1s\tremaining: 14.3s\n",
      "457:\tlearn: 31.7150464\ttotal: 12.1s\tremaining: 14.3s\n",
      "458:\tlearn: 31.6996563\ttotal: 12.1s\tremaining: 14.3s\n",
      "459:\tlearn: 31.6793186\ttotal: 12.1s\tremaining: 14.3s\n",
      "460:\tlearn: 31.6725589\ttotal: 12.2s\tremaining: 14.2s\n",
      "461:\tlearn: 31.6697833\ttotal: 12.2s\tremaining: 14.2s\n",
      "462:\tlearn: 31.6689736\ttotal: 12.2s\tremaining: 14.2s\n",
      "463:\tlearn: 31.6685510\ttotal: 12.2s\tremaining: 14.1s\n",
      "464:\tlearn: 31.6477955\ttotal: 12.3s\tremaining: 14.1s\n",
      "465:\tlearn: 31.6338657\ttotal: 12.3s\tremaining: 14.1s\n",
      "466:\tlearn: 31.6256657\ttotal: 12.3s\tremaining: 14.1s\n",
      "467:\tlearn: 31.6136731\ttotal: 12.3s\tremaining: 14s\n",
      "468:\tlearn: 31.6108219\ttotal: 12.4s\tremaining: 14s\n",
      "469:\tlearn: 31.6087597\ttotal: 12.4s\tremaining: 14s\n",
      "470:\tlearn: 31.5964754\ttotal: 12.4s\tremaining: 14s\n",
      "471:\tlearn: 31.5945734\ttotal: 12.4s\tremaining: 13.9s\n",
      "472:\tlearn: 31.5904791\ttotal: 12.5s\tremaining: 13.9s\n",
      "473:\tlearn: 31.5884317\ttotal: 12.5s\tremaining: 13.9s\n",
      "474:\tlearn: 31.5868894\ttotal: 12.5s\tremaining: 13.8s\n",
      "475:\tlearn: 31.5669555\ttotal: 12.6s\tremaining: 13.8s\n",
      "476:\tlearn: 31.5611937\ttotal: 12.6s\tremaining: 13.8s\n",
      "477:\tlearn: 31.5446072\ttotal: 12.6s\tremaining: 13.8s\n",
      "478:\tlearn: 31.4541679\ttotal: 12.6s\tremaining: 13.7s\n",
      "479:\tlearn: 31.4263686\ttotal: 12.7s\tremaining: 13.7s\n",
      "480:\tlearn: 31.3980139\ttotal: 12.7s\tremaining: 13.7s\n",
      "481:\tlearn: 31.3916877\ttotal: 12.7s\tremaining: 13.7s\n",
      "482:\tlearn: 31.3820013\ttotal: 12.7s\tremaining: 13.6s\n",
      "483:\tlearn: 31.3800710\ttotal: 12.8s\tremaining: 13.6s\n",
      "484:\tlearn: 31.3782692\ttotal: 12.8s\tremaining: 13.6s\n",
      "485:\tlearn: 31.3763161\ttotal: 12.8s\tremaining: 13.5s\n",
      "486:\tlearn: 31.3331434\ttotal: 12.8s\tremaining: 13.5s\n",
      "487:\tlearn: 31.3103060\ttotal: 12.9s\tremaining: 13.5s\n",
      "488:\tlearn: 31.2548991\ttotal: 12.9s\tremaining: 13.5s\n",
      "489:\tlearn: 31.2272948\ttotal: 12.9s\tremaining: 13.4s\n",
      "490:\tlearn: 31.2005281\ttotal: 13s\tremaining: 13.4s\n",
      "491:\tlearn: 31.1657422\ttotal: 13s\tremaining: 13.4s\n",
      "492:\tlearn: 31.1641611\ttotal: 13s\tremaining: 13.4s\n",
      "493:\tlearn: 31.1575850\ttotal: 13s\tremaining: 13.4s\n",
      "494:\tlearn: 31.1553617\ttotal: 13.1s\tremaining: 13.3s\n",
      "495:\tlearn: 31.1448368\ttotal: 13.1s\tremaining: 13.3s\n",
      "496:\tlearn: 31.1431749\ttotal: 13.1s\tremaining: 13.3s\n",
      "497:\tlearn: 31.1340320\ttotal: 13.1s\tremaining: 13.2s\n",
      "498:\tlearn: 31.0893976\ttotal: 13.2s\tremaining: 13.2s\n",
      "499:\tlearn: 31.0546560\ttotal: 13.2s\tremaining: 13.2s\n",
      "500:\tlearn: 31.0461699\ttotal: 13.2s\tremaining: 13.2s\n",
      "501:\tlearn: 31.0401426\ttotal: 13.2s\tremaining: 13.1s\n",
      "502:\tlearn: 31.0294855\ttotal: 13.3s\tremaining: 13.1s\n",
      "503:\tlearn: 31.0091317\ttotal: 13.3s\tremaining: 13.1s\n",
      "504:\tlearn: 31.0078250\ttotal: 13.3s\tremaining: 13s\n",
      "505:\tlearn: 30.9811330\ttotal: 13.3s\tremaining: 13s\n",
      "506:\tlearn: 30.9559771\ttotal: 13.4s\tremaining: 13s\n",
      "507:\tlearn: 30.9311229\ttotal: 13.4s\tremaining: 13s\n",
      "508:\tlearn: 30.9232009\ttotal: 13.4s\tremaining: 12.9s\n",
      "509:\tlearn: 30.9227125\ttotal: 13.4s\tremaining: 12.9s\n",
      "510:\tlearn: 30.9173890\ttotal: 13.5s\tremaining: 12.9s\n",
      "511:\tlearn: 30.8657301\ttotal: 13.5s\tremaining: 12.9s\n",
      "512:\tlearn: 30.8590976\ttotal: 13.5s\tremaining: 12.8s\n",
      "513:\tlearn: 30.8557868\ttotal: 13.6s\tremaining: 12.8s\n",
      "514:\tlearn: 30.8511222\ttotal: 13.6s\tremaining: 12.8s\n",
      "515:\tlearn: 30.8434646\ttotal: 13.6s\tremaining: 12.8s\n",
      "516:\tlearn: 30.8159108\ttotal: 13.6s\tremaining: 12.8s\n",
      "517:\tlearn: 30.7788135\ttotal: 13.7s\tremaining: 12.7s\n",
      "518:\tlearn: 30.7775429\ttotal: 13.7s\tremaining: 12.7s\n",
      "519:\tlearn: 30.7483555\ttotal: 13.7s\tremaining: 12.7s\n",
      "520:\tlearn: 30.7411725\ttotal: 13.8s\tremaining: 12.6s\n",
      "521:\tlearn: 30.7203281\ttotal: 13.8s\tremaining: 12.6s\n",
      "522:\tlearn: 30.7181919\ttotal: 13.8s\tremaining: 12.6s\n",
      "523:\tlearn: 30.6998386\ttotal: 13.8s\tremaining: 12.6s\n",
      "524:\tlearn: 30.6846777\ttotal: 13.9s\tremaining: 12.5s\n",
      "525:\tlearn: 30.6674628\ttotal: 13.9s\tremaining: 12.5s\n",
      "526:\tlearn: 30.6610168\ttotal: 13.9s\tremaining: 12.5s\n",
      "527:\tlearn: 30.6375414\ttotal: 13.9s\tremaining: 12.5s\n",
      "528:\tlearn: 30.6288468\ttotal: 14s\tremaining: 12.4s\n",
      "529:\tlearn: 30.6257863\ttotal: 14s\tremaining: 12.4s\n",
      "530:\tlearn: 30.6003472\ttotal: 14s\tremaining: 12.4s\n",
      "531:\tlearn: 30.5966671\ttotal: 14s\tremaining: 12.3s\n",
      "532:\tlearn: 30.5837101\ttotal: 14.1s\tremaining: 12.3s\n",
      "533:\tlearn: 30.5779144\ttotal: 14.1s\tremaining: 12.3s\n",
      "534:\tlearn: 30.5759640\ttotal: 14.1s\tremaining: 12.3s\n",
      "535:\tlearn: 30.5735521\ttotal: 14.1s\tremaining: 12.2s\n",
      "536:\tlearn: 30.5716572\ttotal: 14.2s\tremaining: 12.2s\n",
      "537:\tlearn: 30.5658833\ttotal: 14.2s\tremaining: 12.2s\n",
      "538:\tlearn: 30.5530387\ttotal: 14.2s\tremaining: 12.2s\n",
      "539:\tlearn: 30.5480295\ttotal: 14.2s\tremaining: 12.1s\n",
      "540:\tlearn: 30.4354309\ttotal: 14.3s\tremaining: 12.1s\n",
      "541:\tlearn: 30.4114001\ttotal: 14.3s\tremaining: 12.1s\n",
      "542:\tlearn: 30.4096201\ttotal: 14.3s\tremaining: 12.1s\n",
      "543:\tlearn: 30.4080959\ttotal: 14.3s\tremaining: 12s\n",
      "544:\tlearn: 30.3961492\ttotal: 14.4s\tremaining: 12s\n",
      "545:\tlearn: 30.3819126\ttotal: 14.4s\tremaining: 12s\n",
      "546:\tlearn: 30.3754196\ttotal: 14.4s\tremaining: 11.9s\n",
      "547:\tlearn: 30.3744411\ttotal: 14.4s\tremaining: 11.9s\n",
      "548:\tlearn: 30.3344989\ttotal: 14.5s\tremaining: 11.9s\n",
      "549:\tlearn: 30.3279711\ttotal: 14.5s\tremaining: 11.8s\n",
      "550:\tlearn: 30.3275923\ttotal: 14.5s\tremaining: 11.8s\n",
      "551:\tlearn: 30.3190065\ttotal: 14.5s\tremaining: 11.8s\n",
      "552:\tlearn: 30.2833688\ttotal: 14.6s\tremaining: 11.8s\n",
      "553:\tlearn: 30.2505298\ttotal: 14.6s\tremaining: 11.7s\n",
      "554:\tlearn: 30.2486108\ttotal: 14.6s\tremaining: 11.7s\n",
      "555:\tlearn: 30.2212199\ttotal: 14.6s\tremaining: 11.7s\n",
      "556:\tlearn: 30.2189533\ttotal: 14.7s\tremaining: 11.7s\n",
      "557:\tlearn: 30.2075148\ttotal: 14.7s\tremaining: 11.6s\n",
      "558:\tlearn: 30.1873109\ttotal: 14.7s\tremaining: 11.6s\n",
      "559:\tlearn: 30.1658315\ttotal: 14.7s\tremaining: 11.6s\n",
      "560:\tlearn: 30.1637826\ttotal: 14.8s\tremaining: 11.5s\n",
      "561:\tlearn: 30.1367070\ttotal: 14.8s\tremaining: 11.5s\n",
      "562:\tlearn: 30.1358414\ttotal: 14.8s\tremaining: 11.5s\n",
      "563:\tlearn: 30.1135044\ttotal: 14.8s\tremaining: 11.5s\n",
      "564:\tlearn: 30.0953757\ttotal: 14.9s\tremaining: 11.4s\n",
      "565:\tlearn: 30.0931985\ttotal: 14.9s\tremaining: 11.4s\n",
      "566:\tlearn: 30.0720738\ttotal: 14.9s\tremaining: 11.4s\n",
      "567:\tlearn: 30.0712225\ttotal: 14.9s\tremaining: 11.4s\n",
      "568:\tlearn: 30.0314088\ttotal: 15s\tremaining: 11.3s\n",
      "569:\tlearn: 30.0154719\ttotal: 15s\tremaining: 11.3s\n",
      "570:\tlearn: 29.9909958\ttotal: 15s\tremaining: 11.3s\n",
      "571:\tlearn: 29.9886115\ttotal: 15s\tremaining: 11.2s\n",
      "572:\tlearn: 29.9776635\ttotal: 15.1s\tremaining: 11.2s\n",
      "573:\tlearn: 29.9764756\ttotal: 15.1s\tremaining: 11.2s\n",
      "574:\tlearn: 29.9753969\ttotal: 15.1s\tremaining: 11.2s\n",
      "575:\tlearn: 29.9703095\ttotal: 15.1s\tremaining: 11.1s\n",
      "576:\tlearn: 29.9510631\ttotal: 15.2s\tremaining: 11.1s\n",
      "577:\tlearn: 29.9295098\ttotal: 15.2s\tremaining: 11.1s\n",
      "578:\tlearn: 29.9065621\ttotal: 15.2s\tremaining: 11.1s\n",
      "579:\tlearn: 29.9053685\ttotal: 15.2s\tremaining: 11s\n",
      "580:\tlearn: 29.8890570\ttotal: 15.2s\tremaining: 11s\n",
      "581:\tlearn: 29.8801329\ttotal: 15.3s\tremaining: 11s\n",
      "582:\tlearn: 29.8607711\ttotal: 15.3s\tremaining: 10.9s\n",
      "583:\tlearn: 29.8182617\ttotal: 15.3s\tremaining: 10.9s\n",
      "584:\tlearn: 29.8005210\ttotal: 15.4s\tremaining: 10.9s\n",
      "585:\tlearn: 29.7886446\ttotal: 15.4s\tremaining: 10.9s\n",
      "586:\tlearn: 29.7877231\ttotal: 15.4s\tremaining: 10.8s\n",
      "587:\tlearn: 29.7864421\ttotal: 15.4s\tremaining: 10.8s\n",
      "588:\tlearn: 29.7775742\ttotal: 15.5s\tremaining: 10.8s\n",
      "589:\tlearn: 29.7711077\ttotal: 15.5s\tremaining: 10.8s\n",
      "590:\tlearn: 29.7587097\ttotal: 15.5s\tremaining: 10.7s\n",
      "591:\tlearn: 29.7573232\ttotal: 15.5s\tremaining: 10.7s\n",
      "592:\tlearn: 29.7408728\ttotal: 15.6s\tremaining: 10.7s\n",
      "593:\tlearn: 29.7396859\ttotal: 15.6s\tremaining: 10.6s\n",
      "594:\tlearn: 29.7262979\ttotal: 15.6s\tremaining: 10.6s\n",
      "595:\tlearn: 29.7249167\ttotal: 15.6s\tremaining: 10.6s\n",
      "596:\tlearn: 29.7213697\ttotal: 15.7s\tremaining: 10.6s\n",
      "597:\tlearn: 29.6343927\ttotal: 15.7s\tremaining: 10.5s\n",
      "598:\tlearn: 29.6317842\ttotal: 15.7s\tremaining: 10.5s\n",
      "599:\tlearn: 29.6239327\ttotal: 15.7s\tremaining: 10.5s\n",
      "600:\tlearn: 29.6199643\ttotal: 15.7s\tremaining: 10.5s\n",
      "601:\tlearn: 29.6186425\ttotal: 15.8s\tremaining: 10.4s\n",
      "602:\tlearn: 29.6142714\ttotal: 15.8s\tremaining: 10.4s\n",
      "603:\tlearn: 29.6126386\ttotal: 15.8s\tremaining: 10.4s\n",
      "604:\tlearn: 29.6109064\ttotal: 15.8s\tremaining: 10.3s\n",
      "605:\tlearn: 29.5782112\ttotal: 15.9s\tremaining: 10.3s\n",
      "606:\tlearn: 29.5741819\ttotal: 15.9s\tremaining: 10.3s\n",
      "607:\tlearn: 29.5648685\ttotal: 15.9s\tremaining: 10.3s\n",
      "608:\tlearn: 29.5480369\ttotal: 15.9s\tremaining: 10.2s\n",
      "609:\tlearn: 29.5461668\ttotal: 15.9s\tremaining: 10.2s\n",
      "610:\tlearn: 29.5345330\ttotal: 16s\tremaining: 10.2s\n",
      "611:\tlearn: 29.5335678\ttotal: 16s\tremaining: 10.1s\n",
      "612:\tlearn: 29.5188693\ttotal: 16s\tremaining: 10.1s\n",
      "613:\tlearn: 29.5113235\ttotal: 16.1s\tremaining: 10.1s\n",
      "614:\tlearn: 29.5101171\ttotal: 16.1s\tremaining: 10.1s\n",
      "615:\tlearn: 29.5088526\ttotal: 16.1s\tremaining: 10s\n",
      "616:\tlearn: 29.5073423\ttotal: 16.1s\tremaining: 10s\n",
      "617:\tlearn: 29.5047987\ttotal: 16.1s\tremaining: 9.98s\n",
      "618:\tlearn: 29.5035207\ttotal: 16.2s\tremaining: 9.95s\n",
      "619:\tlearn: 29.5023968\ttotal: 16.2s\tremaining: 9.92s\n",
      "620:\tlearn: 29.4857925\ttotal: 16.2s\tremaining: 9.9s\n",
      "621:\tlearn: 29.4795581\ttotal: 16.2s\tremaining: 9.87s\n",
      "622:\tlearn: 29.4631223\ttotal: 16.3s\tremaining: 9.84s\n",
      "623:\tlearn: 29.4578523\ttotal: 16.3s\tremaining: 9.82s\n",
      "624:\tlearn: 29.4514433\ttotal: 16.3s\tremaining: 9.79s\n",
      "625:\tlearn: 29.4511818\ttotal: 16.3s\tremaining: 9.76s\n",
      "626:\tlearn: 29.4408225\ttotal: 16.4s\tremaining: 9.73s\n",
      "627:\tlearn: 29.4333677\ttotal: 16.4s\tremaining: 9.7s\n",
      "628:\tlearn: 29.4208622\ttotal: 16.4s\tremaining: 9.68s\n",
      "629:\tlearn: 29.4050765\ttotal: 16.4s\tremaining: 9.65s\n",
      "630:\tlearn: 29.3980838\ttotal: 16.5s\tremaining: 9.62s\n",
      "631:\tlearn: 29.3807558\ttotal: 16.5s\tremaining: 9.6s\n",
      "632:\tlearn: 29.3783945\ttotal: 16.5s\tremaining: 9.57s\n",
      "633:\tlearn: 29.3769423\ttotal: 16.5s\tremaining: 9.54s\n",
      "634:\tlearn: 29.3600670\ttotal: 16.5s\tremaining: 9.51s\n",
      "635:\tlearn: 29.3589902\ttotal: 16.6s\tremaining: 9.48s\n",
      "636:\tlearn: 29.3430611\ttotal: 16.6s\tremaining: 9.46s\n",
      "637:\tlearn: 29.3161171\ttotal: 16.6s\tremaining: 9.43s\n",
      "638:\tlearn: 29.3155238\ttotal: 16.6s\tremaining: 9.4s\n",
      "639:\tlearn: 29.2922428\ttotal: 16.7s\tremaining: 9.37s\n",
      "640:\tlearn: 29.2808427\ttotal: 16.7s\tremaining: 9.35s\n",
      "641:\tlearn: 29.2685904\ttotal: 16.7s\tremaining: 9.32s\n",
      "642:\tlearn: 29.2643204\ttotal: 16.7s\tremaining: 9.29s\n",
      "643:\tlearn: 29.2571536\ttotal: 16.8s\tremaining: 9.27s\n",
      "644:\tlearn: 29.2510903\ttotal: 16.8s\tremaining: 9.24s\n",
      "645:\tlearn: 29.2487365\ttotal: 16.8s\tremaining: 9.21s\n",
      "646:\tlearn: 29.2406326\ttotal: 16.8s\tremaining: 9.18s\n",
      "647:\tlearn: 29.2108256\ttotal: 16.9s\tremaining: 9.16s\n",
      "648:\tlearn: 29.1869135\ttotal: 16.9s\tremaining: 9.13s\n",
      "649:\tlearn: 29.1798350\ttotal: 16.9s\tremaining: 9.1s\n",
      "650:\tlearn: 29.1649222\ttotal: 16.9s\tremaining: 9.08s\n",
      "651:\tlearn: 29.1560934\ttotal: 17s\tremaining: 9.05s\n",
      "652:\tlearn: 29.1540198\ttotal: 17s\tremaining: 9.02s\n",
      "653:\tlearn: 29.1494431\ttotal: 17s\tremaining: 8.99s\n",
      "654:\tlearn: 29.1361721\ttotal: 17s\tremaining: 8.97s\n",
      "655:\tlearn: 29.1140421\ttotal: 17.1s\tremaining: 8.94s\n",
      "656:\tlearn: 29.0820082\ttotal: 17.1s\tremaining: 8.92s\n",
      "657:\tlearn: 29.0809751\ttotal: 17.1s\tremaining: 8.89s\n",
      "658:\tlearn: 29.0795122\ttotal: 17.1s\tremaining: 8.86s\n",
      "659:\tlearn: 29.0478520\ttotal: 17.1s\tremaining: 8.83s\n",
      "660:\tlearn: 29.0245901\ttotal: 17.2s\tremaining: 8.81s\n",
      "661:\tlearn: 29.0235337\ttotal: 17.2s\tremaining: 8.78s\n",
      "662:\tlearn: 29.0080188\ttotal: 17.2s\tremaining: 8.75s\n",
      "663:\tlearn: 29.0058914\ttotal: 17.2s\tremaining: 8.72s\n",
      "664:\tlearn: 29.0041708\ttotal: 17.3s\tremaining: 8.69s\n",
      "665:\tlearn: 28.9673436\ttotal: 17.3s\tremaining: 8.67s\n",
      "666:\tlearn: 28.9585361\ttotal: 17.3s\tremaining: 8.64s\n",
      "667:\tlearn: 28.9539598\ttotal: 17.3s\tremaining: 8.61s\n",
      "668:\tlearn: 28.9512149\ttotal: 17.3s\tremaining: 8.58s\n",
      "669:\tlearn: 28.9500552\ttotal: 17.4s\tremaining: 8.55s\n",
      "670:\tlearn: 28.9444115\ttotal: 17.4s\tremaining: 8.53s\n",
      "671:\tlearn: 28.9429483\ttotal: 17.4s\tremaining: 8.5s\n",
      "672:\tlearn: 28.9399028\ttotal: 17.4s\tremaining: 8.47s\n",
      "673:\tlearn: 28.9396745\ttotal: 17.5s\tremaining: 8.44s\n",
      "674:\tlearn: 28.9080204\ttotal: 17.5s\tremaining: 8.42s\n",
      "675:\tlearn: 28.9040256\ttotal: 17.5s\tremaining: 8.39s\n",
      "676:\tlearn: 28.8978683\ttotal: 17.5s\tremaining: 8.37s\n",
      "677:\tlearn: 28.8956914\ttotal: 17.6s\tremaining: 8.34s\n",
      "678:\tlearn: 28.8820571\ttotal: 17.6s\tremaining: 8.31s\n",
      "679:\tlearn: 28.8802174\ttotal: 17.6s\tremaining: 8.28s\n",
      "680:\tlearn: 28.8785829\ttotal: 17.6s\tremaining: 8.26s\n",
      "681:\tlearn: 28.8717498\ttotal: 17.6s\tremaining: 8.23s\n",
      "682:\tlearn: 28.8472390\ttotal: 17.7s\tremaining: 8.2s\n",
      "683:\tlearn: 28.8460763\ttotal: 17.7s\tremaining: 8.17s\n",
      "684:\tlearn: 28.8305948\ttotal: 17.7s\tremaining: 8.15s\n",
      "685:\tlearn: 28.8183169\ttotal: 17.7s\tremaining: 8.12s\n",
      "686:\tlearn: 28.7787010\ttotal: 17.8s\tremaining: 8.1s\n",
      "687:\tlearn: 28.7664439\ttotal: 17.8s\tremaining: 8.07s\n",
      "688:\tlearn: 28.7646699\ttotal: 17.8s\tremaining: 8.04s\n",
      "689:\tlearn: 28.7492320\ttotal: 17.8s\tremaining: 8.02s\n",
      "690:\tlearn: 28.7476764\ttotal: 17.9s\tremaining: 7.99s\n",
      "691:\tlearn: 28.7460063\ttotal: 17.9s\tremaining: 7.96s\n",
      "692:\tlearn: 28.7453052\ttotal: 17.9s\tremaining: 7.93s\n",
      "693:\tlearn: 28.7447985\ttotal: 17.9s\tremaining: 7.9s\n",
      "694:\tlearn: 28.7439494\ttotal: 17.9s\tremaining: 7.88s\n",
      "695:\tlearn: 28.7292310\ttotal: 18s\tremaining: 7.85s\n",
      "696:\tlearn: 28.7214462\ttotal: 18s\tremaining: 7.82s\n",
      "697:\tlearn: 28.7008316\ttotal: 18s\tremaining: 7.79s\n",
      "698:\tlearn: 28.7000375\ttotal: 18s\tremaining: 7.77s\n",
      "699:\tlearn: 28.6988371\ttotal: 18.1s\tremaining: 7.74s\n",
      "700:\tlearn: 28.6983587\ttotal: 18.1s\tremaining: 7.71s\n",
      "701:\tlearn: 28.6959321\ttotal: 18.1s\tremaining: 7.68s\n",
      "702:\tlearn: 28.6950058\ttotal: 18.1s\tremaining: 7.65s\n",
      "703:\tlearn: 28.6931495\ttotal: 18.1s\tremaining: 7.63s\n",
      "704:\tlearn: 28.6915911\ttotal: 18.2s\tremaining: 7.6s\n",
      "705:\tlearn: 28.6907312\ttotal: 18.2s\tremaining: 7.57s\n",
      "706:\tlearn: 28.6839863\ttotal: 18.2s\tremaining: 7.55s\n",
      "707:\tlearn: 28.6833549\ttotal: 18.2s\tremaining: 7.52s\n",
      "708:\tlearn: 28.6827502\ttotal: 18.2s\tremaining: 7.49s\n",
      "709:\tlearn: 28.6668824\ttotal: 18.3s\tremaining: 7.46s\n",
      "710:\tlearn: 28.6659885\ttotal: 18.3s\tremaining: 7.44s\n",
      "711:\tlearn: 28.6630072\ttotal: 18.3s\tremaining: 7.41s\n",
      "712:\tlearn: 28.6559660\ttotal: 18.3s\tremaining: 7.38s\n",
      "713:\tlearn: 28.6529124\ttotal: 18.4s\tremaining: 7.36s\n",
      "714:\tlearn: 28.6439963\ttotal: 18.4s\tremaining: 7.33s\n",
      "715:\tlearn: 28.6420544\ttotal: 18.4s\tremaining: 7.3s\n",
      "716:\tlearn: 28.6288497\ttotal: 18.4s\tremaining: 7.28s\n",
      "717:\tlearn: 28.6183806\ttotal: 18.5s\tremaining: 7.25s\n",
      "718:\tlearn: 28.6084603\ttotal: 18.5s\tremaining: 7.22s\n",
      "719:\tlearn: 28.6002221\ttotal: 18.5s\tremaining: 7.2s\n",
      "720:\tlearn: 28.5932122\ttotal: 18.5s\tremaining: 7.17s\n",
      "721:\tlearn: 28.5607008\ttotal: 18.6s\tremaining: 7.15s\n",
      "722:\tlearn: 28.5443605\ttotal: 18.6s\tremaining: 7.12s\n",
      "723:\tlearn: 28.5430768\ttotal: 18.6s\tremaining: 7.09s\n",
      "724:\tlearn: 28.5411691\ttotal: 18.6s\tremaining: 7.07s\n",
      "725:\tlearn: 28.5388945\ttotal: 18.7s\tremaining: 7.04s\n",
      "726:\tlearn: 28.5370058\ttotal: 18.7s\tremaining: 7.01s\n",
      "727:\tlearn: 28.5325669\ttotal: 18.7s\tremaining: 6.99s\n",
      "728:\tlearn: 28.5255517\ttotal: 18.7s\tremaining: 6.96s\n",
      "729:\tlearn: 28.5135565\ttotal: 18.8s\tremaining: 6.93s\n",
      "730:\tlearn: 28.4999328\ttotal: 18.8s\tremaining: 6.91s\n",
      "731:\tlearn: 28.4902842\ttotal: 18.8s\tremaining: 6.88s\n",
      "732:\tlearn: 28.4815212\ttotal: 18.8s\tremaining: 6.86s\n",
      "733:\tlearn: 28.4724135\ttotal: 18.9s\tremaining: 6.83s\n",
      "734:\tlearn: 28.4319578\ttotal: 18.9s\tremaining: 6.81s\n",
      "735:\tlearn: 28.4208246\ttotal: 18.9s\tremaining: 6.78s\n",
      "736:\tlearn: 28.4035527\ttotal: 18.9s\tremaining: 6.76s\n",
      "737:\tlearn: 28.3986588\ttotal: 19s\tremaining: 6.73s\n",
      "738:\tlearn: 28.3951311\ttotal: 19s\tremaining: 6.71s\n",
      "739:\tlearn: 28.3894294\ttotal: 19s\tremaining: 6.68s\n",
      "740:\tlearn: 28.3879048\ttotal: 19s\tremaining: 6.65s\n",
      "741:\tlearn: 28.3858142\ttotal: 19.1s\tremaining: 6.62s\n",
      "742:\tlearn: 28.3616862\ttotal: 19.1s\tremaining: 6.6s\n",
      "743:\tlearn: 28.3367441\ttotal: 19.1s\tremaining: 6.57s\n",
      "744:\tlearn: 28.3358292\ttotal: 19.1s\tremaining: 6.55s\n",
      "745:\tlearn: 28.3309941\ttotal: 19.1s\tremaining: 6.52s\n",
      "746:\tlearn: 28.3302446\ttotal: 19.2s\tremaining: 6.49s\n",
      "747:\tlearn: 28.3135659\ttotal: 19.2s\tremaining: 6.47s\n",
      "748:\tlearn: 28.3110940\ttotal: 19.2s\tremaining: 6.44s\n",
      "749:\tlearn: 28.3101616\ttotal: 19.2s\tremaining: 6.41s\n",
      "750:\tlearn: 28.3029587\ttotal: 19.3s\tremaining: 6.39s\n",
      "751:\tlearn: 28.3000782\ttotal: 19.3s\tremaining: 6.36s\n",
      "752:\tlearn: 28.2889736\ttotal: 19.3s\tremaining: 6.33s\n",
      "753:\tlearn: 28.2733856\ttotal: 19.3s\tremaining: 6.31s\n",
      "754:\tlearn: 28.2725269\ttotal: 19.4s\tremaining: 6.28s\n",
      "755:\tlearn: 28.2675663\ttotal: 19.4s\tremaining: 6.25s\n",
      "756:\tlearn: 28.2661113\ttotal: 19.4s\tremaining: 6.23s\n",
      "757:\tlearn: 28.2349118\ttotal: 19.4s\tremaining: 6.2s\n",
      "758:\tlearn: 28.2346054\ttotal: 19.5s\tremaining: 6.18s\n",
      "759:\tlearn: 28.2330594\ttotal: 19.5s\tremaining: 6.15s\n",
      "760:\tlearn: 28.2271871\ttotal: 19.5s\tremaining: 6.12s\n",
      "761:\tlearn: 28.2205537\ttotal: 19.5s\tremaining: 6.1s\n",
      "762:\tlearn: 28.2083266\ttotal: 19.5s\tremaining: 6.07s\n",
      "763:\tlearn: 28.2076146\ttotal: 19.6s\tremaining: 6.04s\n",
      "764:\tlearn: 28.2045875\ttotal: 19.6s\tremaining: 6.02s\n",
      "765:\tlearn: 28.1481662\ttotal: 19.6s\tremaining: 5.99s\n",
      "766:\tlearn: 28.1459806\ttotal: 19.6s\tremaining: 5.97s\n",
      "767:\tlearn: 28.1451448\ttotal: 19.7s\tremaining: 5.94s\n",
      "768:\tlearn: 28.1440100\ttotal: 19.7s\tremaining: 5.91s\n",
      "769:\tlearn: 28.1412039\ttotal: 19.7s\tremaining: 5.88s\n",
      "770:\tlearn: 28.1209226\ttotal: 19.7s\tremaining: 5.86s\n",
      "771:\tlearn: 28.1098281\ttotal: 19.8s\tremaining: 5.83s\n",
      "772:\tlearn: 28.0977607\ttotal: 19.8s\tremaining: 5.81s\n",
      "773:\tlearn: 28.0877758\ttotal: 19.8s\tremaining: 5.78s\n",
      "774:\tlearn: 28.0836275\ttotal: 19.8s\tremaining: 5.76s\n",
      "775:\tlearn: 28.0766066\ttotal: 19.9s\tremaining: 5.74s\n",
      "776:\tlearn: 28.0755019\ttotal: 19.9s\tremaining: 5.71s\n",
      "777:\tlearn: 28.0616886\ttotal: 19.9s\tremaining: 5.69s\n",
      "778:\tlearn: 28.0608259\ttotal: 20s\tremaining: 5.66s\n",
      "779:\tlearn: 28.0551525\ttotal: 20s\tremaining: 5.64s\n",
      "780:\tlearn: 28.0351761\ttotal: 20s\tremaining: 5.61s\n",
      "781:\tlearn: 28.0185194\ttotal: 20s\tremaining: 5.58s\n",
      "782:\tlearn: 27.9978082\ttotal: 20.1s\tremaining: 5.56s\n",
      "783:\tlearn: 27.9968918\ttotal: 20.1s\tremaining: 5.53s\n",
      "784:\tlearn: 27.9953887\ttotal: 20.1s\tremaining: 5.51s\n",
      "785:\tlearn: 27.9936271\ttotal: 20.1s\tremaining: 5.48s\n",
      "786:\tlearn: 27.9784032\ttotal: 20.2s\tremaining: 5.46s\n",
      "787:\tlearn: 27.9770862\ttotal: 20.2s\tremaining: 5.43s\n",
      "788:\tlearn: 27.9677391\ttotal: 20.2s\tremaining: 5.41s\n",
      "789:\tlearn: 27.9675530\ttotal: 20.2s\tremaining: 5.38s\n",
      "790:\tlearn: 27.9585369\ttotal: 20.3s\tremaining: 5.36s\n",
      "791:\tlearn: 27.9477101\ttotal: 20.3s\tremaining: 5.33s\n",
      "792:\tlearn: 27.9419492\ttotal: 20.3s\tremaining: 5.31s\n",
      "793:\tlearn: 27.9392689\ttotal: 20.4s\tremaining: 5.28s\n",
      "794:\tlearn: 27.9291613\ttotal: 20.4s\tremaining: 5.25s\n",
      "795:\tlearn: 27.9164814\ttotal: 20.4s\tremaining: 5.23s\n",
      "796:\tlearn: 27.9116278\ttotal: 20.4s\tremaining: 5.21s\n",
      "797:\tlearn: 27.9091027\ttotal: 20.5s\tremaining: 5.18s\n",
      "798:\tlearn: 27.9079035\ttotal: 20.5s\tremaining: 5.15s\n",
      "799:\tlearn: 27.8998184\ttotal: 20.5s\tremaining: 5.13s\n",
      "800:\tlearn: 27.8867524\ttotal: 20.6s\tremaining: 5.11s\n",
      "801:\tlearn: 27.8678121\ttotal: 20.6s\tremaining: 5.08s\n",
      "802:\tlearn: 27.8501835\ttotal: 20.6s\tremaining: 5.05s\n",
      "803:\tlearn: 27.8497462\ttotal: 20.6s\tremaining: 5.03s\n",
      "804:\tlearn: 27.8390142\ttotal: 20.7s\tremaining: 5s\n",
      "805:\tlearn: 27.8352527\ttotal: 20.7s\tremaining: 4.98s\n",
      "806:\tlearn: 27.8340036\ttotal: 20.7s\tremaining: 4.95s\n",
      "807:\tlearn: 27.8331535\ttotal: 20.7s\tremaining: 4.92s\n",
      "808:\tlearn: 27.8321888\ttotal: 20.7s\tremaining: 4.9s\n",
      "809:\tlearn: 27.8223530\ttotal: 20.8s\tremaining: 4.87s\n",
      "810:\tlearn: 27.7912891\ttotal: 20.8s\tremaining: 4.85s\n",
      "811:\tlearn: 27.7878107\ttotal: 20.8s\tremaining: 4.82s\n",
      "812:\tlearn: 27.7864255\ttotal: 20.8s\tremaining: 4.79s\n",
      "813:\tlearn: 27.7857147\ttotal: 20.9s\tremaining: 4.77s\n",
      "814:\tlearn: 27.7720722\ttotal: 20.9s\tremaining: 4.74s\n",
      "815:\tlearn: 27.7701246\ttotal: 20.9s\tremaining: 4.72s\n",
      "816:\tlearn: 27.7181609\ttotal: 20.9s\tremaining: 4.69s\n",
      "817:\tlearn: 27.7018911\ttotal: 21s\tremaining: 4.67s\n",
      "818:\tlearn: 27.7003507\ttotal: 21s\tremaining: 4.64s\n",
      "819:\tlearn: 27.6991321\ttotal: 21s\tremaining: 4.62s\n",
      "820:\tlearn: 27.6791414\ttotal: 21.1s\tremaining: 4.59s\n",
      "821:\tlearn: 27.6781460\ttotal: 21.1s\tremaining: 4.57s\n",
      "822:\tlearn: 27.6586922\ttotal: 21.1s\tremaining: 4.54s\n",
      "823:\tlearn: 27.6567157\ttotal: 21.1s\tremaining: 4.52s\n",
      "824:\tlearn: 27.6541977\ttotal: 21.2s\tremaining: 4.49s\n",
      "825:\tlearn: 27.6191029\ttotal: 21.2s\tremaining: 4.47s\n",
      "826:\tlearn: 27.6011825\ttotal: 21.2s\tremaining: 4.44s\n",
      "827:\tlearn: 27.5857871\ttotal: 21.3s\tremaining: 4.42s\n",
      "828:\tlearn: 27.5844163\ttotal: 21.3s\tremaining: 4.39s\n",
      "829:\tlearn: 27.5821829\ttotal: 21.3s\tremaining: 4.37s\n",
      "830:\tlearn: 27.5800960\ttotal: 21.3s\tremaining: 4.34s\n",
      "831:\tlearn: 27.5787493\ttotal: 21.4s\tremaining: 4.31s\n",
      "832:\tlearn: 27.5779602\ttotal: 21.4s\tremaining: 4.29s\n",
      "833:\tlearn: 27.5764427\ttotal: 21.4s\tremaining: 4.26s\n",
      "834:\tlearn: 27.5757331\ttotal: 21.4s\tremaining: 4.24s\n",
      "835:\tlearn: 27.5629037\ttotal: 21.5s\tremaining: 4.21s\n",
      "836:\tlearn: 27.5603684\ttotal: 21.5s\tremaining: 4.19s\n",
      "837:\tlearn: 27.5506897\ttotal: 21.5s\tremaining: 4.16s\n",
      "838:\tlearn: 27.5480364\ttotal: 21.6s\tremaining: 4.13s\n",
      "839:\tlearn: 27.5474725\ttotal: 21.6s\tremaining: 4.11s\n",
      "840:\tlearn: 27.5417177\ttotal: 21.6s\tremaining: 4.08s\n",
      "841:\tlearn: 27.5217447\ttotal: 21.6s\tremaining: 4.06s\n",
      "842:\tlearn: 27.5161439\ttotal: 21.7s\tremaining: 4.03s\n",
      "843:\tlearn: 27.5039486\ttotal: 21.7s\tremaining: 4.01s\n",
      "844:\tlearn: 27.4696306\ttotal: 21.7s\tremaining: 3.99s\n",
      "845:\tlearn: 27.4491866\ttotal: 21.8s\tremaining: 3.96s\n",
      "846:\tlearn: 27.4431038\ttotal: 21.8s\tremaining: 3.94s\n",
      "847:\tlearn: 27.4419699\ttotal: 21.8s\tremaining: 3.91s\n",
      "848:\tlearn: 27.4408273\ttotal: 21.8s\tremaining: 3.88s\n",
      "849:\tlearn: 27.4217008\ttotal: 21.9s\tremaining: 3.86s\n",
      "850:\tlearn: 27.4088715\ttotal: 21.9s\tremaining: 3.83s\n",
      "851:\tlearn: 27.3970123\ttotal: 21.9s\tremaining: 3.81s\n",
      "852:\tlearn: 27.3958266\ttotal: 22s\tremaining: 3.78s\n",
      "853:\tlearn: 27.3850232\ttotal: 22s\tremaining: 3.76s\n",
      "854:\tlearn: 27.3841150\ttotal: 22s\tremaining: 3.73s\n",
      "855:\tlearn: 27.3818104\ttotal: 22s\tremaining: 3.71s\n",
      "856:\tlearn: 27.3739569\ttotal: 22.1s\tremaining: 3.68s\n",
      "857:\tlearn: 27.3704725\ttotal: 22.1s\tremaining: 3.65s\n",
      "858:\tlearn: 27.3682348\ttotal: 22.1s\tremaining: 3.63s\n",
      "859:\tlearn: 27.3655831\ttotal: 22.1s\tremaining: 3.6s\n",
      "860:\tlearn: 27.3566635\ttotal: 22.1s\tremaining: 3.58s\n",
      "861:\tlearn: 27.3558720\ttotal: 22.2s\tremaining: 3.55s\n",
      "862:\tlearn: 27.3541557\ttotal: 22.2s\tremaining: 3.52s\n",
      "863:\tlearn: 27.3532020\ttotal: 22.2s\tremaining: 3.5s\n",
      "864:\tlearn: 27.3504995\ttotal: 22.3s\tremaining: 3.47s\n",
      "865:\tlearn: 27.3490009\ttotal: 22.3s\tremaining: 3.45s\n",
      "866:\tlearn: 27.3481228\ttotal: 22.3s\tremaining: 3.42s\n",
      "867:\tlearn: 27.3436509\ttotal: 22.3s\tremaining: 3.4s\n",
      "868:\tlearn: 27.3238498\ttotal: 22.4s\tremaining: 3.37s\n",
      "869:\tlearn: 27.3098816\ttotal: 22.4s\tremaining: 3.34s\n",
      "870:\tlearn: 27.3054200\ttotal: 22.4s\tremaining: 3.32s\n",
      "871:\tlearn: 27.3008701\ttotal: 22.4s\tremaining: 3.29s\n",
      "872:\tlearn: 27.2881087\ttotal: 22.5s\tremaining: 3.27s\n",
      "873:\tlearn: 27.2876627\ttotal: 22.5s\tremaining: 3.24s\n",
      "874:\tlearn: 27.2858932\ttotal: 22.5s\tremaining: 3.21s\n",
      "875:\tlearn: 27.2753302\ttotal: 22.5s\tremaining: 3.19s\n",
      "876:\tlearn: 27.2744971\ttotal: 22.6s\tremaining: 3.16s\n",
      "877:\tlearn: 27.2458662\ttotal: 22.6s\tremaining: 3.14s\n",
      "878:\tlearn: 27.2422394\ttotal: 22.6s\tremaining: 3.12s\n",
      "879:\tlearn: 27.2346433\ttotal: 22.7s\tremaining: 3.09s\n",
      "880:\tlearn: 27.2336344\ttotal: 22.7s\tremaining: 3.07s\n",
      "881:\tlearn: 27.2182030\ttotal: 22.8s\tremaining: 3.04s\n",
      "882:\tlearn: 27.2055196\ttotal: 22.8s\tremaining: 3.02s\n",
      "883:\tlearn: 27.1951034\ttotal: 22.8s\tremaining: 3s\n",
      "884:\tlearn: 27.1862927\ttotal: 22.9s\tremaining: 2.97s\n",
      "885:\tlearn: 27.1813499\ttotal: 22.9s\tremaining: 2.95s\n",
      "886:\tlearn: 27.1782758\ttotal: 23s\tremaining: 2.93s\n",
      "887:\tlearn: 27.1739320\ttotal: 23.1s\tremaining: 2.91s\n",
      "888:\tlearn: 27.1732121\ttotal: 23.1s\tremaining: 2.88s\n",
      "889:\tlearn: 27.1691804\ttotal: 23.1s\tremaining: 2.86s\n",
      "890:\tlearn: 27.1682488\ttotal: 23.2s\tremaining: 2.84s\n",
      "891:\tlearn: 27.1571850\ttotal: 23.3s\tremaining: 2.82s\n",
      "892:\tlearn: 27.1363986\ttotal: 23.3s\tremaining: 2.79s\n",
      "893:\tlearn: 27.1310508\ttotal: 23.4s\tremaining: 2.77s\n",
      "894:\tlearn: 27.1301733\ttotal: 23.4s\tremaining: 2.74s\n",
      "895:\tlearn: 27.1288028\ttotal: 23.4s\tremaining: 2.72s\n",
      "896:\tlearn: 27.1268994\ttotal: 23.4s\tremaining: 2.69s\n",
      "897:\tlearn: 27.1144978\ttotal: 23.5s\tremaining: 2.66s\n",
      "898:\tlearn: 27.1047976\ttotal: 23.5s\tremaining: 2.64s\n",
      "899:\tlearn: 27.0985535\ttotal: 23.5s\tremaining: 2.62s\n",
      "900:\tlearn: 27.0971824\ttotal: 23.6s\tremaining: 2.59s\n",
      "901:\tlearn: 27.0961728\ttotal: 23.7s\tremaining: 2.58s\n",
      "902:\tlearn: 27.0815833\ttotal: 23.8s\tremaining: 2.55s\n",
      "903:\tlearn: 27.0810177\ttotal: 23.8s\tremaining: 2.53s\n",
      "904:\tlearn: 27.0725269\ttotal: 23.9s\tremaining: 2.5s\n",
      "905:\tlearn: 27.0706106\ttotal: 23.9s\tremaining: 2.48s\n",
      "906:\tlearn: 27.0675960\ttotal: 24s\tremaining: 2.46s\n",
      "907:\tlearn: 27.0653439\ttotal: 24s\tremaining: 2.43s\n",
      "908:\tlearn: 27.0647538\ttotal: 24.1s\tremaining: 2.41s\n",
      "909:\tlearn: 27.0639756\ttotal: 24.1s\tremaining: 2.38s\n",
      "910:\tlearn: 27.0584077\ttotal: 24.2s\tremaining: 2.36s\n",
      "911:\tlearn: 27.0569434\ttotal: 24.2s\tremaining: 2.33s\n",
      "912:\tlearn: 27.0424016\ttotal: 24.3s\tremaining: 2.31s\n",
      "913:\tlearn: 27.0422592\ttotal: 24.3s\tremaining: 2.29s\n",
      "914:\tlearn: 27.0411899\ttotal: 24.3s\tremaining: 2.26s\n",
      "915:\tlearn: 27.0314382\ttotal: 24.4s\tremaining: 2.24s\n",
      "916:\tlearn: 27.0303466\ttotal: 24.4s\tremaining: 2.21s\n",
      "917:\tlearn: 27.0221575\ttotal: 24.5s\tremaining: 2.19s\n",
      "918:\tlearn: 27.0210671\ttotal: 24.5s\tremaining: 2.16s\n",
      "919:\tlearn: 27.0128105\ttotal: 24.5s\tremaining: 2.13s\n",
      "920:\tlearn: 27.0102935\ttotal: 24.6s\tremaining: 2.11s\n",
      "921:\tlearn: 27.0089898\ttotal: 24.6s\tremaining: 2.08s\n",
      "922:\tlearn: 27.0030604\ttotal: 24.7s\tremaining: 2.06s\n",
      "923:\tlearn: 27.0021444\ttotal: 24.7s\tremaining: 2.03s\n",
      "924:\tlearn: 27.0013960\ttotal: 24.7s\tremaining: 2s\n",
      "925:\tlearn: 27.0004372\ttotal: 24.8s\tremaining: 1.98s\n",
      "926:\tlearn: 26.9936144\ttotal: 24.8s\tremaining: 1.95s\n",
      "927:\tlearn: 26.9879066\ttotal: 24.8s\tremaining: 1.93s\n",
      "928:\tlearn: 26.9712323\ttotal: 24.9s\tremaining: 1.9s\n",
      "929:\tlearn: 26.9703113\ttotal: 24.9s\tremaining: 1.87s\n",
      "930:\tlearn: 26.9696623\ttotal: 24.9s\tremaining: 1.85s\n",
      "931:\tlearn: 26.9674583\ttotal: 25s\tremaining: 1.82s\n",
      "932:\tlearn: 26.9662720\ttotal: 25s\tremaining: 1.79s\n",
      "933:\tlearn: 26.9619789\ttotal: 25s\tremaining: 1.77s\n",
      "934:\tlearn: 26.9611847\ttotal: 25s\tremaining: 1.74s\n",
      "935:\tlearn: 26.9480541\ttotal: 25.1s\tremaining: 1.71s\n",
      "936:\tlearn: 26.9472839\ttotal: 25.1s\tremaining: 1.69s\n",
      "937:\tlearn: 26.9385646\ttotal: 25.1s\tremaining: 1.66s\n",
      "938:\tlearn: 26.9366121\ttotal: 25.1s\tremaining: 1.63s\n",
      "939:\tlearn: 26.9351076\ttotal: 25.2s\tremaining: 1.61s\n",
      "940:\tlearn: 26.9193366\ttotal: 25.2s\tremaining: 1.58s\n",
      "941:\tlearn: 26.9188249\ttotal: 25.2s\tremaining: 1.55s\n",
      "942:\tlearn: 26.9176143\ttotal: 25.3s\tremaining: 1.53s\n",
      "943:\tlearn: 26.9146683\ttotal: 25.3s\tremaining: 1.5s\n",
      "944:\tlearn: 26.9136070\ttotal: 25.3s\tremaining: 1.47s\n",
      "945:\tlearn: 26.9004809\ttotal: 25.4s\tremaining: 1.45s\n",
      "946:\tlearn: 26.8994444\ttotal: 25.4s\tremaining: 1.42s\n",
      "947:\tlearn: 26.8980209\ttotal: 25.4s\tremaining: 1.39s\n",
      "948:\tlearn: 26.8955228\ttotal: 25.5s\tremaining: 1.37s\n",
      "949:\tlearn: 26.8876807\ttotal: 25.5s\tremaining: 1.34s\n",
      "950:\tlearn: 26.8872457\ttotal: 25.5s\tremaining: 1.31s\n",
      "951:\tlearn: 26.8804934\ttotal: 25.5s\tremaining: 1.29s\n",
      "952:\tlearn: 26.8796976\ttotal: 25.6s\tremaining: 1.26s\n",
      "953:\tlearn: 26.8788872\ttotal: 25.6s\tremaining: 1.23s\n",
      "954:\tlearn: 26.8775652\ttotal: 25.6s\tremaining: 1.21s\n",
      "955:\tlearn: 26.8770016\ttotal: 25.6s\tremaining: 1.18s\n",
      "956:\tlearn: 26.8763613\ttotal: 25.7s\tremaining: 1.15s\n",
      "957:\tlearn: 26.8741562\ttotal: 25.7s\tremaining: 1.13s\n",
      "958:\tlearn: 26.8637086\ttotal: 25.7s\tremaining: 1.1s\n",
      "959:\tlearn: 26.8609178\ttotal: 25.7s\tremaining: 1.07s\n",
      "960:\tlearn: 26.8574579\ttotal: 25.8s\tremaining: 1.04s\n",
      "961:\tlearn: 26.8427853\ttotal: 25.8s\tremaining: 1.02s\n",
      "962:\tlearn: 26.8417344\ttotal: 25.8s\tremaining: 992ms\n",
      "963:\tlearn: 26.8387260\ttotal: 25.8s\tremaining: 965ms\n",
      "964:\tlearn: 26.8262338\ttotal: 25.9s\tremaining: 938ms\n",
      "965:\tlearn: 26.8158698\ttotal: 25.9s\tremaining: 911ms\n",
      "966:\tlearn: 26.8148371\ttotal: 25.9s\tremaining: 885ms\n",
      "967:\tlearn: 26.8114617\ttotal: 26s\tremaining: 858ms\n",
      "968:\tlearn: 26.8015376\ttotal: 26s\tremaining: 832ms\n",
      "969:\tlearn: 26.8007582\ttotal: 26.1s\tremaining: 806ms\n",
      "970:\tlearn: 26.7801956\ttotal: 26.1s\tremaining: 780ms\n",
      "971:\tlearn: 26.7786381\ttotal: 26.1s\tremaining: 753ms\n",
      "972:\tlearn: 26.7762514\ttotal: 26.2s\tremaining: 726ms\n",
      "973:\tlearn: 26.7759670\ttotal: 26.2s\tremaining: 699ms\n",
      "974:\tlearn: 26.7720331\ttotal: 26.2s\tremaining: 673ms\n",
      "975:\tlearn: 26.7706429\ttotal: 26.3s\tremaining: 646ms\n",
      "976:\tlearn: 26.7686409\ttotal: 26.3s\tremaining: 619ms\n",
      "977:\tlearn: 26.7679763\ttotal: 26.3s\tremaining: 592ms\n",
      "978:\tlearn: 26.7651888\ttotal: 26.4s\tremaining: 566ms\n",
      "979:\tlearn: 26.7644438\ttotal: 26.4s\tremaining: 539ms\n",
      "980:\tlearn: 26.7635015\ttotal: 26.4s\tremaining: 512ms\n",
      "981:\tlearn: 26.7618481\ttotal: 26.5s\tremaining: 486ms\n",
      "982:\tlearn: 26.7537921\ttotal: 26.5s\tremaining: 459ms\n",
      "983:\tlearn: 26.7530758\ttotal: 26.6s\tremaining: 432ms\n",
      "984:\tlearn: 26.7497355\ttotal: 26.6s\tremaining: 405ms\n",
      "985:\tlearn: 26.7491685\ttotal: 26.6s\tremaining: 378ms\n",
      "986:\tlearn: 26.7385649\ttotal: 26.7s\tremaining: 352ms\n",
      "987:\tlearn: 26.7304678\ttotal: 26.7s\tremaining: 325ms\n",
      "988:\tlearn: 26.7176170\ttotal: 26.8s\tremaining: 298ms\n",
      "989:\tlearn: 26.7016979\ttotal: 26.8s\tremaining: 271ms\n",
      "990:\tlearn: 26.7007502\ttotal: 26.8s\tremaining: 244ms\n",
      "991:\tlearn: 26.6952146\ttotal: 26.9s\tremaining: 217ms\n",
      "992:\tlearn: 26.6941802\ttotal: 26.9s\tremaining: 190ms\n",
      "993:\tlearn: 26.6934808\ttotal: 26.9s\tremaining: 163ms\n",
      "994:\tlearn: 26.6842273\ttotal: 27s\tremaining: 136ms\n",
      "995:\tlearn: 26.6811936\ttotal: 27s\tremaining: 108ms\n",
      "996:\tlearn: 26.6534598\ttotal: 27s\tremaining: 81.3ms\n",
      "997:\tlearn: 26.6290005\ttotal: 27.1s\tremaining: 54.2ms\n",
      "998:\tlearn: 26.6278981\ttotal: 27.1s\tremaining: 27.1ms\n",
      "999:\tlearn: 26.6198588\ttotal: 27.1s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "def random_forrest_regressor(train, valid, test):\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(train, valid, test)\n",
    "\n",
    "    X_train = pd.concat([X_train, X_valid])\n",
    "    y_train = pd.concat([y_train, y_valid])\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    res = X_test.copy()\n",
    "    res[\"actual\"] = y_test\n",
    "    res[\"pred\"] = y_pred\n",
    "    \n",
    "    \n",
    "    #res.to_csv(\"results/pred_random_forrest_regressor_all.csv\")\n",
    "    return model, res\n",
    "\n",
    "def gradient_boosting_regression(train, valid, test):\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(train, valid, test)\n",
    "    \n",
    "    X_train = pd.concat([X_train, X_valid])\n",
    "    y_train = pd.concat([y_train, y_valid])\n",
    "    \n",
    "    model = GradientBoostingRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    res = X_test.copy()\n",
    "    res[\"actual\"] = y_test\n",
    "    res[\"pred\"] = y_pred\n",
    "    \n",
    "    #res.to_csv(\"results/pred_gradient_boosting_regressor_all.csv\")\n",
    "    return model, res\n",
    "\n",
    "def tensor_flow(train, valid, test):\n",
    "    \n",
    "    def model_prep(train, valid, test):\n",
    "        df_train = train.copy()\n",
    "        df_valid = valid.copy()\n",
    "        df_test = test.copy()\n",
    "        \n",
    "        # One hot encoding of Boolean variables\n",
    "        encoder = OneHotEncoder()\n",
    "        encoded = pd.DataFrame(encoder.fit_transform(df_train[['is_holiday', 'is_weekend']]).toarray(), columns=encoder.get_feature_names_out(['is_holiday', 'is_weekend']))\n",
    "        df_train = df_train.drop(columns=['is_holiday', 'is_weekend'])\n",
    "        df_train = df_train.join(encoded)\n",
    "        encoded = pd.DataFrame(encoder.transform(df_valid[['is_holiday', 'is_weekend']]).toarray(), columns=encoder.get_feature_names_out(['is_holiday', 'is_weekend']))\n",
    "        df_valid = df_valid.drop(columns=['is_holiday', 'is_weekend'])\n",
    "        df_valid = df_valid.join(encoded)\n",
    "        encoded = pd.DataFrame(encoder.transform(df_test[['is_holiday', 'is_weekend']]).toarray(), columns=encoder.get_feature_names_out(['is_holiday', 'is_weekend']))\n",
    "        df_test = df_test.drop(columns=['is_holiday', 'is_weekend'])\n",
    "        df_test = df_test.join(encoded)\n",
    "        \n",
    "        # Standard scaler for continuous variables\n",
    "        scaler = StandardScaler()\n",
    "        df_train[['duration_sec', 'mean_temperature', 'total_precipitation']] = scaler.fit_transform(df_train[['duration_sec', 'mean_temperature', 'total_precipitation']])\n",
    "        df_valid[['duration_sec', 'mean_temperature', 'total_precipitation']] = scaler.transform(df_valid[['duration_sec', 'mean_temperature', 'total_precipitation']])\n",
    "        df_test[['duration_sec', 'mean_temperature', 'total_precipitation']] = scaler.transform(df_test[['duration_sec', 'mean_temperature', 'total_precipitation']])\n",
    "        \n",
    "        # Minmax scaler for station cluster ids\n",
    "        scaler = MinMaxScaler()\n",
    "        df_train[['start_station_cluster', 'end_station_cluster']] = scaler.fit_transform(df_train[['start_station_cluster', 'end_station_cluster']])\n",
    "        df_valid[['start_station_cluster', 'end_station_cluster']] = scaler.transform(df_valid[['start_station_cluster', 'end_station_cluster']])\n",
    "        df_test[['start_station_cluster', 'end_station_cluster']] = scaler.transform(df_test[['start_station_cluster', 'end_station_cluster']])\n",
    "        \n",
    "        return df_train, df_valid, df_test\n",
    "    \n",
    "    train, valid, test = model_prep(train, valid, test)\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(train, valid, test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_valid, y_valid))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    res = X_test.copy()\n",
    "    res[\"actual\"] = y_test\n",
    "    res[\"pred\"] = y_pred\n",
    "    \n",
    "    #res.to_csv(\"results/pred_tensorflow_all.csv\")\n",
    "    return model, res\n",
    "\n",
    "def cat_boost(train, valid, test):\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = df_split(train, valid, test)\n",
    "\n",
    "    X_train = pd.concat([X_train, X_valid])\n",
    "    y_train = pd.concat([y_train, y_valid])\n",
    "    \n",
    "    model = CatBoostRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    res = X_test.copy()\n",
    "    res[\"actual\"] = y_test\n",
    "    res[\"pred\"] = y_pred\n",
    "    \n",
    "    #res.to_csv(\"results/pred_cat_boost_all.csv\")\n",
    "    return model, res\n",
    "\n",
    "rfr_mod, rfr_res = random_forrest_regressor(df_train, df_valid, df_test)\n",
    "gbr_mod, gbr_res = gradient_boosting_regression(df_train, df_valid, df_test)\n",
    "tsf_mod, tsf_res = tensor_flow(df_train, df_valid, df_test)\n",
    "cbt_mod, cbt_res = cat_boost(df_train, df_valid, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfed01a-6146-4f15-b972-614422c732a0",
   "metadata": {},
   "source": [
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a45da095-6f0c-4d62-b6b7-5e474b583fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model       RMSE          MSE   \n",
      "0    Random Forrest Regressor  51.190232  2620.439871  \\\n",
      "1  GradientBoosting Regressor  85.247879  7267.200816   \n",
      "2                  TensorFlow  83.831886  7027.785027   \n",
      "3                    CatBoost  60.481705  3658.036639   \n",
      "\n",
      "   Correlation Coefficient  R-squared  \n",
      "0                 0.927423   0.694604  \n",
      "1                 0.506357   0.153054  \n",
      "2                 0.475957   0.180956  \n",
      "3                 0.879918   0.573679  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def evaluate(df):\n",
    "    actual_values = df['actual']\n",
    "    predicted_values = df['pred']\n",
    "    \n",
    "    mse = mean_squared_error(actual_values, predicted_values)\n",
    "    rmse = np.sqrt(mse)\n",
    "    correlation_coefficient, p_value = pearsonr(actual_values, predicted_values)\n",
    "    r2 = r2_score(actual_values, predicted_values)\n",
    "    \n",
    "    return rmse, mse, correlation_coefficient, r2\n",
    "\n",
    "def compare_results(all_results):    \n",
    "    results = []\n",
    "    for name, df in all_results.items():\n",
    "        rmse, mse, correlation_coefficient, r2 = evaluate(df)\n",
    "        result = {\n",
    "            'Model': name,\n",
    "            'RMSE': rmse,\n",
    "            'MSE': mse,\n",
    "            'Correlation Coefficient': correlation_coefficient,\n",
    "            'R-squared': r2\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    #results_df.to_csv(\"results/evaluations.csv\")\n",
    "    return results_df\n",
    "\n",
    "all_results = {\n",
    "    \"Random Forrest Regressor\": rfr_res,\n",
    "    \"GradientBoosting Regressor\": gbr_res,\n",
    "    \"TensorFlow\": tsf_res,\n",
    "    \"CatBoost\": cbt_res\n",
    "}\n",
    "\n",
    "print(compare_results(all_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75418527-3ee4-420f-9180-03136a336a5f",
   "metadata": {},
   "source": [
    "## Hyperparametertuning (RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c97b88-ff2d-40b8-a6bd-7310c55be1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None}\n",
      "Best Score: -419.3617432098575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def hpt_random_forrest(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['auto', 'sqrt']\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        rf, param_distributions=param_grid, n_iter=5, scoring=scorer, cv=5, random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "best_model = hpt_random_forrest(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1a00fdcf-4a3a-42e3-8409-a1e90cac7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/Repos/datamining/data_mining_project/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model       RMSE          MSE  Correlation Coefficient   \n",
      "0          Best model  51.010210  2602.041503                 0.934137  \\\n",
      "1  Default parameters  51.190232  2620.439871                 0.927423   \n",
      "\n",
      "   R-squared  \n",
      "0   0.696749  \n",
      "1   0.694604  \n"
     ]
    }
   ],
   "source": [
    "X_train_combined = pd.concat([X_train, X_valid])\n",
    "y_train_combined = pd.concat([y_train, y_valid])\n",
    "\n",
    "new_best_model = best_model.fit(X_train_combined, y_train_combined)\n",
    "new_predictions = new_best_model.predict(X_test)\n",
    "\n",
    "res = X_test.copy()\n",
    "res[\"actual\"] = y_test\n",
    "res[\"pred\"] = new_predictions\n",
    "\n",
    "hpt_comparison = {\n",
    "    \"Best model\": res,\n",
    "    \"Default parameters\": rfr_res\n",
    "}\n",
    "\n",
    "print(compare_results(hpt_comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a9ae7-9cd3-4095-807e-98feab4f3dfa",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0537fd0c-54a8-4d97-9367-22a0f51c9404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model       RMSE          MSE  Correlation Coefficient   \n",
      "0  Hyperparameter tuning  51.010210  2602.041503                 0.934137  \\\n",
      "1     Default parameters  51.190232  2620.439871                 0.927423   \n",
      "2               Baseline  56.329891  3173.056594                 0.926345   \n",
      "\n",
      "   R-squared  \n",
      "0   0.696749  \n",
      "1   0.694604  \n",
      "2   0.651306  \n"
     ]
    }
   ],
   "source": [
    "def baseline(X_train, y_train, X_test, y_test):\n",
    "    baseline = X_test.copy()\n",
    "    baseline[\"count\"] = y_test\n",
    "    baseline = baseline[[\"start_station_cluster\", \"end_station_cluster\", \"count\"]]\n",
    "\n",
    "    traning_df = X_train.copy()\n",
    "    traning_df[\"count\"] = y_train\n",
    "    traning_df = traning_df[[\"start_station_cluster\", \"end_station_cluster\", \"count\"]]\n",
    "    \n",
    "    mean_df = traning_df.groupby([\"start_station_cluster\", \"end_station_cluster\"]).mean()[[\"count\"]]\n",
    "    \n",
    "    merged_df = pd.merge(baseline, mean_df, left_on=['start_station_cluster', 'end_station_cluster'], right_on=['start_station_cluster', 'end_station_cluster'])\n",
    "    merged_df = merged_df.rename(columns={'count_x': 'actual', 'count_y': 'pred'})\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "baseline_comparison = {\n",
    "    \"Hyperparameter tuning\": res, \n",
    "    \"Default parameters\": rfr_res, \n",
    "    \"Baseline\": baseline(X_train_combined, y_train_combined, X_test, y_test)\n",
    "}\n",
    "\n",
    "print(compare_results(baseline_comparison).to_csv(\"baseline.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96213196-abc4-4889-b936-6b958f47f009",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ba511-4794-44cf-9f09-8bfc8006b755",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "73fa3f87-b4ce-432c-8b48-86d3b869f9cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['start_station_cluster', 'end_station_cluster', 'is_holiday',\n",
      "       'is_weekend', 'mean_temperature', 'total_precipitation'],\n",
      "      dtype='object')\n",
      "[9.11741959e-01 9.16933353e-01 7.48650911e-04 7.77137132e-03\n",
      " 3.48968577e-02 1.91392336e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq4AAAHHCAYAAAB+7NoJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABclklEQVR4nO3dd1QU1/8+8GfpdWkCgiJFQFHBhgUVwRasscRuBKyxEGzYPkYFe0xMsBs1ATVGNGpiosaoKCQiUTRiRWwgJhK7IKJIub8//DFfV4qAKI48r3P2HHbmzp33zJjwcPfOrEIIIUBERERE9I5Tq+gCiIiIiIhKgsGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIqJKws7ODv79/RZdBVGYMrkRErxAeHg6FQlHoa9q0aW9kn0ePHkVwcDAePnz4Rvp/Hfnn48SJExVdSpmtWrUK4eHhFV1GuXnx36Samhqsra3xwQcfICoqqlz6v3nzJoKDgxEfH18u/RGVlUZFF0BEJBdz5syBvb29yrJ69eq9kX0dPXoUISEh8Pf3h7Gx8RvZR2W2atUqVKlS5b0afezQoQN8fX0hhEBSUhJWrVqFtm3bYs+ePejUqdNr9X3z5k2EhITAzs4ODRo0KJ+CicqAwZWIqIQ6deoEd3f3ii7jtTx+/Bj6+voVXUaFyczMhJ6eXkWX8UY4Ozvj448/lt737NkTbm5uCA0Nfe3gSvSu4FQBIqJy8ttvv8HT0xP6+vowNDREly5dcP78eZU2Z86cgb+/PxwcHKCjo4OqVati6NChuHfvntQmODgYkydPBgDY29tLHwEnJycjOTkZCoWi0I+5FQoFgoODVfpRKBS4cOECBg4cCBMTE7Rq1Upa//3336Nx48bQ1dWFqakp+vfvjxs3bpTp2P39/WFgYICUlBR07doVBgYGqFatGlauXAkAOHv2LNq2bQt9fX3Y2trihx9+UNk+f/rBH3/8gU8++QRmZmZQKpXw9fXFgwcPCuxv1apVqFu3LrS1tWFtbY2xY8cWmFbh7e2NevXq4eTJk2jdujX09PTwv//9D3Z2djh//jyio6Olc+vt7Q0AuH//PoKCguDq6goDAwMolUp06tQJp0+fVuk7KioKCoUC27Ztw/z581G9enXo6OigXbt2uHLlSoF6jx07hs6dO8PExAT6+vpwc3PD0qVLVdpcvHgRvXv3hqmpKXR0dODu7o5ffvmltJdC4urqiipVqiApKanYdteuXUOfPn1gamoKPT09NG/eHHv27FE51iZNmgAAhgwZIp2z92mqBckHR1yJiEooLS0Nd+/eVVlWpUoVAMCmTZvg5+cHHx8ffP7558jMzMTq1avRqlUrnDp1CnZ2dgCAAwcO4Nq1axgyZAiqVq2K8+fPY+3atTh//jz++usvKBQK9OrVC5cuXcKWLVvw9ddfS/swNzfHnTt3Sl13nz594OTkhAULFkAIAQCYP38+Zs6cib59+2L48OG4c+cOli9fjtatW+PUqVNlmp6Qm5uLTp06oXXr1li8eDE2b96MgIAA6OvrY8aMGRg0aBB69eqFNWvWwNfXFx4eHgWmXgQEBMDY2BjBwcFITEzE6tWrcf36dSkoAs8DeUhICNq3b4/Ro0dL7eLi4hATEwNNTU2pv3v37qFTp07o378/Pv74Y1haWsLb2xuffvopDAwMMGPGDACApaUlgOch7ueff0afPn1gb2+PW7du4ZtvvoGXlxcuXLgAa2trlXoXLVoENTU1BAUFIS0tDYsXL8agQYNw7Ngxqc2BAwfQtWtXWFlZYdy4cahatSoSEhKwe/dujBs3DgBw/vx5tGzZEtWqVcO0adOgr6+Pbdu2oUePHtixYwd69uxZ6uvx4MEDPHjwAI6OjkW2uXXrFlq0aIHMzEwEBgbCzMwMGzZswIcffojt27ejZ8+ecHFxwZw5czBr1iyMHDkSnp6eAIAWLVqUuiai1yaIiKhYYWFhAkChLyGEePTokTA2NhYjRoxQ2e6///4TRkZGKsszMzML9L9lyxYBQPzxxx/Ssi+++EIAEElJSSptk5KSBAARFhZWoB8AYvbs2dL72bNnCwBiwIABKu2Sk5OFurq6mD9/vsrys2fPCg0NjQLLizofcXFx0jI/Pz8BQCxYsEBa9uDBA6GrqysUCoWIiIiQll+8eLFArfl9Nm7cWDx79kxavnjxYgFA7Nq1SwghxO3bt4WWlpb44IMPRG5urtRuxYoVAoD47rvvpGVeXl4CgFizZk2BY6hbt67w8vIqsPzp06cq/Qrx/Jxra2uLOXPmSMsOHz4sAAgXFxeRlZUlLV+6dKkAIM6ePSuEECInJ0fY29sLW1tb8eDBA5V+8/LypJ/btWsnXF1dxdOnT1XWt2jRQjg5ORWo82UAxLBhw8SdO3fE7du3xbFjx0S7du0EALFkyRKpna2trfDz85Pejx8/XgAQf/75p7Ts0aNHwt7eXtjZ2UnnIi4ursh/d0RvE6cKEBGV0MqVK3HgwAGVF/B8RO3hw4cYMGAA7t69K73U1dXRrFkzHD58WOpDV1dX+vnp06e4e/cumjdvDgD4+++/30jdo0aNUnm/c+dO5OXloW/fvir1Vq1aFU5OTir1ltbw4cOln42NjVGrVi3o6+ujb9++0vJatWrB2NgY165dK7D9yJEjVUZMR48eDQ0NDezduxcAcPDgQTx79gzjx4+Hmtr//QobMWIElEqlykfcAKCtrY0hQ4aUuH5tbW2p39zcXNy7dw8GBgaoVatWoddnyJAh0NLSkt7nj0bmH9upU6eQlJSE8ePHFxjFzh9Bvn//Pg4dOoS+ffvi0aNH0vW4d+8efHx8cPnyZfz777+vrP3bb7+Fubk5LCws0KxZM8TExGDixIkYP358kdvs3bsXTZs2VZlCYmBggJEjRyI5ORkXLlx45X6J3iZOFSAiKqGmTZsWenPW5cuXAQBt27YtdDulUin9fP/+fYSEhCAiIgK3b99WaZeWllaO1f6flz+Ov3z5MoQQcHJyKrT9i8GxNHR0dGBubq6yzMjICNWrV5dC2ovLC5u7+nJNBgYGsLKyQnJyMgDg+vXrAJ6H3xdpaWnBwcFBWp+vWrVqKsHyVfLy8rB06VKsWrUKSUlJyM3NldaZmZkVaF+jRg2V9yYmJgAgHdvVq1cBFP/0iStXrkAIgZkzZ2LmzJmFtrl9+zaqVatWbO3du3dHQEAAFAoFDA0NUbdu3VfeiHf9+nU0a9aswHIXFxdp/Zt6cgZRWTC4EhG9pry8PADP57lWrVq1wHoNjf/7X23fvn1x9OhRTJ48GQ0aNICBgQHy8vLQsWNHqZ/ivBwA870YsF724ihvfr0KhQK//fYb1NXVC7Q3MDB4ZR2FKayv4paL/z/f9k16+dhfZcGCBZg5cyaGDh2KuXPnwtTUFGpqahg/fnyh16c8ji2/36CgIPj4+BTaprh5qvmqV6+O9u3bl3i/RHLE4EpE9Jpq1qwJALCwsCg2ODx48ACRkZEICQnBrFmzpOX5I7YvKiqg5o/ovXwH/csjja+qVwgBe3t7ODs7l3i7t+Hy5cto06aN9D4jIwOpqano3LkzAMDW1hYAkJiYCAcHB6nds2fPkJSUVOLgVtT53b59O9q0aYNvv/1WZfnDhw+lm+RKI//fxrlz54qsLf84NDU133rwtLW1RWJiYoHlFy9elNYDRZ8voreNc1yJiF6Tj48PlEolFixYgOzs7ALr858EkD869/JoXGhoaIFt8j/ifTmgKpVKVKlSBX/88YfK8lWrVpW43l69ekFdXR0hISEFahFCqDya621bu3atyjlcvXo1cnJypOeQtm/fHlpaWli2bJlK7d9++y3S0tLQpUuXEu1HX1+/0G8lU1dXL3BOfvzxxxLNMS1Mo0aNYG9vj9DQ0AL7y9+PhYUFvL298c033yA1NbVAH2V5kkRJde7cGcePH0dsbKy07PHjx1i7di3s7OxQp04dAEX/eyR62zjiSkT0mpRKJVavXo3BgwejUaNG6N+/P8zNzZGSkoI9e/agZcuWWLFiBZRKpfSoqOzsbFSrVg379+8v9DmbjRs3BgDMmDED/fv3h6amJrp16wZ9fX0MHz4cixYtwvDhw+Hu7o4//vgDly5dKnG9NWvWxLx58zB9+nQkJyejR48eMDQ0RFJSEn766SeMHDkSQUFB5XZ+SuPZs2do164d+vbti8TERKxatQqtWrXChx9+COD5I8GmT5+OkJAQdOzYER9++KHUrkmTJioP4C9O48aNsXr1asybNw+Ojo6wsLBA27Zt0bVrV8yZMwdDhgxBixYtcPbsWWzevFlldLc01NTUsHr1anTr1g0NGjTAkCFDYGVlhYsXL+L8+fP4/fffATy/8a9Vq1ZwdXXFiBEj4ODggFu3biE2Nhb//PNPgefIlpdp06Zhy5Yt6NSpEwIDA2FqaooNGzYgKSkJO3bskG5Uq1mzJoyNjbFmzRoYGhpCX18fzZo1KzB/muiNq6CnGRARyUZhj38qzOHDh4WPj48wMjISOjo6ombNmsLf31+cOHFCavPPP/+Inj17CmNjY2FkZCT69Okjbt68WeDxUEIIMXfuXFGtWjWhpqam8miszMxMMWzYMGFkZCQMDQ1F3759xe3bt4t8HNadO3cKrXfHjh2iVatWQl9fX+jr64vatWuLsWPHisTExFKfDz8/P6Gvr1+grZeXl6hbt26B5ba2tqJLly4F+oyOjhYjR44UJiYmwsDAQAwaNEjcu3evwPYrVqwQtWvXFpqamsLS0lKMHj26wOOmitq3EM8fVdalSxdhaGgoAEiPxnr69KmYNGmSsLKyErq6uqJly5YiNjZWeHl5qTw+K/9xWD/++KNKv0U9ruzIkSOiQ4cOwtDQUOjr6ws3NzexfPlylTZXr14Vvr6+omrVqkJTU1NUq1ZNdO3aVWzfvr3QY3gRADF27NhXtnv5cVj5++3du7cwNjYWOjo6omnTpmL37t0Ftt21a5eoU6eO0NDQ4KOxqMIohHgLs+OJiIiKER4ejiFDhiAuLk72X6tLRG8O57gSERERkSwwuBIRERGRLDC4EhEREZEscI4rEREREckCR1yJiIiISBYYXImIiIhIFvgFBPReycvLw82bN2FoaMivKCQiIpIJIQQePXoEa2tr6YsvCsPgSu+VmzdvwsbGpqLLICIiojK4ceMGqlevXuR6Bld6rxgaGgJ4/g9fqVRWcDVERERUEunp6bCxsZF+jxeFwZXeK/nTA5RKJYMrERGRzLxqmh9vziIiIiIiWWBwJSIiIiJZYHAlIiIiIllgcCUiIiIiWWBwJSIiIiJZYHAlIiIiIllgcCUiIiIiWWBwJSIiIiJZYHAlIiIiIllgcCUiIiIiWWBwJSIiIiJZYHAlIiIiIllgcCUiIiIiWWBwJSIiIiJZ0KjoAojehHqzf4eatl6xbZIXdXlL1RAREVF54IgrEREREckCgysRERERyQKDKxERERHJAoMrEREREckCgysRERERyQKDKxERERHJAoMrEREREckCgysRERERyQKDKxERERHJAoMrEREREckCgysRERERyQKDKxERERHJAoMrEREREckCgysRERERyQKDKxERERHJAoMrEREREckCgysRERERyQKDawn4+/ujR48eFV1GsaKioqBQKPDw4cMSbxMcHIwGDRq8sZoUCgV+/vnnN9Y/ERERVS6yDa7e3t4YP378G99GLlq0aIHU1FQYGRmVeJugoCBERkZK78sa0IsKwKmpqejUqVOp+yMiIiIqjEZFF0DAs2fPoKWl9Vp9aGlpoWrVqqXaxsDAAAYGBq+13+KUth4iIiKi4shyxNXf3x/R0dFYunQpFAoFFAoFkpOTER0djaZNm0JbWxtWVlaYNm0acnJyit0mNzcXw4YNg729PXR1dVGrVi0sXbq0zLV5e3sjICAAAQEBMDIyQpUqVTBz5kwIIaQ2dnZ2mDt3Lnx9faFUKjFy5EgAwJEjR+Dp6QldXV3Y2NggMDAQjx8/lrbLysrC1KlTYWNjA21tbTg6OuLbb78FUHCqQHh4OIyNjfHzzz/DyckJOjo68PHxwY0bN6T+XhwpDQ4OxoYNG7Br1y7p/ERFRQEApk6dCmdnZ+jp6cHBwQEzZ85Edna2tJ+QkBCcPn1a2i48PBxAwakCZ8+eRdu2baGrqwszMzOMHDkSGRkZKte1R48e+PLLL2FlZQUzMzOMHTtW2hcRERFVbrIccV26dCkuXbqEevXqYc6cOQCA3NxcdO7cGf7+/ti4cSMuXryIESNGQEdHB8HBwYVuY25ujry8PFSvXh0//vgjzMzMcPToUYwcORJWVlbo27dvmerbsGEDhg0bhuPHj+PEiRMYOXIkatSogREjRkhtvvzyS8yaNQuzZ88GAFy9ehUdO3bEvHnz8N133+HOnTtSAA4LCwMA+Pr6IjY2FsuWLUP9+vWRlJSEu3fvFllHZmYm5s+fj40bN0JLSwtjxoxB//79ERMTU6BtUFAQEhISkJ6eLu3P1NQUAGBoaIjw8HBYW1vj7NmzGDFiBAwNDTFlyhT069cP586dw759+3Dw4EEAKHS6wuPHj+Hj4wMPDw/ExcXh9u3bGD58OAICAqSgCwCHDx+GlZUVDh8+jCtXrqBfv35o0KCByrl7UVZWFrKysqT36enpRZ4PIiIikjdZBlcjIyNoaWlBT09P+jh6xowZsLGxwYoVK6BQKFC7dm3cvHkTU6dOxaxZswrdBgDU1dUREhIivbe3t0dsbCy2bdtW5uBqY2ODr7/+GgqFArVq1cLZs2fx9ddfq4Svtm3bYtKkSdL74cOHY9CgQdIcXCcnJyxbtgxeXl5YvXo1UlJSsG3bNhw4cADt27cHADg4OBRbR3Z2NlasWIFmzZoBeB6oXVxccPz4cTRt2lSlrYGBAXR1dZGVlVXgI/7PPvtM+tnOzg5BQUGIiIjAlClToKurCwMDA2hoaBQ7NeCHH37A06dPsXHjRujr6wMAVqxYgW7duuHzzz+HpaUlAMDExAQrVqyAuro6ateujS5duiAyMrLI4Lpw4UKV60dERETvL1lOFShMQkICPDw8oFAopGUtW7ZERkYG/vnnn2K3XblyJRo3bgxzc3MYGBhg7dq1SElJKXMtzZs3V6nDw8MDly9fRm5urrTM3d1dZZvTp08jPDxcmndqYGAAHx8f5OXlISkpCfHx8VBXV4eXl1eJ69DQ0ECTJk2k97Vr14axsTESEhJKdTxbt25Fy5YtUbVqVRgYGOCzzz4r9flJSEhA/fr1pdAKPL8+eXl5SExMlJbVrVsX6urq0nsrKyvcvn27yH6nT5+OtLQ06fXiVAgiIiJ6v8hyxLU8RUREICgoCEuWLIGHhwcMDQ3xxRdf4NixY290vy8GOADIyMjAJ598gsDAwAJta9SogStXrrzReooSGxuLQYMGISQkBD4+PjAyMkJERASWLFnyRvanqamp8l6hUCAvL6/I9tra2tDW1n4jtRAREdG7RbbBVUtLS2UE08XFBTt27IAQQhrtjImJgaGhIapXr17oNvltWrRogTFjxkjLrl69+lq1vRx6//rrLzg5OamMJL6sUaNGuHDhAhwdHQtd7+rqiry8PERHR0tTBV4lJycHJ06ckKYFJCYm4uHDh3BxcSm0fWHn5+jRo7C1tcWMGTOkZdevX3/ldi9zcXFBeHg4Hj9+LIX2mJgYqKmpoVatWiU6HiIiIqrcZDtVwM7ODseOHUNycjLu3r2LMWPG4MaNG/j0009x8eJF7Nq1C7Nnz8bEiROhpqZW6DZ5eXlwcnLCiRMn8Pvvv+PSpUuYOXMm4uLiXqu2lJQUTJw4EYmJidiyZQuWL1+OcePGFbvN1KlTcfToUQQEBCA+Ph6XL1/Grl27EBAQINXu5+eHoUOH4ueff0ZSUhKioqKwbdu2IvvU1NTEp59+imPHjuHkyZPw9/dH8+bNC8xvzWdnZ4czZ84gMTERd+/eRXZ2NpycnJCSkoKIiAhcvXoVy5Ytw08//VRgu/zpDHfv3lW5WSrfoEGDoKOjAz8/P5w7dw6HDx/Gp59+isGDB0vzW4mIiIiKI9vgGhQUBHV1ddSpUwfm5ubIzs7G3r17cfz4cdSvXx+jRo3CsGHDVG4senmblJQUfPLJJ+jVqxf69euHZs2a4d69eyqjr2Xh6+uLJ0+eoGnTphg7dizGjRsnPfKqKG5uboiOjsalS5fg6emJhg0bYtasWbC2tpbarF69Gr1798aYMWNQu3ZtjBgxQuVxWS/T09PD1KlTMXDgQLRs2RIGBgbYunVrke1HjBiBWrVqwd3dHebm5oiJicGHH36ICRMmICAgAA0aNMDRo0cxc+ZMle0++ugjdOzYEW3atIG5uTm2bNlSaC2///477t+/jyZNmqB3795o164dVqxYUex5ISIiIsqnEC8+YJRem7e3Nxo0aIDQ0NAKrSM8PBzjx48v1VfAvg/S09NhZGQEm/HboKatV2zb5EVd3lJVREREVJz8399paWlQKpVFtpPtiCsRERERVS6yvTmrIqSkpKBOnTpFrr9w4cJbrIaIiIiocuFUgVLIyclBcnJykevt7OygocG/BSoSpwoQERHJT0mnCjBllYKGhkaRj6siIiIiojeLc1yJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWNCq6AKI34VyID5RKZUWXQUREROWII65EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCxoVXQDRm1Bv9u9Q09Z7rT6SF3Upp2qIiIioPHDElYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBtRyFh4fD2Ni4ost4K5KTk6FQKBAfH1/RpRAREVElweBKKp49e1Yp9klERETy884GV29vb3z66acYP348TExMYGlpiXXr1uHx48cYMmQIDA0N4ejoiN9++03a5ty5c+jUqRMMDAxgaWmJwYMH4+7du9L6ffv2oVWrVjA2NoaZmRm6du2Kq1evSuvzRxF37tyJNm3aQE9PD/Xr10dsbOwr642KisKQIUOQlpYGhUIBhUKB4OBgAEBWVhaCgoJQrVo16Ovro1mzZoiKipK2zR+p3b17N2rVqgU9PT307t0bmZmZ2LBhA+zs7GBiYoLAwEDk5uZK29nZ2WHu3LkYMGAA9PX1Ua1aNaxcuVKlrocPH2L48OEwNzeHUqlE27Ztcfr0aWl9cHAwGjRogPXr18Pe3h46OjolOlf29vYAgIYNG0KhUMDb21u6buPHj1epoUePHvD39y9Qt6+vL5RKJUaOHAkAOHLkCDw9PaGrqwsbGxsEBgbi8ePHrzz3REREVDm8s8EVADZs2IAqVarg+PHj+PTTTzF69Gj06dMHLVq0wN9//40PPvgAgwcPRmZmJh4+fIi2bduiYcOGOHHiBPbt24dbt26hb9++Un+PHz/GxIkTceLECURGRkJNTQ09e/ZEXl6eyn5nzJiBoKAgxMfHw9nZGQMGDEBOTk6xtbZo0QKhoaFQKpVITU1FamoqgoKCAAABAQGIjY1FREQEzpw5gz59+qBjx464fPmytH1mZiaWLVuGiIgI7Nu3D1FRUejZsyf27t2LvXv3YtOmTfjmm2+wfft2lf1+8cUXqF+/Pk6dOoVp06Zh3LhxOHDggLS+T58+uH37Nn777TecPHkSjRo1Qrt27XD//n2pzZUrV7Bjxw7s3LlT+uj/Vefq+PHjAICDBw8iNTUVO3fuLOllBQB8+eWXUt0zZ87E1atX0bFjR3z00Uc4c+YMtm7diiNHjiAgIKDYfrKyspCenq7yIiIioveTQgghKrqIwnh7eyM3Nxd//vknACA3NxdGRkbo1asXNm7cCAD477//YGVlhdjYWBw8eBB//vknfv/9d6mPf/75BzY2NkhMTISzs3OBfdy9exfm5uY4e/Ys6tWrh+TkZNjb22P9+vUYNmwYAODChQuoW7cuEhISULt27WJrDg8Px/jx4/Hw4UNpWUpKChwcHJCSkgJra2tpefv27dG0aVMsWLAA4eHhGDJkCK5cuYKaNWsCAEaNGoVNmzbh1q1bMDAwAAB07NgRdnZ2WLNmDYDnI5cuLi4qo879+/dHeno69u7diyNHjqBLly64ffs2tLW1pTaOjo6YMmUKRo4cieDgYCxYsAD//vsvzM3Nizy2os7VqVOn0KBBA5Xr1qBBA4SGhkrLevToAWNjY4SHh0t1N2zYED/99JPUZvjw4VBXV8c333wjLTty5Ai8vLzw+PFjaST4ZcHBwQgJCSmw3Gb8Nqhp6xV5PCWRvKjLa21PREREJZOeng4jIyOkpaVBqVQW2e6dHnF1c3OTflZXV4eZmRlcXV2lZZaWlgCA27dv4/Tp0zh8+DAMDAykV37QzP+I+/LlyxgwYAAcHBygVCphZ2cH4Hm4LGq/VlZW0j7K4uzZs8jNzYWzs7NKbdHR0Sofvevp6UmhNf/Y7OzspNCav+zlOjw8PAq8T0hIAACcPn0aGRkZMDMzU9l3UlKSyr5tbW0LhNaSnquycnd3V3l/+vRphIeHq9Tp4+ODvLw8JCUlFdnP9OnTkZaWJr1u3LhRLvURERHRu0ejogsojqampsp7hUKhskyhUAAA8vLykJGRgW7duuHzzz8v0E9++OzWrRtsbW2xbt06WFtbIy8vD/Xq1Stwc1BR+yiLjIwMqKur4+TJk1BXV1dZ92IofdWx5i8rTR0ZGRmwsrJSmU+b78WnH+jr6xdYX9Jz9TI1NTW8PIifnZ1doN3L+8zIyMAnn3yCwMDAAm1r1KhR5P60tbVVRpOJiIjo/fVOB9fSaNSoEXbs2AE7OztoaBQ8rHv37iExMRHr1q2Dp6cngOcfRZcnLS0tlZungOc3L+Xm5uL27dvSfsvTX3/9VeC9i4sLgOfn5L///oOGhoY0YloSJTlXWlpaAFDgeM3NzZGamiq9z83Nxblz59CmTZti99moUSNcuHABjo6OJa6TiIiIKpd3eqpAaYwdOxb379/HgAEDEBcXh6tXr+L333/HkCFDkJubCxMTE5iZmWHt2rW4cuUKDh06hIkTJ5ZrDXZ2dsjIyEBkZCTu3r2LzMxMODs7Y9CgQfD19cXOnTuRlJSE48ePY+HChdizZ89r7zMmJgaLFy/GpUuXsHLlSvz4448YN24cgOfzaD08PNCjRw/s378fycnJOHr0KGbMmIETJ04U2WdJzpWFhQV0dXWlm+DS0tIAAG3btsWePXuwZ88eXLx4EaNHj1aZ81uUqVOn4ujRowgICEB8fDwuX76MXbt2vfLmLCIiIqo83pvgam1tjZiYGOTm5uKDDz6Aq6srxo8fD2NjY6ipqUFNTQ0RERE4efIk6tWrhwkTJuCLL74o1xpatGiBUaNGoV+/fjA3N8fixYsBAGFhYfD19cWkSZNQq1Yt9OjRA3FxccV+BF5SkyZNwokTJ9CwYUPMmzcPX331FXx8fAA8n1qwd+9etG7dGkOGDIGzszP69++P69evS/ODC1OSc6WhoYFly5bhm2++gbW1Nbp37w4AGDp0KPz8/ODr6wsvLy84ODi8crQVeD6vODo6GpcuXYKnpycaNmyIWbNmqdzQRkRERJXbO/tUAXo1Ozs7jB8/vsBzUyuz/LsS+VQBIiIi+XgvnipARERERJSPwbUU8r+Vq7DXggULKro8IiIiovfae/NUgbdh/fr1ePLkSaHrTE1N33I1z7+iloiIiKiyYHAthWrVqlV0CURERESVFqcKEBEREZEsMLgSERERkSwwuBIRERGRLDC4EhEREZEsMLgSERERkSwwuBIRERGRLDC4EhEREZEsMLgSERERkSwwuBIRERGRLDC4EhEREZEsMLgSERERkSwwuBIRERGRLGhUdAFEb8K5EB8olcqKLoOIiIjKEUdciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBY0KroAojeh3uzfoaatBwBIXtSlgqshIiKi8sARVyIiIiKSBQZXIiIiIpIFBlciIiIikgUGVyIiIiKSBQZXIiIiIpIFBlciIiIikgUGVyIiIiKSBQZXIiIiIpIFBlciIiIikgUGVyIiIiKSBQZXIiIiIpIFBlciIiIikgUGVyIiIiKSBQZXIiIiIpIFBlciIiIikgUGVyIiIiKSBQZXIiIiIpIFBte3zNvbG+PHj6/oMkolPDwcxsbGb32/wcHBaNCgwVvfLxEREb2bNCq6gMpm586d0NTUrOgyiIiIiGSHwfUtMzU1regSiIiIiGSJUwXeshenCqxatQpOTk7Q0dGBpaUlevfu/crtd+/eDWNjY+Tm5gIA4uPjoVAoMG3aNKnN8OHD8fHHH0vvjxw5Ak9PT+jq6sLGxgaBgYF4/PixtD4rKwtBQUGoVq0a9PX10axZM0RFRRVZw507d+Du7o6ePXsiKysLeXl5WLhwIezt7aGrq4v69etj+/btUvuoqCgoFApERkbC3d0denp6aNGiBRITE1X6XbRoESwtLWFoaIhhw4bh6dOnrzwfREREVHkwuFaQEydOIDAwEHPmzEFiYiL27duH1q1bv3I7T09PPHr0CKdOnQIAREdHo0qVKipBMzo6Gt7e3gCAq1evomPHjvjoo49w5swZbN26FUeOHEFAQIDUPiAgALGxsYiIiMCZM2fQp08fdOzYEZcvXy6w/xs3bsDT0xP16tXD9u3boa2tjYULF2Ljxo1Ys2YNzp8/jwkTJuDjjz9GdHS0yrYzZszAkiVLcOLECWhoaGDo0KHSum3btiE4OBgLFizAiRMnYGVlhVWrVr3yfGRlZSE9PV3lRURERO8pQW+Vl5eXGDdunNixY4dQKpUiPT291H00atRIfPHFF0IIIXr06CHmz58vtLS0xKNHj8Q///wjAIhLly4JIYQYNmyYGDlypMr2f/75p1BTUxNPnjwR169fF+rq6uLff/9VadOuXTsxffp0IYQQYWFhwsjISFy8eFHY2NiIwMBAkZeXJ4QQ4unTp0JPT08cPXpUZfthw4aJAQMGCCGEOHz4sAAgDh48KK3fs2ePACCePHkihBDCw8NDjBkzRqWPZs2aifr16xd7LmbPni0AFHjZjN8mbKfuFrZTd7/yfBIREVHFSktLEwBEWlpase044lpBOnToAFtbWzg4OGDw4MHYvHkzMjMzS7Stl5cXoqKiIITAn3/+iV69esHFxQVHjhxBdHQ0rK2t4eTkBAA4ffo0wsPDYWBgIL18fHyQl5eHpKQknD17Frm5uXB2dlZpEx0djatXr0r7fPLkCTw9PdGrVy8sXboUCoUCAHDlyhVkZmaiQ4cOKttv3LhRZXsAcHNzk362srICANy+fRsAkJCQgGbNmqm09/DweOW5mD59OtLS0qTXjRs3SnQOiYiISH54c1YFMTQ0xN9//42oqCjs378fs2bNQnBwMOLi4l756Clvb2989913OH36NDQ1NVG7dm14e3sjKioKDx48gJeXl9Q2IyMDn3zyCQIDAwv0U6NGDZw5cwbq6uo4efIk1NXVVdYbGBhIP2tra6N9+/bYvXs3Jk+ejGrVqkn9A8CePXukZS9u86IXn6aQH3zz8vKKPdZX0dbWLrAfIiIiej8xuFYgDQ0NtG/fHu3bt8fs2bNhbGyMQ4cOoVevXsVulz/P9euvv5ZCqre3NxYtWoQHDx5g0qRJUttGjRrhwoULcHR0LLSvhg0bIjc3F7dv34anp2eR+1RTU8OmTZswcOBAtGnTBlFRUbC2tkadOnWgra2NlJQUlcBcWi4uLjh27Bh8fX2lZX/99VeZ+yMiIqL3D4NrBdm9ezeuXbuG1q1bw8TEBHv37kVeXh5q1ar1ym1NTEzg5uaGzZs3Y8WKFQCA1q1bo2/fvsjOzlYJkFOnTkXz5s0REBCA4cOHQ19fHxcuXMCBAwewYsUKODs7Y9CgQfD19cWSJUvQsGFD3LlzB5GRkXBzc0OXLl2kvtTV1bF582YMGDAAbdu2RVRUFKpWrYqgoCBMmDABeXl5aNWqFdLS0hATEwOlUgk/P78SnY9x48bB398f7u7uaNmyJTZv3ozz58/DwcGhlGeWiIiI3lcMrhXE2NgYO3fuRHBwMJ4+fQonJyds2bIFdevWLdH2Xl5eiI+Pl54eYGpqijp16uDWrVsq4dfNzQ3R0dGYMWMGPD09IYRAzZo10a9fP6lNWFgY5s2bh0mTJuHff/9FlSpV0Lx5c3Tt2rXAfjU0NLBlyxb069dPCq9z586Fubk5Fi5ciGvXrsHY2BiNGjXC//73vxKfj379+uHq1auYMmUKnj59io8++gijR4/G77//XuI+iIiI6P2mEEKIsmy4adMmrFmzBklJSYiNjYWtrS1CQ0Nhb2+P7t27l3edRCWSnp4OIyMj2IzfBjVtPQBA8qIur9iKiIiIKlL+7++0tDQolcoi25XpqQKrV6/GxIkT0blzZzx8+FB6GL6xsTFCQ0PLVDARERERUXHKFFyXL1+OdevWYcaMGSp3oru7u+Ps2bPlVlxllJKSovJYqZdfKSkpFV0iERERUYUo0xzXpKQkNGzYsMBybW1tla8SpdKztrZGfHx8seuJiIiIKqMyBVd7e3vEx8fD1tZWZfm+ffvg4uJSLoVVVhoaGkU+uoqIiIioMitTcJ04cSLGjh2Lp0+fQgiB48ePY8uWLVi4cCHWr19f3jUSEREREZUtuA4fPhy6urr47LPPkJmZiYEDB8La2hpLly5F//79y7tGIiIiIqLSB9ecnBz88MMP8PHxwaBBg5CZmYmMjAxYWFi8ifqIiIiIiACU4akCGhoaGDVqFJ4+fQoA0NPTY2glIiIiojeuTI/Datq0KU6dOlXetRARERERFalMc1zHjBmDSZMm4Z9//kHjxo2hr6+vst7Nza1ciiMiIiIiylem4Jp/A1ZgYKC0TKFQQAgBhUIhfZMWEREREVF5KfMXEBARERERvU1lCq4vf/EAEREREdGbVqbgunHjxmLX+/r6lqkYIiIiIqKilCm4jhs3TuV9dnY2MjMzoaWlBT09PQZXIiIiIip3ZXoc1oMHD1ReGRkZSExMRKtWrbBly5byrpGIiIiICAohhCivzk6cOIGPP/4YFy9eLK8uiUolPT0dRkZGSEtLg1KprOhyiIiIqARK+vu7TCOuRdHQ0MDNmzfLs0siIiIiIgBlnOP6yy+/qLwXQiA1NRUrVqxAy5Yty6UwIiIiIqIXlSm49ujRQ+W9QqGAubk52rZtiyVLlpRHXUREREREKsoUXPPy8sq7DiIiIiKiYpVpjuucOXOQmZlZYPmTJ08wZ86c1y6KiIiIiOhlZXqqgLq6OlJTU2FhYaGy/N69e7CwsEBubm65FUhUGnyqABERkfy80acKCCGgUCgKLD99+jRMTU3L0iURERERUbFKNcfVxMQECoUCCoUCzs7OKuE1NzcXGRkZGDVqVLkXSURERERUquAaGhoKIQSGDh2KkJAQGBkZSeu0tLRgZ2cHDw+Pci+SiIiIiKhUwdXPzw8AYG9vjxYtWkBTU/ONFEVERERE9LIyPQ7Ly8tL+vnp06d49uyZynreFENERERE5a1MN2dlZmYiICAAFhYW0NfXh4mJicqLiIiIiKi8lSm4Tp48GYcOHcLq1auhra2N9evXIyQkBNbW1ti4cWN510hEREREVLapAr/++is2btwIb29vDBkyBJ6ennB0dIStrS02b96MQYMGlXedRERERFTJlWnE9f79+3BwcADwfD7r/fv3AQCtWrXCH3/8UX7VERERERH9f2UKrg4ODkhKSgIA1K5dG9u2bQPwfCTW2Ni43IojIiIiIspXpuA6ZMgQnD59GgAwbdo0rFy5Ejo6OpgwYQImT55crgUSEREREQGAQgghXreT69ev4+TJk3B0dISbm1t51EVUJiX9rmMiIiJ6d5T093eZbs560dOnT2FrawtbW9vX7YqIiIiIqEhlmiqQm5uLuXPnolq1ajAwMMC1a9cAADNnzsS3335brgUSEREREQFlDK7z589HeHg4Fi9eDC0tLWl5vXr1sH79+nIrjoiIiIgoX5mC68aNG7F27VoMGjQI6urq0vL69evj4sWL5VYcEREREVG+MgXXf//9F46OjgWW5+XlITs7+7WLIiIiIiJ6WZmCa506dfDnn38WWL59+3Y0bNjwtYsiIiIiInpZmZ4qMGvWLPj5+eHff/9FXl4edu7cicTERGzcuBG7d+8u7xqJiIiIiEo34nrt2jUIIdC9e3f8+uuvOHjwIPT19TFr1iwkJCTg119/RYcOHd5UrURERERUiZVqxNXJyQmpqamwsLCAp6cnTE1NcfbsWVhaWr6p+oiIiIiIAJRyxPXlL9n67bff8Pjx43ItiIiIiIioMGW6OStfOXxbLBERERFRiZQquCoUCigUigLL6M3x9vbG+PHjK7yP4OBgNGjQQHrv7++PHj16vPH9EhEREeUr1RxXIQT8/f2hra0NAHj69ClGjRoFfX19lXY7d+4svworuZ07d0JTU7Oiyyhg6dKlHHEnIiKit6pUwdXPz0/l/ccff1yuxVBBpqamFV1CoYyMjCq6BCIiIqpkSjVVICwsrEQvKj8vfty+atUqODk5QUdHB5aWlujdu3eJ+8nLy8OUKVNgamqKqlWrIjg4WGV9SkoKunfvDgMDAyiVSvTt2xe3bt0qsr+Xpwo8fvwYvr6+MDAwgJWVFZYsWVJgm02bNsHd3R2GhoaoWrUqBg4ciNu3bwN4Pprv6OiIL7/8UmWb+Ph4KBQKXLlypcTHSkRERO+n17o5i96eEydOIDAwEHPmzEFiYiL27duH1q1bl3j7DRs2QF9fH8eOHcPixYsxZ84cHDhwAMDzUNu9e3fcv38f0dHROHDgAK5du4Z+/fqVuP/JkycjOjoau3btwv79+xEVFYW///5bpU12djbmzp2L06dP4+eff0ZycjL8/f0BPJ8rPXTo0AJ/+ISFhaF169aFfsUwAGRlZSE9PV3lRURERO+nMn1zFr19KSkp0NfXR9euXWFoaAhbW9tSfb2um5sbZs+eDeD583hXrFiByMhIdOjQAZGRkTh79iySkpJgY2MDANi4cSPq1q2LuLg4NGnSpNi+MzIy8O233+L7779Hu3btADwPytWrV1dpN3ToUOlnBwcHLFu2DE2aNEFGRgYMDAzg7++PWbNm4fjx42jatCmys7Pxww8/FBiFfdHChQsREhJS4vNARERE8sURV5no0KEDbG1t4eDggMGDB2Pz5s3IzMws8fZubm4q762srKSP6RMSEmBjYyOFVgCoU6cOjI2NkZCQ8Mq+r169imfPnqFZs2bSMlNTU9SqVUul3cmTJ9GtWzfUqFEDhoaG8PLyAvA8lAOAtbU1unTpgu+++w4A8OuvvyIrKwt9+vQpct/Tp09HWlqa9Lpx48Yr6yUiIiJ5YnCVCUNDQ/z999/YsmULrKysMGvWLNSvXx8PHz4s0fYvP5lAoVAgLy/vDVRauMePH8PHxwdKpRKbN29GXFwcfvrpJwDAs2fPpHbDhw9HREQEnjx5grCwMPTr1w96enpF9qutrQ2lUqnyIiIiovcTg6uMaGhooH379li8eDHOnDmD5ORkHDp06LX7dXFxwY0bN1RGKy9cuICHDx+iTp06r9y+Zs2a0NTUxLFjx6RlDx48wKVLl6T3Fy9exL1797Bo0SJ4enqidu3a0ojvizp37gx9fX2sXr0a+/btU5leQERERJUb57jKxO7du3Ht2jW0bt0aJiYm2Lt3L/Ly8gp8HF8W7du3h6urKwYNGoTQ0FDk5ORgzJgx8PLygru7+yu3NzAwwLBhwzB58mSYmZnBwsICM2bMgJra//1dVKNGDWhpaWH58uUYNWoUzp07h7lz5xboS11dHf7+/pg+fTqcnJzg4eHx2sdHRERE7weOuMqEsbExdu7cibZt28LFxQVr1qzBli1bULdu3dfuW6FQYNeuXTAxMUHr1q3Rvn17ODg4YOvWrSXu44svvoCnpye6deuG9u3bo1WrVmjcuLG03tzcHOHh4fjxxx9Rp04dLFq0qMibroYNG4Znz55hyJAhr31sRERE9P5QCH79Eb1j/vzzT7Rr1w43btyApaVlqbZNT0+HkZER0tLSON+ViIhIJkr6+5tTBeidkZWVhTt37iA4OBh9+vQpdWglIiKi9xunCshcSkoKDAwMinzlP2pKDrZs2QJbW1s8fPgQixcvruhyiIiI6B3DqQIyl5OTg+Tk5CLX29nZQUOj8gysc6oAERGR/HCqQCWhoaFR5NehEhEREb1POFWAiIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkQaOiCyB6E+rN/h1q2noVXQYREdF7I3lRl4ougSOuRERERCQPDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAuVKrgGBwejQYMGFV1GAXZ2dggNDa3oMgAAycnJUCgUiI+Pr+hSiIiIiFRUquBaXsoagMPDw2FsbFxgeVxcHEaOHPn6hb2DijpmIiIiotLSqOgCCDA3N6/oEt55ubm5UCgUUFPj31pERESV1TubAvLy8rBw4ULY29tDV1cX9evXx/bt2wEAUVFRUCgUiIyMhLu7O/T09NCiRQskJiaq9LFo0SJYWlrC0NAQw4YNw9OnT0u8/6ioKDRt2hT6+vowNjZGy5Ytcf36dYSHhyMkJASnT5+GQqGAQqFAeHg4AOCrr76Cq6sr9PX1YWNjgzFjxiAjI0Pqb8iQIUhLS5O2Cw4OBlBwqkBKSgq6d+8OAwMDKJVK9O3bF7du3ZLW54/4btq0CXZ2djAyMkL//v3x6NGjEp/bxYsXw9HREdra2qhRowbmz59faNvCRkx//vlnKBQK6f3p06fRpk0bGBoaQqlUonHjxjhx4kSxx5yVlYWgoCBUq1YN+vr6aNasGaKiogrs95dffkGdOnWgra2NlJSUEh0fERERvZ/e2eC6cOFCbNy4EWvWrMH58+cxYcIEfPzxx4iOjpbazJgxA0uWLMGJEyegoaGBoUOHSuu2bduG4OBgLFiwACdOnICVlRVWrVpVon3n5OSgR48e8PLywpkzZxAbG4uRI0dCoVCgX79+mDRpEurWrYvU1FSkpqaiX79+AAA1NTUsW7YM58+fx4YNG3Do0CFMmTIFANCiRQuEhoZCqVRK2wUFBRXYd15eHrp374779+8jOjoaBw4cwLVr16R95Lt69Sp+/vln7N69G7t370Z0dDQWLVpUouObPn06Fi1ahJkzZ+LChQv44YcfYGlpWaJtCzNo0CBUr14dcXFxOHnyJKZNmwZNTc1ijzkgIACxsbGIiIjAmTNn0KdPH3Ts2BGXL1+W+s3MzMTnn3+O9evX4/z587CwsCiw76ysLKSnp6u8iIiI6P30Tk4VyMrKwoIFC3Dw4EF4eHgAABwcHHDkyBF888030nzQ+fPnw8vLCwAwbdo0dOnSBU+fPoWOjg5CQ0MxbNgwDBs2DAAwb948HDx4sESjrunp6UhLS0PXrl1Rs2ZNAICLi4u03sDAABoaGqhatarKduPHj5d+trOzw7x58zBq1CisWrUKWlpaMDIygkKhKLDdiyIjI3H27FkkJSXBxsYGALBx40bUrVsXcXFxaNKkCYDnATc8PByGhoYAgMGDByMyMrLIkdN8jx49wtKlS7FixQr4+fkBAGrWrIlWrVq98rwUJSUlBZMnT0bt2rUBAE5OTtK6wo45JSUFYWFhSElJgbW1NQAgKCgI+/btQ1hYGBYsWAAAyM7OxqpVq1C/fv0i971w4UKEhISUuXYiIiKSj3dyxPXKlSvIzMxEhw4dYGBgIL02btyIq1evSu3c3Nykn62srAAAt2/fBgAkJCSgWbNmKv3mh+BXMTU1hb+/P3x8fNCtWzcsXboUqampr9zu4MGDaNeuHapVqwZDQ0MMHjwY9+7dQ2ZmZon2m1+3jY2NFFoBoE6dOjA2NkZCQoK0zM7OTgqtwPPjzz/2V/WflZWFdu3albimV5k4cSKGDx+O9u3bY9GiRSrXqDBnz55Fbm4unJ2dVa5vdHS0yrZaWloq17gw06dPR1pamvS6ceNGuRwTERERvXveyeCaPy90z549iI+Pl14XLlyQ5rkCgKampvRz/pzLvLy8cqkhLCwMsbGxaNGiBbZu3QpnZ2f89ddfRbZPTk5G165d4ebmhh07duDkyZNYuXIlAODZs2flUtOLXjx24Pnxl+TYdXV1S7UfNTU1CCFUlmVnZ6u8Dw4Oxvnz59GlSxccOnQIderUwU8//VRknxkZGVBXV8fJkydVrm9CQgKWLl2qUuuLc2kLo62tDaVSqfIiIiKi99M7GVxfvBnH0dFR5fXiSGRxXFxccOzYMZVlxQXPwjRs2BDTp0/H0aNHUa9ePfzwww8Ano8E5ubmqrQ9efIk8vLysGTJEjRv3hzOzs64efOmSpvCtius7hs3bqiMHF64cAEPHz5EnTp1SlV/YZycnKCrq4vIyMgStTc3N8ejR4/w+PFjaVlhz3h1dnbGhAkTsH//fvTq1QthYWEACj/mhg0bIjc3F7dv3y5wfYubRkFERESV2zs5x9XQ0BBBQUGYMGEC8vLy0KpVK6SlpSEmJgZKpRK2trav7GPcuHHw9/eHu7s7WrZsic2bN+P8+fNwcHB45bZJSUlYu3YtPvzwQ1hbWyMxMRGXL1+Gr68vgOcf0yclJSE+Ph7Vq1eHoaEhHB0dkZ2djeXLl6Nbt26IiYnBmjVrVPq1s7NDRkYGIiMjUb9+fejp6UFPT0+lTfv27eHq6opBgwYhNDQUOTk5GDNmDLy8vODu7l6Ks1g4HR0dTJ06FVOmTIGWlhZatmyJO3fu4Pz589J84Bc1a9YMenp6+N///ofAwEAcO3ZMeooCADx58gSTJ09G7969YW9vj3/++QdxcXH46KOPijxmZ2dnDBo0CL6+vliyZAkaNmyIO3fuIDIyEm5ubujSpctrHycRERG9f97JEVcAmDt3LmbOnImFCxfCxcUFHTt2xJ49e2Bvb1+i7fv164eZM2diypQpaNy4Ma5fv47Ro0eXaFs9PT1cvHgRH330EZydnTFy5EiMHTsWn3zyCQDgo48+QseOHdGmTRuYm5tjy5YtqF+/Pr766it8/vnnqFevHjZv3oyFCxeq9NuiRQuMGjUK/fr1g7m5ORYvXlxg3wqFArt27YKJiQlat26N9u3bw8HBAVu3bi1R7SUxc+ZMTJo0CbNmzYKLiwv69etX5PxYU1NTfP/999i7dy9cXV2xZcsW6ZFWAKCuro579+7B19cXzs7O6Nu3Lzp16iTdMFXUMYeFhcHX1xeTJk1CrVq10KNHD8TFxaFGjRrldpxERET0flGIlycwEslYeno6jIyMYDN+G9S09V69AREREZVI8qI394lo/u/vtLS0Yu9XeWdHXImIiIiIXlRpg+uLj2F6+fXnn39WdHlllpKSUuyx8duniIiISK7eyZuz3obC7ozPV61atbdXSDmztrYu9tjyH/hPREREJDeVNrg6OjpWdAlvhIaGxnt7bERERFS5VdqpAkREREQkLwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsaFV0A0ZtwLsQHSqWyossgIiKicsQRVyIiIiKSBQZXIiIiIpIFBlciIiIikgUGVyIiIiKSBQZXIiIiIpIFBlciIiIikgUGVyIiIiKSBQZXIiIiIpIFBlciIiIikgUGVyIiIiKSBQZXIiIiIpIFjYougOhNqDf7d6hp61V0GURERLKWvKhLRZeggiOuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrkREREQkCwyuRERERCQLDK5EREREJAsMrhUsODgYDRo0qOgyJN7e3hg/fnxFl0FERERUwDsZXP39/dGjR49y6688w1hycjIUCgXi4+NLva1CocDPP/+ssiwoKAiRkZHlUtu7qLBjJiIiIiqLdzK4lpdnz55VdAmvZGBgADMzs4ou452XnZ1d0SUQERFRBavQ4Lp9+3a4urpCV1cXZmZmaN++PSZPnowNGzZg165dUCgUUCgUiIqKAgBMnToVzs7O0NPTg4ODA2bOnKkSaPI/dl+/fj3s7e2ho6MDf39/REdHY+nSpVJ/ycnJxdb14MEDDBo0CObm5tDV1YWTkxPCwsIAAPb29gCAhg0bQqFQwNvbGwAQFxeHDh06oEqVKjAyMoKXlxf+/vtvqU87OzsAQM+ePaFQKKT3L08VyMvLw5w5c1C9enVoa2ujQYMG2Ldvn7Q+f8R3586daNOmDfT09FC/fn3ExsaW+LzHxMTA29sbenp6MDExgY+PDx48eFBo28JGTI2NjREeHg7g+R8HAQEBsLKygo6ODmxtbbFw4cJijxkAdu3ahUaNGkFHRwcODg4ICQlBTk6Oyn5Xr16NDz/8EPr6+pg/f36Jj4+IiIjeTxoVtePU1FQMGDAAixcvRs+ePfHo0SP8+eef8PX1RUpKCtLT06WwaGpqCgAwNDREeHg4rK2tcfbsWYwYMQKGhoaYMmWK1O+VK1ewY8cO7Ny5E+rq6rC1tcWlS5dQr149zJkzBwBgbm5ebG0zZ87EhQsX8Ntvv6FKlSq4cuUKnjx5AgA4fvw4mjZtioMHD6Ju3brQ0tICADx69Ah+fn5Yvnw5hBBYsmQJOnfujMuXL8PQ0BBxcXGwsLBAWFgYOnbsCHV19UL3vXTpUixZsgTffPMNGjZsiO+++w4ffvghzp8/DycnJ6ndjBkz8OWXX8LJyQkzZszAgAEDcOXKFWhoFH9J4+Pj0a5dOwwdOhRLly6FhoYGDh8+jNzc3GK3K8qyZcvwyy+/YNu2bahRowZu3LiBGzduAECRx5x/nZctWwZPT09cvXoVI0eOBADMnj1b6js4OBiLFi1CaGhokceVlZWFrKws6X16enqZjoOIiIjefRUaXHNyctCrVy/Y2toCAFxdXQEAurq6yMrKQtWqVVW2+eyzz6Sf7ezsEBQUhIiICJXg+uzZM2zcuFElnGppaUFPT69Af0VJSUlBw4YN4e7uLu0rX36/ZmZmKv21bdtWpY+1a9fC2NgY0dHR6Nq1q7SdsbFxsXV8+eWXmDp1Kvr37w8A+Pzzz3H48GGEhoZi5cqVUrugoCB06dIFABASEoK6deviypUrqF27drHHtnjxYri7u2PVqlXSsrp16xa7TXFSUlLg5OSEVq1aQaFQSNcSQJHHHBISgmnTpsHPzw8A4ODggLlz52LKlCkqwXXgwIEYMmRIsftfuHAhQkJCylw/ERERyUeFTRWoX78+2rVrB1dXV/Tp0wfr1q0r8uPqfFu3bkXLli1RtWpVGBgY4LPPPkNKSopKG1tb21eOqL7K6NGjERERgQYNGmDKlCk4evToK7e5desWRowYAScnJxgZGUGpVCIjI6NAfcVJT0/HzZs30bJlS5XlLVu2REJCgsoyNzc36WcrKysAwO3bt1+5j/wR1/Li7++P+Ph41KpVC4GBgdi/f/8rtzl9+jTmzJkDAwMD6TVixAikpqYiMzNTapf/h0Nxpk+fjrS0NOmVP9pLRERE758KC67q6uo4cOAAfvvtN9SpUwfLly9HrVq1kJSUVGj72NhYDBo0CJ07d8bu3btx6tQpzJgxo8ANWPr6+q9dW6dOnXD9+nVMmDABN2/eRLt27RAUFFTsNn5+foiPj8fSpUtx9OhRxMfHw8zM7I3dIKapqSn9rFAoADyfH/squrq6pdqPQqGAEEJl2Yvzihs1aoSkpCTMnTsXT548Qd++fdG7d+9i+8zIyEBISAji4+Ol19mzZ3H58mXo6OhI7UpyLbW1taFUKlVeRERE9H6q0JuzFAoFWrZsiZCQEJw6dQpaWlr46aefoKWlVWDO5dGjR2Fra4sZM2bA3d0dTk5OuH79eon2U1h/r2Jubg4/Pz98//33CA0Nxdq1a6W+ABToLyYmBoGBgejcuTPq1q0LbW1t3L17V6WNpqZmsXUolUpYW1sjJiamQN916tQpVf1FcXNzK9Xjt8zNzZGamiq9v3z5ssqoKPC87n79+mHdunXYunUrduzYgfv37wMo/JgbNWqExMREODo6Fnipqb3XD7ogIiKi11Bhc1yPHTuGyMhIfPDBB7CwsMCxY8dw584duLi44OnTp/j999+RmJgIMzMzGBkZwcnJCSkpKYiIiECTJk2wZ88e/PTTTyXal52dHY4dO4bk5GQYGBjA1NS02IA0a9YsNG7cGHXr1kVWVhZ2794NFxcXAICFhQV0dXWxb98+VK9eHTo6OlJ9mzZtgru7O9LT0zF58uQCo5t2dnaIjIxEy5Ytoa2tDRMTkwL7njx5MmbPno2aNWuiQYMGCAsLQ3x8PDZv3lyKs1u06dOnw9XVFWPGjMGoUaOgpaWFw4cPo0+fPqhSpUqB9m3btsWKFSvg4eGB3NxcTJ06VWW096uvvoKVlRUaNmwINTU1/Pjjj6hatSqMjY2LPOZZs2aha9euqFGjBnr37g01NTWcPn0a586dw7x588rlOImIiOj9U2HDW0qlEn/88Qc6d+4MZ2dnfPbZZ1iyZAk6deqEESNGoFatWnB3d4e5uTliYmLw4YcfYsKECQgICECDBg1w9OhRzJw5s0T7CgoKgrq6OurUqQNzc/NXzjvV0tLC9OnT4ebmhtatW0NdXR0REREAAA0NDSxbtgzffPMNrK2t0b17dwDAt99+iwcPHqBRo0YYPHgwAgMDYWFhodLvkiVLcODAAdjY2KBhw4aF7jswMBATJ07EpEmT4Orqin379uGXX35ReaLA63B2dsb+/ftx+vRpNG3aFB4eHti1a1eRd+0vWbIENjY28PT0xMCBAxEUFAQ9PT1pvaGhoXTDV5MmTZCcnIy9e/dKfxgUdsw+Pj7YvXs39u/fjyZNmqB58+b4+uuvVW7sIiIiInqZQrw8gZFIxtLT02FkZASb8dugpq336g2IiIioSMmLuryV/eT//k5LSyv2fhVOKCQiIiIiWaiUwXXUqFEqj2J68TVq1KiKLu+1dOrUqchjW7BgQUWXR0RERFRmFXZzVkWaM2dOkY+3kvvjlNavXy99y9fL8r+BjIiIiEiOKmVwtbCwKHDj1PuiWrVqFV0CERER0RtRKacKEBEREZH8MLgSERERkSwwuBIRERGRLDC4EhEREZEsMLgSERERkSwwuBIRERGRLDC4EhEREZEsMLgSERERkSwwuBIRERGRLDC4EhEREZEsMLgSERERkSwwuBIRERGRLGhUdAFEb8K5EB8olcqKLoOIiIjKEUdciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFjQqugCi8iSEAACkp6dXcCVERERUUvm/t/N/jxeFwZXeK/fu3QMA2NjYVHAlREREVFqPHj2CkZFRkesZXOm9YmpqCgBISUkp9h8+vX3p6emwsbHBjRs3oFQqK7ocegGvzbuL1+bdxWtTvoQQePToEaytrYttx+BK7xU1tefTto2MjPg/kneUUqnktXlH8dq8u3ht3l28NuWnJANOvDmLiIiIiGSBwZWIiIiIZIHBld4r2tramD17NrS1tSu6FHoJr827i9fm3cVr8+7itakYCvGq5w4QEREREb0DOOJKRERERLLA4EpEREREssDgSkRERESywOBKRERERLLA4Eqys3LlStjZ2UFHRwfNmjXD8ePHi23/448/onbt2tDR0YGrqyv27t37liqtfEpzbdatWwdPT0+YmJjAxMQE7du3f+W1pLIr7X83+SIiIqBQKNCjR483W2AlVtpr8/DhQ4wdOxZWVlbQ1taGs7Mz/7/2hpT22oSGhqJWrVrQ1dWFjY0NJkyYgKdPn76laisJQSQjERERQktLS3z33Xfi/PnzYsSIEcLY2FjcunWr0PYxMTFCXV1dLF68WFy4cEF89tlnQlNTU5w9e/YtV/7+K+21GThwoFi5cqU4deqUSEhIEP7+/sLIyEj8888/b7ny919pr02+pKQkUa1aNeHp6Sm6d+/+doqtZEp7bbKysoS7u7vo3LmzOHLkiEhKShJRUVEiPj7+LVf+/ivttdm8ebPQ1tYWmzdvFklJSeL3338XVlZWYsKECW+58vcbgyvJStOmTcXYsWOl97m5ucLa2losXLiw0PZ9+/YVXbp0UVnWrFkz8cknn7zROiuj0l6bl+Xk5AhDQ0OxYcOGN1VipVWWa5OTkyNatGgh1q9fL/z8/Bhc35DSXpvVq1cLBwcH8ezZs7dVYqVV2mszduxY0bZtW5VlEydOFC1btnyjdVY2nCpAsvHs2TOcPHkS7du3l5apqamhffv2iI2NLXSb2NhYlfYA4OPjU2R7KpuyXJuXZWZmIjs7G6ampm+qzEqprNdmzpw5sLCwwLBhw95GmZVSWa7NL7/8Ag8PD4wdOxaWlpaoV68eFixYgNzc3LdVdqVQlmvTokULnDx5UppOcO3aNezduxedO3d+KzVXFhoVXQBRSd29exe5ubmwtLRUWW5paYmLFy8Wus1///1XaPv//vvvjdVZGZXl2rxs6tSpsLa2LvCHBr2eslybI0eO4Ntvv0V8fPxbqLDyKsu1uXbtGg4dOoRBgwZh7969uHLlCsaMGYPs7GzMnj37bZRdKZTl2gwcOBB3795Fq1atIIRATk4ORo0ahf/9739vo+RKgyOuRFThFi1ahIiICPz000/Q0dGp6HIqtUePHmHw4MFYt24dqlSpUtHl0Evy8vJgYWGBtWvXonHjxujXrx9mzJiBNWvWVHRplV5UVBQWLFiAVatW4e+//8bOnTuxZ88ezJ07t6JLe69wxJVko0qVKlBXV8etW7dUlt+6dQtVq1YtdJuqVauWqj2VTVmuTb4vv/wSixYtwsGDB+Hm5vYmy6yUSnttrl69iuTkZHTr1k1alpeXBwDQ0NBAYmIiatas+WaLriTK8t+NlZUVNDU1oa6uLi1zcXHBf//9h2fPnkFLS+uN1lxZlOXazJw5E4MHD8bw4cMBAK6urnj8+DFGjhyJGTNmQE2NY4XlgWeRZENLSwuNGzdGZGSktCwvLw+RkZHw8PAodBsPDw+V9gBw4MCBIttT2ZTl2gDA4sWLMXfuXOzbtw/u7u5vo9RKp7TXpnbt2jh79izi4+Ol14cffog2bdogPj4eNjY2b7P891pZ/rtp2bIlrly5Iv0xAQCXLl2ClZUVQ2s5Ksu1yczMLBBO8//AEEK8uWIrm4q+O4yoNCIiIoS2trYIDw8XFy5cECNHjhTGxsbiv//+E0IIMXjwYDFt2jSpfUxMjNDQ0BBffvmlSEhIELNnz+bjsN6Q0l6bRYsWCS0tLbF9+3aRmpoqvR49elRRh/DeKu21eRmfKvDmlPbapKSkCENDQxEQECASExPF7t27hYWFhZg3b15FHcJ7q7TXZvbs2cLQ0FBs2bJFXLt2Tezfv1/UrFlT9O3bt6IO4b3E4Eqys3z5clGjRg2hpaUlmjZtKv766y9pnZeXl/Dz81Npv23bNuHs7Cy0tLRE3bp1xZ49e95yxZVHaa6Nra2tAFDgNXv27LdfeCVQ2v9uXsTg+maV9tocPXpUNGvWTGhrawsHBwcxf/58kZOT85arrhxKc22ys7NFcHCwqFmzptDR0RE2NjZizJgx4sGDB2+/8PeYQgiOXxMRERHRu49zXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiIiISBYYXImIiIhIFhhciYiIiEgWGFyJiN5h/v7+UCgUBV5Xrlwpl/7Dw8NhbGxcLn2Vlb+/P3r06FGhNRQnOTkZCoUC8fHxFV0KUaWnUdEFEBFR8Tp27IiwsDCVZebm5hVUTdGys7OhqalZ0WWUq2fPnlV0CUT0Ao64EhG947S1tVG1alWVl7q6OgBg165daNSoEXR0dODg4ICQkBDk5ORI23711VdwdXWFvr4+bGxsMGbMGGRkZAAAoqKiMGTIEKSlpUkjucHBwQAAhUKBn3/+WaUOY2NjhIeHA/i/UcitW7fCy8sLOjo62Lx5MwBg/fr1cHFxgY6ODmrXro1Vq1aV6ni9vb3x6aefYvz48TAxMYGlpSXWrVuHx48fY8iQITA0NISjoyN+++03aZuoqCgoFArs2bMHbm5u0NHRQfPmzXHu3DmVvnfs2IG6detCW1sbdnZ2WLJkicp6Ozs7zJ07F76+vlAqlRg5ciTs7e0BAA0bNoRCoYC3tzcAIC4uDh06dECVKlVgZGQELy8v/P333yr9KRQKrF+/Hj179oSenh6cnJzwyy+/qLQ5f/48unbtCqVSCUNDQ3h6euLq1avS+tc9n0TvFUFERO8sPz8/0b1790LX/fHHH0KpVIrw8HBx9epVsX//fmFnZyeCg4OlNl9//bU4dOiQSEpKEpGRkaJWrVpi9OjRQgghsrKyRGhoqFAqlSI1NVWkpqaKR48eCSGEACB++uknlf0ZGRmJsLAwIYQQSUlJAoCws7MTO3bsENeuXRM3b94U33//vbCyspKW7dixQ5iamorw8PASH6OXl5cwNDQUc+fOFZcuXRJz584V6urqolOnTmLt2rXi0qVLYvTo0cLMzEw8fvxYCCHE4cOHBQDh4uIi9u/fL86cOSO6du0q7OzsxLNnz4QQQpw4cUKoqamJOXPmiMTERBEWFiZ0dXWlYxJCCFtbW6FUKsWXX34prly5Iq5cuSKOHz8uAIiDBw+K1NRUce/ePSGEEJGRkWLTpk0iISFBXLhwQQwbNkxYWlqK9PR0qT8Aonr16uKHH34Qly9fFoGBgcLAwEDq459//hGmpqaiV69eIi4uTiQmJorvvvtOXLx4UQghynQ+id5nDK5ERO8wPz8/oa6uLvT19aVX7969hRBCtGvXTixYsECl/aZNm4SVlVWR/f3444/CzMxMeh8WFiaMjIwKtCtpcA0NDVVpU7NmTfHDDz+oLJs7d67w8PAo9hhfDq6tWrWS3ufk5Ah9fX0xePBgaVlqaqoAIGJjY4UQ/xdcIyIipDb37t0Turq6YuvWrUIIIQYOHCg6dOigsu/JkyeLOnXqSO9tbW1Fjx49VNrkH+upU6eKPAYhhMjNzRWGhobi119/lZYBEJ999pn0PiMjQwAQv/32mxBCiOnTpwt7e3spXL+sLOeT6H3GOa5ERO+4Nm3aYPXq1dJ7fX19AMDp06cRExOD+fPnS+tyc3Px9OlTZGZmQk9PDwcPHsTChQtx8eJFpKenIycnR2X963J3d5d+fvz4Ma5evYphw4ZhxIgR0vKcnBwYGRmVql83NzfpZ3V1dZiZmcHV1VVaZmlpCQC4ffu2ynYeHh7Sz6ampqhVqxYSEhIAAAkJCejevbtK+5YtWyI0NBS5ubnS9IsXj6k4t27dwmeffYaoqCjcvn0bubm5yMzMREpKSpHHoq+vD6VSKdUdHx8PT0/PQucGl+f5JHpfMLgSEb3j9PX14ejoWGB5RkYGQkJC0KtXrwLrdHR0kJycjK5du2L06NGYP38+TE1NceTIEQwbNgzPnj0rNrgqFAoIIVSWZWdnF1rbi/UAwLp169CsWTOVdvmhsKReDnIKhUJlmUKhAADk5eWVqt+SePGYiuPn54d79+5h6dKlsLW1hba2Njw8PArc0FXYseTXraurW2T/5Xk+id4XDK5ERDLVqFEjJCYmFhpqAeDkyZPIy8vDkiVLoKb2/F7cbdu2qbTR0tJCbm5ugW3Nzc2Rmpoqvb98+TIyMzOLrcfS0hLW1ta4du0aBg0aVNrDKRd//fUXatSoAQB48OABLl26BBcXFwCAi4sLYmJiVNrHxMTA2dm52CCopaUFAAXOU0xMDFatWoXOnTsDAG7cuIG7d++Wql43Nzds2LCh0CcyvAvnk+hdw+BKRCRTs2bNQteuXVGjRg307t0bampqOH36NM6dO4d58+bB0dER2dnZWL58Obp164aYmBisWbNGpQ87OztkZGQgMjIS9evXh56eHvT09NC2bVusWLECHh4eyM3NxdSpU0v0qKuQkBAEBgbCyMgIHTt2RFZWFk6cOIEHDx5g4sSJb+pUSObMmQMzMzNYWlpixowZqFKlivSM2EmTJqFJkyaYO3cu+vXrh9jYWKxYseKVd+lbWFhAV1cX+/btQ/Xq1aGjowMjIyM4OTlh06ZNcHd3R3p6OiZPnlzsCGphAgICsHz5cvTv3x/Tp0+HkZER/vrrLzRt2hS1atWq8PNJ9K7h47CIiGTKx8cHu3fvxv79+9GkSRM0b94cX3/9NWxtbQEA9evXx1dffYXPP/8c9erVw+bNm7Fw4UKVPlq0aIFRo0ahX79+MDc3x+LFiwEAS5YsgY2NDTw9PTFw4EAEBQWVaE7s8OHDsX79eoSFhcHV1RVeXl4IDw+XHin1pi1atAjjxo1D48aN8d9//+HXX3+VRkwbNWqEbdu2ISIiAvXq1cOsWbMwZ84c+Pv7F9unhoYGli1bhm+++QbW1tbSPNlvv/0WDx48QKNGjTB48GAEBgbCwsKiVPWamZnh0KFDyMjIgJeXFxo3box169ZJfyRU9PkketcoxMuTmIiIiGQmKioKbdq0wYMHDyr8m8CI6M3hiCsRERERyQKDKxERERHJAqcKEBEREZEscMSViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhkgcGViIiIiGSBwZWIiIiIZIHBlYiIiIhk4f8BilIgAoEQGw0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def plot_feature_importance(model, X_test, y_test):\n",
    "    result = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    importance = result.importances_mean\n",
    "    feature_names = X_test.columns\n",
    "\n",
    "    print(feature_names)\n",
    "    print(importance)\n",
    "    \n",
    "    plt.barh(feature_names, importance)\n",
    "    \n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance Plot')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(new_best_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6d81c-ee37-4340-9548-801bd75155c3",
   "metadata": {},
   "source": [
    "### Variations in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dcbe3538-076b-4ae6-b5e5-91d631747f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unseen combinations in test data: 43189\n"
     ]
    }
   ],
   "source": [
    "err_analysis = res.copy()\n",
    "err_analysis[\"relative_error\"] = abs(err_analysis['pred'] - err_analysis['actual']) / err_analysis['actual']\n",
    "err_analysis = err_analysis[[\"start_station_cluster\", \"end_station_cluster\", \"relative_error\"]].copy()\n",
    "err_analysis = err_analysis.groupby([\"start_station_cluster\", \"end_station_cluster\"]).mean()\n",
    "\n",
    "worst_predictions = err_analysis.copy().reset_index().sort_values(\"relative_error\", ascending=False)\n",
    "\n",
    "df_train_copy = pd.concat([df_train, df_valid]).copy()[[\"start_station_cluster\", \"end_station_cluster\", \"count\"]]\n",
    "df_train_copy = df_train_copy.groupby([\"start_station_cluster\", \"end_station_cluster\"]).sum().reset_index()\n",
    "\n",
    "df_test_copy = df_test.copy()[[\"start_station_cluster\", \"end_station_cluster\", \"count\"]]\n",
    "df_test_copy = df_test_copy.groupby([\"start_station_cluster\", \"end_station_cluster\"]).sum().reset_index()\n",
    "\n",
    "compare_stations = pd.merge(df_test_copy, df_train_copy, on=[\"start_station_cluster\", \"end_station_cluster\"], how=\"left\")\n",
    "\n",
    "stations_not_in_training = compare_stations[compare_stations[\"count_y\"].isna()]\n",
    "stations_not_in_training = stations_not_in_training.drop(\"count_x\", axis=1).rename(columns={'count_y': 'in_training'})\n",
    "stations_not_in_training['in_training'].fillna(False, inplace=True)\n",
    "\n",
    "worst_predictions = pd.merge(wors_predictions, stations_not_in_training, on=[\"start_station_cluster\", \"end_station_cluster\"], how=\"left\")\n",
    "\n",
    "error_testing = df_test.copy()\n",
    "error_testing.drop(\"duration_sec\", axis=1, inplace=True)\n",
    "\n",
    "error_testing = pd.merge(error_testing, stations_not_in_training, on=[\"start_station_cluster\", \"end_station_cluster\"], how=\"left\")\n",
    "error_testing[\"in_training\"].fillna(True, inplace=True)\n",
    "before = len(error_testing)\n",
    "error_testing = error_testing[error_testing[\"in_training\"] == True]\n",
    "after = len(error_testing)\n",
    "\n",
    "print(\"Number of unseen combinations in test data: \" + str(before - after))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
