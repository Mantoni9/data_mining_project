{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea5435bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from geopy.distance import geodesic\n",
    "import holidays\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "788027eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_list = ['data/weather_data/en_climate_daily_QC_7025251_2014_P1D.csv', 'data/weather_data/en_climate_daily_QC_7025251_2015_P1D.csv', 'data/weather_data/en_climate_daily_QC_7025251_2016_P1D.csv',\n",
    "                          'data/weather_data/en_climate_daily_QC_7025251_2016_P1D.csv', 'data/weather_data/en_climate_daily_QC_7025251_2017_P1D.csv', 'data/weather_data/en_climate_daily_QC_7025251_2018_P1D.csv',\n",
    "                          'data/weather_data/en_climate_daily_QC_7025251_2019_P1D.csv', 'data/weather_data/en_climate_daily_QC_7025251_2020_P1D.csv', 'data/weather_data/en_climate_daily_QC_7025251_2021_P1D.csv', 'data/weather_data/en_climate_daily_QC_7025251_2022_P1D.csv']\n",
    "\n",
    "df_weather = []\n",
    "\n",
    "\n",
    "for file in weather_list:\n",
    "    df = pd.read_csv(file)\n",
    "    df_weather.append(df)\n",
    "\n",
    "df_weather = pd.concat(df_weather)\n",
    "df_weather.to_csv('data/preprocessed_data/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9735d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with files for stations 2022\n",
    "stations2022_list = ['data/stations_2022/20220104_stations.csv','data/stations_2022/20220105_stations.csv','data/stations_2022/20220106_stations.csv','data/stations_2022/20220107_stations.csv','data/stations_2022/20220108_stations.csv','data/stations_2022/20220109_stations.csv','data/stations_2022/20220110_stations.csv','data/stations_2022/20220111_stations.csv']\n",
    "\n",
    "df_stations_2022 = []\n",
    "\n",
    "for file in stations2022_list:\n",
    "    df = pd.read_csv(file)\n",
    "    df_stations_2022.append(df)\n",
    "\n",
    "# Remove Duplicates\n",
    "df_stations_2022 = pd.concat(df_stations_2022, ignore_index= True)\n",
    "df_stations_2022 = df_stations_2022.drop_duplicates()\n",
    "\n",
    "df_stations_2022.to_csv('data/stations/Stations_2022.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8f985e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with files for stations 2022\n",
    "def prepare_stations():\n",
    "    lst = []\n",
    "    for year in range(2014, 2023):\n",
    "        df = pd.read_csv(f'data/stations/Stations_{year}.csv')\n",
    "        lst.append(df)\n",
    "    \n",
    "    # Remove Duplicates\n",
    "    df_stations = pd.concat(lst, ignore_index=True)\n",
    "    df_stations.drop_duplicates(subset=['code'], inplace=True, keep=\"first\")\n",
    "    df_stations.to_csv(\"data/regression_analysis/all_stations.csv\")\n",
    "    \n",
    "    df_stations_2022 = pd.read_csv('data/stations/Stations_2022.csv')\n",
    "    df_stations['distance_to_center'] = df_stations_2022.apply(calculate_distance_to_center, axis=1)\n",
    "    coordinates = df_stations[['latitude', 'longitude']]\n",
    "    kmeans = KMeans(n_clusters=50, random_state=0).fit(coordinates)\n",
    "    df_stations['stations_cluster'] =  kmeans.labels_\n",
    "    \n",
    "    df_stations.to_csv(\"data/regression_analysis/all_stations_clustered.csv\")\n",
    "    return df_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f875ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_clusters(rides_df, stations_df):\n",
    "    merged_df = pd.merge(rides_df, stations_df, left_on='start_station_code', right_on='code', how='left')\n",
    "    merged_df = merged_df.rename(columns={'stations_cluster': 'start_station_cluster'})\n",
    "    merged_df.drop('code', axis=1, inplace=True)\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, stations_df, left_on='end_station_code', right_on='code', how='left')\n",
    "    merged_df = merged_df.rename(columns={'stations_cluster': 'end_station_cluster'})\n",
    "    merged_df.drop('code', axis=1, inplace=True)\n",
    "    \n",
    "    grouped_df = merged_df.groupby(['start_date', 'start_station_cluster', 'end_station_cluster']).agg(count=('start_date', 'size'), duration_sec=('duration_sec', 'mean'), is_holiday=(\"is_holiday\", \"first\"), is_weekend=(\"is_weekend\", \"first\")).reset_index()\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ac002466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather():\n",
    "    df_weather = pd.read_csv('data/preprocessed_data/weather.csv', parse_dates=[4])\n",
    "    df_weather.columns = df_weather.columns.str.lower()\n",
    "    df_weather = df_weather[[\"date/time\", \"mean temp (째c)\", \"total precip (mm)\"]]\n",
    "    df_weather = df_weather.rename(columns={\"date/time\": \"date\",'mean temp (째c)': 'mean_temperature','total precip (mm)': 'total_precipitation'})\n",
    "    df_weather['date'] = pd.to_datetime(df_weather['date']).dt.date\n",
    "    \n",
    "    # interpolate missing data\n",
    "    df_weather[['mean_temperature','total_precipitation']] = df_weather[['mean_temperature','total_precipitation']].interpolate()\n",
    "    return df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d6f7dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_weather(grouped, weather):\n",
    "    w_weather = grouped.merge(weather, left_on='start_date', right_on='date', how='left')\n",
    "    w_weather.drop('date', axis=1, inplace=True)\n",
    "    return w_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5e37ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_to_center(row):\n",
    "    center_coords = (45.508888, -73.554167)  # City center coordinates (latitude, longitude)\n",
    "    station_coords = (row['latitude'], row['longitude'])  # Station coordinates (latitude, longitude)\n",
    "    distance_km = geodesic(center_coords, station_coords).kilometers\n",
    "    return distance_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "19c870e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(rides_file_path, stations_file_path):\n",
    "    # Read rides data and stations data\n",
    "    rides_data = pd.read_csv(rides_file_path, parse_dates=[0, 1, 2, 3])\n",
    "    stations_data = pd.read_csv(stations_file_path)\n",
    "\n",
    "    # Convert column names to lowercase\n",
    "    rides_data.columns = rides_data.columns.str.lower()\n",
    "    stations_data.columns = stations_data.columns.str.lower()\n",
    "\n",
    "    # Rename columns if necessary\n",
    "    if 'start_station_code' not in rides_data.columns:\n",
    "        rides_data = rides_data.rename(columns={'emplacement_pk_start': 'start_station_code',\n",
    "                                                'emplacement_pk_end': 'end_station_code'})\n",
    "\n",
    "    if 'code' not in stations_data.columns:\n",
    "        stations_data = stations_data.rename(columns={'pk': 'code'})\n",
    "\n",
    "    # Convert station codes to integers\n",
    "    if rides_data['start_station_code'].dtype != 'int':\n",
    "        rides_data['start_station_code'] = pd.to_numeric(rides_data['start_station_code'], errors='coerce')\n",
    "        rides_data['end_station_code'] = pd.to_numeric(rides_data['end_station_code'], errors='coerce')\n",
    "        rides_data = rides_data.dropna(subset=['start_station_code', 'end_station_code'])\n",
    "        rides_data['start_station_code'] = rides_data['start_station_code'].astype(int)\n",
    "        rides_data['end_station_code'] = rides_data['end_station_code'].astype(int)\n",
    "\n",
    "    # Extract year, month, and weekday information\n",
    "    rides_data['year'] = rides_data['start_date'].dt.year\n",
    "    rides_data['month'] = rides_data['start_date'].dt.month\n",
    "    rides_data['weekday'] = rides_data['start_date'].dt.weekday\n",
    "\n",
    "\n",
    "    # Group rides by start date and start station code and count rides\n",
    "    rides_count = rides_data.groupby([pd.Grouper(key='start_date', freq='12h'), 'start_station_code'])['end_date'].count().reset_index()\n",
    "    rides_count = rides_count.rename(columns={'end_date': 'rides_count'})\n",
    "\n",
    "    # Add AM/PM flag based on start hour\n",
    "    rides_count['am_pm'] = rides_count['start_date'].dt.hour < 12\n",
    "\n",
    "    # Count the number of stations\n",
    "    stations_count = stations_data['code'].nunique()\n",
    "    rides_count['stations_count'] = stations_count\n",
    "\n",
    "    # Check if the date is a holiday or weekend\n",
    "    holidays_canada = holidays.country_holidays('CA', subdiv='QC')\n",
    "    rides_count['is_holiday'] = rides_count['start_date'].dt.date.map(lambda x: x in holidays_canada)\n",
    "    rides_count['is_weekend'] = rides_count['start_date'].dt.weekday > 4\n",
    "\n",
    "    rides_data['is_holiday'] = rides_data['start_date'].dt.date.map(lambda x: x in holidays_canada)\n",
    "    rides_data['is_weekend'] = rides_data['start_date'].dt.weekday > 4\n",
    "\n",
    "    # Convert start_date column to datetime and set it as the index\n",
    "    rides_data['start_date'] = pd.to_datetime(rides_data['start_date']).dt.date\n",
    "\n",
    "    # Merge rides data with stations data\n",
    "    rides_count = rides_count.merge(stations_data, left_on='start_station_code', right_on='code', how='left')\n",
    "\n",
    "    # Drop rows with NaN coordinates\n",
    "    rides_count = rides_count.dropna(subset=['latitude', 'longitude'])\n",
    "      \n",
    "    # Calculate distance to city center for each station\n",
    "    rides_count['distance_to_center'] = rides_count.apply(calculate_distance_to_center, axis=1)\n",
    "\n",
    "    # Read weather data and interpolate missing values\n",
    "    weather_data = pd.read_csv('data/preprocessed_data/weather.csv', parse_dates=[4])\n",
    "    weather_data.columns = weather_data.columns.str.lower()\n",
    "    weather_data = weather_data[[\"date/time\", \"mean temp (째c)\", \"total precip (mm)\"]]\n",
    "    weather_data = weather_data.rename(columns={\"date/time\": \"date\", 'mean temp (째c)': 'mean_temperature', 'total precip (mm)': 'total_precipitation'})\n",
    "    weather_data['date'] = pd.to_datetime(weather_data['date']).dt.date\n",
    "    weather_data[['mean_temperature', 'total_precipitation']] = weather_data[['mean_temperature', 'total_precipitation']].interpolate()\n",
    "\n",
    "    # Merge rides data with weather data\n",
    "    rides_count['ride_date'] = rides_count['start_date'].dt.date\n",
    "    rides_count = rides_count.merge(weather_data, left_on='ride_date', right_on='date', how='left')\n",
    "\n",
    "\n",
    "    # Extract year, month, day, and weekday information\n",
    "    rides_count[['year', 'month', 'day', 'weekday']] = pd.DataFrame({\n",
    "        'year': rides_count['start_date'].dt.year,\n",
    "        'month': rides_count['start_date'].dt.month,\n",
    "        'day': rides_count['start_date'].dt.day,\n",
    "        'weekday': rides_count['start_date'].dt.weekday.values\n",
    "    })\n",
    "\n",
    "    # Select relevant columns for the final output\n",
    "    rides_count = rides_count[[\n",
    "        'latitude', 'longitude', 'distance_to_center', 'year', 'month', 'day', 'weekday', 'am_pm', 'is_holiday',\n",
    "        'is_weekend', 'mean_temperature', 'total_precipitation', 'stations_count', 'rides_count'\n",
    "    ]]\n",
    "\n",
    "    return rides_count, rides_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "91e5057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_task1(data):\n",
    "    # Columns and thresholds\n",
    "    day_data_cols = ['year', 'month', 'day', 'weekday', 'is_holiday', 'is_weekend', 'mean_temperature', 'total_precipitation',]\n",
    "    label3_split = [10, 30]\n",
    "    label5_split = [5, 15, 30, 50]\n",
    "\n",
    "    # Remove duplicates and calculate daily sums\n",
    "    day_data = data[day_data_cols].drop_duplicates(subset=day_data_cols, keep='first')\n",
    "    data_new = data.groupby(['year', 'month', 'day', 'am_pm'], as_index=False)['rides_count'].sum()\n",
    "\n",
    "    # Merge with daily columns\n",
    "    data_new = data_new.merge(day_data, how='left', on=['year', 'month', 'day'])\n",
    "\n",
    "    # Create label columns\n",
    "    bins3 = [float('-inf'), label3_split[0], label3_split[1], float('inf')]\n",
    "    bins5 = [float('-inf'), label5_split[0], label5_split[1], label5_split[2], label5_split[3], float('inf')]\n",
    "    labels3 = [1, 2, 3]\n",
    "    labels5 = [1, 2, 3, 4, 5]\n",
    "    data_new['label3'] = pd.cut(data_new['rides_count'], bins=bins3, labels=labels3)\n",
    "    data_new['label5'] = pd.cut(data_new['rides_count'], bins=bins5, labels=labels5)\n",
    "\n",
    "    return data_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "79f2c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task2(rides):\n",
    "  stations = prepare_stations()[[\"code\", \"stations_cluster\"]]\n",
    "  grouped = include_clusters(rides, stations)\n",
    "  weather = get_weather()\n",
    "  grouped_weather = include_weather(grouped, weather).drop_duplicates()\n",
    "\n",
    "  return grouped_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3e02fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_preprocessed_data():\n",
    "    stations_files = {\n",
    "        'train': [list(range(2014, 2019)), 'train.csv'],\n",
    "        'valid': [(2019,), 'valid.csv'],\n",
    "        'test': [(2022,), 'test.csv']\n",
    "    }\n",
    "\n",
    "    weather_data = None\n",
    "\n",
    "    for dataset, (years, filename) in stations_files.items():\n",
    "        df_dataset = pd.DataFrame()\n",
    "        df_rides = pd.DataFrame()\n",
    "        for year in years:\n",
    "            stations_file_path = f'data/stations/Stations_{year}.csv'\n",
    "            for month in range(4, 11):\n",
    "                rides_file_path = f'data/bike_rides/OD_{year}-{month:02d}.csv'\n",
    "                df_month, rides_month = preprocess_data(rides_file_path, stations_file_path)\n",
    "                df_dataset = pd.concat([df_dataset, df_month]).reset_index(drop=True)\n",
    "                df_rides = pd.concat([df_rides, rides_month])\n",
    "\n",
    "        df_dataset.to_csv(f'data/preprocessed_data/{filename}', index=False)\n",
    "        df_dataset_t1 = preprocess_task1(df_dataset)\n",
    "        df_dataset_t1.to_csv(f'data/preprocessed_data/t1_{dataset}.csv', index=False)\n",
    "        df_dataset_t2 = preprocess_task2(df_rides)\n",
    "        df_dataset_t2.to_csv(f'data/preprocessed_data/t2_{dataset}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "14adbe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generate_preprocessed_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
